{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Propeller","text":"<p>Propeller is a cutting-edge orchestrator for WebAssembly (Wasm) workloads across the Cloud-Edge continuum. It enables seamless deployment of Wasm applications from powerful cloud servers to constrained microcontrollers, combining flexibility, security, and performance.</p>"},{"location":"#features","title":"\ud83c\udf1f Features","text":"<ul> <li>\ud83c\udf10 Cloud-Edge Orchestration: Deploy Wasm workloads effortlessly across diverse environments, from robust cloud servers to lightweight microcontrollers.</li> <li>\u26a1 Fast Boot Times: Take advantage of Wasm's near-instant startup for efficient workload execution.</li> <li>\ud83d\udce6 FaaS Deployment: Enable Function-as-a-Service (FaaS) capabilities for scalable and event-driven applications.</li> <li>\ud83d\udda5\ufe0f OCI Registry Support: Push and pull Wasm workloads from OCI-compliant registries for streamlined workflow integration.</li> <li>\ud83d\udd27 WAMR on Zephyr RTOS: Deploy lightweight Wasm workloads on constrained devices running Zephyr RTOS via the WebAssembly Micro Runtime (WAMR).</li> <li>\ud83d\udee0\ufe0f Powerful Service Mesh: Integrates with SuperMQ for secure, efficient IoT device communication.</li> <li>\ud83d\udd12 Security at the Core: Propeller ensures secure workload execution and communication for IoT environments.</li> </ul>"},{"location":"#how-it-works","title":"\ud83d\udee0\ufe0f How It Works","text":"<ol> <li>Develop in WebAssembly: Write portable, lightweight Wasm workloads for your application.</li> <li>Register Workloads: Push your workloads to an OCI-compliant registry for easy deployment.</li> <li>Deploy Anywhere: Use Propeller to orchestrate and manage workload deployment across the cloud, edge, and IoT devices.</li> <li>Monitor &amp; Scale: Leverage real-time monitoring and dynamic scaling to optimize your system's performance.</li> </ol>"},{"location":"architecture/","title":"System Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>The Propeller system is a distributed computing platform designed to manage and execute tasks across multiple nodes (proplets). It leverages MQTT for communication, a manager service for task orchestration, and a proxy service for container image distribution. The system is composed of several key components:</p> <ol> <li>CLI: Command Line Interface for interacting with the Propeller system.</li> <li>Manager: Central service responsible for task management and proplet coordination.</li> <li>Proplet: Worker nodes that execute tasks.</li> <li>Proxy: Service for fetching and distributing container images from a registry.</li> <li>SuperMQ: Internal Event Driven Infrastructure for creation and coommunication between services.</li> </ol> <p></p>"},{"location":"architecture/#components","title":"Components","text":""},{"location":"architecture/#cli","title":"CLI","text":"<p>The CLI provides a command-line interface for users to interact with the Propeller system. It allows users to create, list, update, and delete tasks, as well as start and stop tasks. The CLI also allows you to provision manager and proplets.</p>"},{"location":"architecture/#manager","title":"Manager","text":"<p>The Manager is the central service responsible for managing tasks and coordinating proplets. It handles task creation, updates, deletion, and execution and maintains an internal database for tracking tasks and proplets. It also manages the lifecycle of proplets and ensures they are alive and healthy. The Manager uses MQTT for communication between services. It exposes REST endpoints for task management and proplet coordination. Currently, the system supports 1 manager : multiple workers. In the future, the system will be expanded to support multiple managers : multiple workers.</p>"},{"location":"architecture/#proplet","title":"Proplet","text":"<p>Proplets are worker nodes that execute tasks. They receive tasks from the Manager, execute them, and report the results back. Proplets also send periodic liveliness updates to the Manager to indicate they are alive.</p>"},{"location":"architecture/#proxy","title":"Proxy","text":"<p>The Proxy service is responsible for fetching container images from a registry and distributing them to proplets. It handles authentication with the registry and splits the container images into chunks for efficient distribution. This is for OCI registry to fetch image from OCI registry and split the image into chunks for proplets to assemble and execute.</p>"},{"location":"architecture/#supermq","title":"SuperMQ","text":"<p>SuperMQ is an Event Driven Infrastructure (EDI) for creating and coordinating services. It provides a way to create and manage entities, as well as handle communication between services. SuperMQ uses MQTT for communication and provides a set of APIs for entity creation, management, and communication.</p>"},{"location":"architecture/#communication","title":"Communication","text":""},{"location":"architecture/#mqtt","title":"MQTT","text":"<p>MQTT is used for communication between the Manager, Proplets, and Proxy. The Manager publishes tasks to proplets, and proplets send liveliness updates and task results back to the Manager. The Proxy fetches container images and distributes them to proplets.</p>"},{"location":"architecture/#http","title":"HTTP","text":"<p>HTTP is used for the CLI to interact with the Manager. The Manager exposes REST endpoints for task management and proplet coordination.</p>"},{"location":"architecture/#task-lifecycle","title":"Task Lifecycle","text":"<ol> <li>Task Creation: A user creates a task using the CLI or HTTP API, which sends a request to the Manager.</li> <li>Task Scheduling: The Manager selects a proplet to execute the task based on the scheduling algorithm.</li> <li>Task Execution: The selected proplet receives the task, executes it, and reports the results back to the Manager.</li> <li>Task Completion: The Manager updates the task status and stores the results.</li> </ol>"},{"location":"architecture/#proplet-liveliness","title":"Proplet Liveliness","text":"<p>Proplets send periodic liveliness updates to the Manager to indicate they are alive. The Manager uses these updates to monitor the health of proplets and ensure they are available for task execution.</p>"},{"location":"architecture/#container-image-distribution","title":"Container Image Distribution","text":"<p>The Proxy fetches container images from a registry, splits them into chunks, and distributes them to proplets. Proplets assemble the chunks and execute the container image.</p>"},{"location":"developer-guide/","title":"Developer's Guide","text":""},{"location":"developer-guide/#getting-propeller","title":"Getting Propeller","text":"<p>Propeller source can be found in the official Propeller GitHub repository. You should fork this repository in order to make changes to the project. The forked version of the repository should be cloned using the following:</p> <pre><code>git clone https://github.com/your-github-username/propeller.git $SOMEPATH/propeller\ncd $SOMEPATH/propeller\n</code></pre>"},{"location":"developer-guide/#building-propeller","title":"Building Propeller","text":""},{"location":"developer-guide/#prerequisites","title":"Prerequisites","text":"<p>To build Propeller, you will need the following:</p> <ul> <li>A Go compiler (Go 1.23 or later)</li> <li>Make</li> <li>Docker</li> <li>Wasmtime</li> <li>TinyGo</li> </ul>"},{"location":"developer-guide/#building","title":"Building","text":"<p>Use the GNU Make tool to build all Propeller services:</p> <pre><code>make all\n</code></pre> <p>This will build Propeller for your platforms.</p> <p>To build Propeller for other platforms, use the following:</p> OS Architecture Command Linux amd64 <code>GOOS=linux GOARCH=amd64 make all</code> Linux arm64 <code>GOOS=linux GOARCH=arm64 make all</code> Windows amd64 <code>GOOS=windows GOARCH=amd64 make all</code> Darwin amd64 <code>GOOS=darwin GOARCH=amd64 make all</code>"},{"location":"developer-guide/#building-an-individual-service","title":"Building an individual service","text":"<p>You can build individual services using the following:</p> <pre><code>make &lt;service&gt;\n</code></pre> <p>For example, to build the <code>manager</code> service, use the following:</p> <pre><code>make manager\n</code></pre> <p>The built binaries will be located in the <code>build</code> directory.</p>"},{"location":"developer-guide/#building-examples","title":"Building examples","text":"<p>You can build examples using the following:</p> <pre><code>make &lt;example&gt;\n</code></pre> <p>For example, to build the <code>addition</code> example, use the following:</p> <pre><code>make addition\n</code></pre> <p>This compiles the addition example to wasm and can be located in the <code>build</code> directory.</p> <p>To test the addition example, use the following:</p> <pre><code>wasmtime --invoke add ./build/addition.wasm 1 2\n</code></pre> <p>This will output something like:</p> <pre><code>warning: using `--invoke` with a function that takes arguments is experimental and may break in the future\nwarning: using `--invoke` with a function that returns values is experimental and may break in the future\n3\n</code></pre>"},{"location":"developer-guide/#installing","title":"Installing","text":"<p>Once you have built Propeller, you can install it using the following:</p> <pre><code>make install\n</code></pre> <p>This will install Propeller to the <code>GOBIN</code> directory.</p>"},{"location":"developer-guide/#linter","title":"Linter","text":"<p>Propeller uses golangci-lint to lint the code. You can run the linter using the following:</p> <pre><code>make lint\n</code></pre>"},{"location":"developer-guide/#supermq","title":"SuperMQ","text":""},{"location":"developer-guide/#starting-supermq","title":"Starting SuperMQ","text":"<p>To start SuperMQ, use the following:</p> <pre><code>make start-supermq\n</code></pre> <p>This will in the background run <code>docker compose -f docker/compose.yaml up -d</code> which will start the SuperMQ services.</p> <p>You can override the configuration or add some extra parameters to the docker compose configuration.</p>"},{"location":"developer-guide/#stopping-supermq","title":"Stopping SuperMQ","text":"<p>SuperMQ can be stopped using the following:</p> <pre><code>make stop-supermq\n</code></pre>"},{"location":"embedded-proplet/","title":"Embedded Proplet","text":""},{"location":"embedded-proplet/#wamr-integration-in-the-embedded-proplet","title":"WAMR Integration in the Embedded Proplet","text":"<p>Propeller integrates WAMR within its decentralized worker-node framework, enabling distributed execution of WASM workloads on Zephyr-based embedded devices through the embedded proplet. The WAMR runtime is integrated into the Propeller project as a Git submodule, ensuring modular dependency management and streamlined updates. The integration is defined within the CMakeLists.txt configuration, where WAMR is compiled as part of the Zephyr build system. The embedded proplet explicitly configures WAMR for the ESP32-S3 (XTENSA) architecture by setting <code>WAMR_BUILD_PLATFORM=\"zephyr\"</code> and <code>WAMR_BUILD_TARGET=\"XTENSA\"</code>. Other target options include <code>\"ARM\"</code>, <code>\"RISCV\"</code>, <code>\"X86_64\"</code>, and <code>\"MIPS\"</code>, making the embedded proplet adaptable to a wide range of embedded architectures beyond XTENSA.</p> <p>To ensure an optimal balance between performance and flexibility in embedded environments, the embedded proplet is configured to support both interpreter mode (<code>WAMR_BUILD_INTERP=1</code>) and ahead-of-time (AOT) compilation (<code>WAMR_BUILD_AOT=1</code>). The above configuration allows for efficient execution of pre-compiled WASM modules while retaining the ability to interpret dynamically loaded binaries. Disabling the interpreter (<code>WAMR_BUILD_INTERP=0</code>) mandates the use of AOT-compiled modules, potentially improving runtime efficiency but limiting flexibility. Conversely, disabling AOT (<code>WAMR_BUILD_AOT=0</code>) forces reliance on interpretation, which may introduce performance overhead but ensures broader compatibility for modules that have not been precompiled. The built-in WAMR libc (<code>WAMR_BUILD_LIBC_BUILTIN=1</code>) is utilized instead of WASI, as full WASI support in Zephyr is still evolving. Furthermore, a global heap pool (<code>WAMR_BUILD_GLOBAL_HEAP_POOL=1</code>) is allocated with a size of 40 KB (<code>WAMR_BUILD_GLOBAL_HEAP_SIZE=40960</code>), ensuring efficient memory management for WASM execution.</p>"},{"location":"embedded-proplet/#extending-the-zephyr-build-system-for-wamr-integration","title":"Extending the Zephyr Build System for WAMR Integration","text":"<p>To integrate WAMR seamlessly within the Zephyr build system, the following configurations and module definitions are applied. First, the build system includes <code>runtime_lib.cmake</code> from the WAMR repository, ensuring that all necessary runtime components are compiled as part of the Zephyr application. The approach enables the embedded proplet to efficiently execute WASM workloads while using Zephyr\u2019s build and dependency management capabilities. Additionally, the Zephyr build system is extended to recognize WAMR as an integral part of the embedded proplet by modifying the <code>ZEPHYR_EXTRA_MODULES</code> variable. The modification ensures that the WAMR repository path is explicitly included, allowing Zephyr to treat WAMR as a native library. Consequently, WAMR\u2019s runtime components are automatically included during the firmware compilation process, avoiding manual dependency management.</p> <p>To establish a direct connection between the application and WAMR\u2019s execution environment, the build system explicitly includes WAMR\u2019s core runtime headers and source files. This guarantees that the WebAssembly engine is properly compiled and linked within the firmware, ensuring smooth execution of WASM workloads.</p> <p>Finally, WAMR is embedded into the Zephyr application as a dedicated library using <code>zephyr_library_named(wamr_lib)</code>. The application then links WAMR with the Zephyr build system through <code>target_link_libraries(app PRIVATE wamr_lib)</code>, allowing the WASM execution environment to be tightly integrated with the Zephyr firmware.</p>"},{"location":"embedded-proplet/#wasm-handler","title":"WASM Handler","text":"<p>The WASM handler, implemented in <code>wasm_handler.c</code> and <code>wasm_handler.h</code>, serves as the primary interface between the embedded proplet and the embedded device. It is responsible for reading binary WebAssembly modules, validating their integrity, and loading the wasm modules into WAMR\u2019s runtime. The validation step ensures that corrupted or malformed modules do not compromise system stability. Once a WASM module is loaded, the handler initializes the runtime environment to ensure proper execution. The initialization includes allocating a dedicated stack (16 KB) and heap (16 KB) using <code>wasm_runtime_instantiate()</code>. To support concurrent execution of multiple WASM workloads, the handler maintains an array where each running module is tracked with a unique task ID. The implementation of the embedded proplet also ensures that WASM modules can be explicitly terminated, freeing memory and execution slots when no longer needed.</p> <p>For WASM modules to interact with external hardware and networking components, the embedded proplet exposes controlled system interfacing methods. The methods provide secure access to essential embedded system capabilities, including:</p> <ul> <li>Publishing results over MQTT: The handler enables the embedded proplet to send execution results to the Manager using <code>publish_results()</code>, facilitating seamless communication with the Manager.</li> <li>Interacting with external inputs: Embedded Proplets receive dynamic inputs through a defined input structure (<code>inputs[MAX_INPUTS]</code>), allowing parameterized execution of WebAssembly code</li> <li>Performing logging and debugging: The embedded proplet integrates with Zephyr\u2019s logging framework, ensuring that execution logs and error messages are captured for real-time monitoring and debugging.</li> </ul> <p>Since embedded devices have limited resources, the WASM handler enforces strict memory isolation and execution constraints to maintain system reliability. This is achieved through:</p> <ul> <li>Creating execution environments: Each WASM module operates within a sandboxed memory region, using <code>wasm_runtime_create_exec_env()</code>, preventing unintended access to system memory.</li> <li>Limiting execution time and memory usage: The WASM handler enforces a predefined memory allocation (e.g., a global heap size of 40 KB) to prevent system-wide memory exhaustion.</li> <li>Handling runtime exceptions: The system continuously monitors for execution errors using <code>wasm_runtime_get_exception()</code>. If an error occurs, it is logged, and the execution is halted to prevent cascading failures.</li> </ul> <p>For WebAssembly modules to interact with hardware and networking components, the WASM handler facilitates controlled access to system interfaces. The controlled access is achieved by exposing custom host functions, which allow WebAssembly code to:</p> <ul> <li>Publish results over MQTT: Using <code>publish_results()</code>, execution results from a WASM module can be sent over an MQTT channel.</li> <li>Interact with external inputs: WASM functions can receive input values (<code>inputs[MAX_INPUTS]</code>) that modify their behavior dynamically.</li> <li>Perform logging and debugging: The handler integrates with Zephyr\u2019s logging system, providing real-time execution feedback.</li> </ul>"},{"location":"embedded-proplet/#ensuring-memory-isolation-and-stability","title":"Ensuring Memory Isolation and Stability","text":"<p>Since embedded devices have limited resources, the WASM handler enforces strict memory constraints and execution limits. This is done by:</p> <ul> <li>Creating execution environments using <code>wasm_runtime_create_exec_env()</code>, which ensures each WASM module operates in a sandboxed memory region.</li> <li>Limiting execution time by enforcing predefined memory allocations (e.g., 40 KB global heap) to prevent system-wide memory exhaustion.</li> <li>Handling runtime exceptions by checking for error messages from <code>wasm_runtime_get_exception()</code>, preventing runtime crashes caused by invalid operations.</li> </ul> <p>A key aspect of WAMR integration is ensuring sandboxed execution. Each WASM module operates in an isolated environment, with controlled access to system resources. The WASM handler enforces strict memory and execution limits, preventing any single module from consuming excessive resources or interfering with other processes. Additionally, the system enables secure inter-process communication between WASM modules and native Zephyr components, allowing WebAssembly workloads to interact with hardware peripherals and networking functions through a well-defined API.</p> <p>Propeller also leverages WAMR\u2019s extensibility by incorporating custom host functions. These functions allow WASM modules to perform operations such as network communication, sensor data acquisition, and logging. By defining specific host functions, Propeller enables WASM workloads to execute efficiently while maintaining security and stability within the embedded environment.</p> <p>Another critical component of the WAMR integration is task scheduling and workload management. The orchestrator assigns WASM tasks to available proplets based on resource availability, with the WASM handler dynamically managing execution priorities. Each proplet periodically reports its workload status to the orchestrator, enabling real-time load balancing and task reassignment if needed.</p>"},{"location":"embedded-proplet/#task-scheduling-and-resource-management","title":"Task Scheduling and Resource Management","text":"<p>The Propeller Orchestrator dynamically assigns workloads to proplets based on resource availability, power constraints, and scheduling priorities. Each proplet operates independently while receiving tasks from the orchestrator, executing them in an isolated runtime environment. This design guarantees security and stability while preventing resource contention among different workloads.</p> <p>The embedded proplet system is structured into the following components:</p> <p>The networking and connectivity components of the embedded proplet are built upon the networking stack of Zephyr, providing robust support for WiFi and IP-based communication. The configuration file enables WiFi networking and network management, allowing devices to establish and maintain wireless connections effectively. The system also supports general networking capabilities through the network management layer of Zephyr, which enables runtime control and configuration of networking interfaces.</p> <p>The system relies on DHCPv4 for dynamic IP address allocation, ensuring that each embedded proplet can automatically obtain an IP address when connecting to the network. The above eliminates the need for static IP configurations and allows seamless integration into existing network infrastructures. Additionally, the networking stack supports both TCP and UDP, ensuring compatibility with various communication protocols used in distributed systems. To manage multiple network interfaces, the configuration allows up to two IPv4 addresses, configured through <code>CONFIG_NET_IF_MAX_IPV4_COUNT=2</code>, per network interface. Though IPv6 support is available, it is disabled in the configuration file, as the embedded proplet currently prioritizes IPv4 networking. At the link-layer level, the system enables Ethernet and WiFi management, ensuring that edge devices connect using standard networking interfaces. The configuration file also specifies a maximum of two managed WiFi interfaces, allowing the system to handle multiple WiFi connections efficiently.</p> <p>Packet and buffer management is fine-tuned to optimize networking performance for embedded devices, where memory and processing power are constrained and can lead to dropped packets, increased retransmissions, and degraded communication efficiency. The configuration sets <code>CONFIG_NET_BUF_RX_COUNT=64</code> and <code>CONFIG_NET_BUF_TX_COUNT=64</code>, ensuring that sufficient buffers are allocated for incoming and outgoing network packets to reduce packet loss and improve transmission reliability. Similarly, <code>CONFIG_NET_PKT_RX_COUNT=32</code> and <code>CONFIG_NET_PKT_TX_COUNT=32</code> define the number of packet descriptors available for processing network traffic, balancing memory usage and network performance. The dedicated memory allocations for networking tasks <code>CONFIG_NET_RX_STACK_SIZE=2048</code> and <code>CONFIG_NET_TX_STACK_SIZE=2048</code>, further improve the responsiveness and stability of the system in handling concurrent network operations. Additionally, <code>CONFIG_NET_MAX_CONTEXTS=10</code> ensures that multiple networking contexts can be managed concurrently, allowing seamless handling of multiple network sockets, connections, or protocols.</p> <p>A key aspect of connectivity in the embedded proplet is the integration of MQTT for message-based communication. The configuration enables the MQTT library and socket support for seamless data exchange between Propeller nodes and the orchestrator. The MQTT client is configured to maintain session state and use a keep-alive mechanism to ensure continuous connectivity.</p> <p>To enhance reliability, the embedded proplet supports the Last Will and Testament (LWT) feature of MQTT. The feature ensures that in the event of an unexpected disconnection of the embedded proplet, a predefined message is sent to the broker, notifying the Manager of the disconnection event. Additionally, the embedded proplet leverages Quality of Service (QoS) levels to provide varying degrees of message reliability, ensuring that critical messages are received without duplication or loss. The configuration also allows for adaptive reconnection strategies, ensuring that embedded proplets can re-establish connections in case of temporary network disruptions.</p> <p>For debugging and diagnostics, the configuration enables logging with a default logging level of 3. This provides useful insights into networking operations without excessive verbosity. The system also supports early console output (<code>CONFIG_EARLY_CONSOLE=y</code>) and network statistics tracking (<code>CONFIG_NET_STATISTICS=y</code>), allowing developers to monitor network performance and diagnose potential issues efficiently.</p> <ul> <li>WASM Handler : Interfaces with WAMR to load, execute, and manage WASM modules on the embedded device, enforcing isolation and resource constraints.</li> <li>Configuration and Build System: Defines system parameters, dependencies, and build instructions to streamline deployment on Zephyr OS.</li> <li>Data Serialization: Handles encoding and decoding of structured data in JSON format for efficient message parsing within the Propeller network.</li> </ul>"},{"location":"embedded-proplet/#setup","title":"Setup","text":"<p>When running:</p> <pre><code>west build -b esp32s3_devkitc/esp32s3/procpu -p auto .\n</code></pre> <p>CMake might stop with:</p> <pre><code>Could NOT find Threads (missing: Threads_FOUND)\n...\nFATAL ERROR: command exited with status 1: ...\n</code></pre> <p>This is triggered by WAMR\u2019s top-level <code>CMakeLists.txt</code> in <code>wasm-micro-runtime/</code>, specifically the lines:</p> <pre><code>set (THREADS_PREFER_PTHREAD_FLAG ON)\nfind_package(Threads REQUIRED)\n</code></pre> <p>because <code>WAMR</code> tries to detect and link <code>pthread</code> on the <code>host</code> system (Linux, Windows, macOS).</p> <ul> <li>However, on <code>Zephyr</code>, especially for an <code>ESP32-S3</code> target, we do not use the host\u2019s pthread library at all. There\u2019s no concept of a local Linux \u201cThreads\u201d library in a cross-compile for an Xtensa SoC.</li> <li>So CMake\u2019s <code>find_package(Threads REQUIRED)</code> fails with \u201cCould NOT find Threads\u201d because there\u2019s no suitable host pthread dev package to fulfill that requirement in the cross-compilation environment.</li> </ul> <p>Installing host pthread dev files sometimes helps in a purely local scenario, but it can still fail or is semantically incorrect for embedded cross-builds.</p> <p>The Solution is to bypass <code>find_package(Threads REQUIRED)</code> on Zephyr. So, in your WAMR repo file <code>wasm-micro-runtime/CMakeLists.txt</code>, locate where it calls:</p> <pre><code>find_package(Threads REQUIRED)\n</code></pre> <p>and wrap that call in a conditional so it does not run on Zephyr:</p> <pre><code>if (NOT WAMR_BUILD_PLATFORM STREQUAL \"zephyr\")\n  set (THREADS_PREFER_PTHREAD_FLAG ON)\n  find_package(Threads REQUIRED)\nendif()\n</code></pre> <p>then clean and rebuild:</p> <pre><code>rm -rf build\nwest build -b esp32s3_devkitc/esp32s3/procpu -p auto .\n</code></pre>"},{"location":"embedded-proplet/#dynamic-linking","title":"Dynamic Linking","text":"<p>Zephyr does not support dynamic linking on most embedded targets (including ESP32-S3). When WAMR\u2019s CMakeLists tries:</p> <pre><code>add_library(iwasm_shared SHARED ...)\n</code></pre> <p>you see the warning:</p> <pre><code>ADD_LIBRARY called with SHARED option but the target platform does not support\ndynamic linking. Building a STATIC library instead. This may lead to problems.\n</code></pre> <p>This is harmless on Zephyr\u2014it just forces the shared library to become a static library\u2014but it can be confusing. To fix it, you should skip building a shared library entirely when you are on Zephyr.</p> <p>In your <code>modules/wamr/wasm-micro-runtime/CMakeLists.txt</code>, right after you set <code>WAMR_BUILD_PLATFORM=\"zephyr\"</code>, force shared libs off:</p> <pre><code>if (WAMR_BUILD_PLATFORM STREQUAL \"zephyr\")\n  set(WAMR_BUILD_SHARED 0 CACHE BOOL \"Disable shared library on Zephyr\" FORCE)\nendif ()\n</code></pre> <p>If that\u2019s in place, the <code>if (WAMR_BUILD_SHARED)</code> block that calls:</p> <pre><code>add_library (iwasm_shared SHARED ${WAMR_RUNTIME_LIB_SOURCE})\n...\n</code></pre> <p>will not run. Hence, no \u201cshared library\u201d warning on Zephyr.</p> <p>Alternatively, you can guard the <code>iwasm_shared</code> block with:</p> <pre><code># SHARED LIBRARY\nif (WAMR_BUILD_SHARED AND NOT WAMR_BUILD_PLATFORM STREQUAL \"zephyr\")\n    add_library (iwasm_shared SHARED ${WAMR_RUNTIME_LIB_SOURCE})\n    ...\nendif ()\n</code></pre> <p>That way, the shared library part is skipped on Zephyr.</p> <p>Either approach ensures the warning disappears, and you end up only with a static WAMR build (<code>iwasm_static</code>) on Zephyr, which is what you actually need.</p>"},{"location":"embedded-proplet/#configuration-files","title":"Configuration Files","text":"<p>Configuration options are split between <code>prj.conf</code> and <code>esp32s3-devkitc.conf</code>, which Zephyr's build system merges based on the board and build target. Follow best practices to avoid conflicting settings.</p>"},{"location":"embedded-proplet/#purpose-of-each-file","title":"Purpose of Each File","text":"<ol> <li> <p><code>prj.conf</code>:</p> </li> <li> <p>Application-specific settings.</p> </li> <li> <p>Defines project-specific features, libraries, and behaviors.</p> </li> <li> <p><code>esp32s3-devkitc.conf</code>:</p> </li> <li> <p>Board-specific settings.</p> </li> <li> <p>Configures hardware-specific options for the ESP32-S3.</p> </li> <li> <p><code>esp32s3-devkitc.overlay</code>:</p> </li> <li>Extends or modifies the board's Devicetree source.</li> </ol>"},{"location":"embedded-proplet/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<p>Zephyr processes files in this order:</p> <ol> <li>Default Kconfig files: Zephyr subsystems and modules.</li> <li>Board files: <code>esp32s3-devkitc.conf</code> overrides defaults.</li> <li>Application files: <code>prj.conf</code> overrides earlier settings.</li> </ol> <p>If a setting appears in both <code>prj.conf</code> and <code>esp32s3-devkitc.conf</code>, the value in <code>prj.conf</code> takes precedence. Avoid duplicate definitions to prevent conflicts.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Before proceeding, install the following prerequisites:</p> <ul> <li>A Go compiler (Go 1.24 or later)</li> <li>Make</li> <li>Docker</li> <li>Wasmtime</li> <li>TinyGo</li> <li>Mosquitto Tools</li> </ul>"},{"location":"getting-started/#clone-the-repository","title":"Clone the repository","text":"<p>Clone the repository</p> <pre><code>git clone https://github.com/absmach/propeller.git\ncd propeller\n</code></pre>"},{"location":"getting-started/#build-and-install-the-artifacts","title":"Build and Install the artifacts","text":"<p>Build and install the artifacts</p> <pre><code>make all\nmake install\n</code></pre> <p>The output of the build command will be something like:</p> <pre><code>CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags \"-s -w -X 'github.com/absmach/supermq.BuildTime=2025-06-12T10:57:04Z' -X 'github.com/absmach/supermq.Version=v0.3.0' -X 'github.com/absmach/supermq.Commit=26ef8cb167a4f88359e55eb9916cdca232bde39c'\" -o build/manager cmd/manager/main.go\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags \"-s -w -X 'github.com/absmach/supermq.BuildTime=2025-06-12T10:57:07Z' -X 'github.com/absmach/supermq.Version=v0.3.0' -X 'github.com/absmach/supermq.Commit=26ef8cb167a4f88359e55eb9916cdca232bde39c'\" -o build/proplet cmd/proplet/main.go\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags \"-s -w -X 'github.com/absmach/supermq.BuildTime=2025-06-12T10:57:07Z' -X 'github.com/absmach/supermq.Version=v0.3.0' -X 'github.com/absmach/supermq.Commit=26ef8cb167a4f88359e55eb9916cdca232bde39c'\" -o build/cli cmd/cli/main.go\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags \"-s -w -X 'github.com/absmach/supermq.BuildTime=2025-06-12T10:57:08Z' -X 'github.com/absmach/supermq.Version=v0.3.0' -X 'github.com/absmach/supermq.Commit=26ef8cb167a4f88359e55eb9916cdca232bde39c'\" -o build/proxy cmd/proxy/main.go\nGOOS=js GOARCH=wasm tinygo build -no-debug -panic=trap -scheduler=none -gc=leaking -o build/addition.wasm -target wasi examples/addition/addition.go\nGOOS=js GOARCH=wasm tinygo build -no-debug -panic=trap -scheduler=none -gc=leaking -o build/compute.wasm -target wasi examples/compute/compute.go\nGOOS=js GOARCH=wasm tinygo build -no-debug -panic=trap -scheduler=none -gc=leaking -o build/hello-world.wasm -target wasi examples/hello-world/hello-world.go\n</code></pre> <p>Installing the artifacts will install Propeller to the <code>GOBIN</code> directory. That is:</p> <pre><code>cp build/cli $GOBIN/propeller-cli\\\ncp build/manager $GOBIN/propeller-manager\\\ncp build/proplet $GOBIN/propeller-proplet\\\ncp build/proxy $GOBIN/propeller-proxy\n</code></pre>"},{"location":"getting-started/#start-docker-composition","title":"Start Docker composition","text":"<p>Start docker composition</p> <pre><code>cd propeller\nmake start-supermq\n</code></pre> <p>To install the SuperMQ CLI, follow the instructions.</p>"},{"location":"getting-started/#provision-supermq","title":"Provision SuperMQ","text":"<p>In order for propeller to work, we need to provision SuperMQ. This will:</p> <ul> <li>Login the user with there credentials. If they are not registered, they will need to login using the supermq-cli or curl or the web interface. This will require you to have supermq-cli installed.</li> <li>Create a domain</li> <li>Login that user to the domain</li> <li>Create a manager client</li> <li>Create a proplet client</li> <li>Create a manager channel</li> <li>Connect the manager client to the manager channel</li> <li>Connect the proplet client to the manager channel</li> </ul> <p>This can be done using the following command:</p> <pre><code>propeller-cli provision\n</code></pre> <p>The process will look something like this:</p> <p></p> <p>This will output a response like the following</p> <pre><code>Successfully created config.toml file\n</code></pre> <p>The <code>config.toml</code> file will be created in the current directory. This file contains the credentials for the user, domain, manager client, proplet client, and manager channel. It will look something like this:</p> <pre><code># SuperMQ Configuration\n\n[manager]\ndomain_id = \"182c0907-002c-4bfd-8bf3-e4f40c58dde6\"\nclient_id = \"f2fe9a33-144a-4346-a5d6-38e2eb07815e\"\nclient_key = \"ef7da52b-c01f-4b62-9502-6723d639405b\"\nchannel_id = \"8c6e1e6c-fc89-43b4-b00b-884a690c7419\"\n\n[proplet]\ndomain_id = \"182c0907-002c-4bfd-8bf3-e4f40c58dde6\"\nclient_id = \"fa407362-9c5f-41b8-9a09-9d0c0b039287\"\nclient_key = \"991c4d03-2f2c-4ba5-97a6-45bead85457e\"\nchannel_id = \"8c6e1e6c-fc89-43b4-b00b-884a690c7419\"\n\n[proxy]\ndomain_id = \"182c0907-002c-4bfd-8bf3-e4f40c58dde6\"\nclient_id = \"fa407362-9c5f-41b8-9a09-9d0c0b039287\"\nclient_key = \"991c4d03-2f2c-4ba5-97a6-45bead85457e\"\nchannel_id = \"8c6e1e6c-fc89-43b4-b00b-884a690c7419\"\n</code></pre>"},{"location":"getting-started/#start-the-manager","title":"Start the manager","text":"<p>To start the manager, run the following command</p> <pre><code>propeller-manager\n</code></pre> <p>The logs from the manager will look something like this:</p> <pre><code>{\"time\":\"2025-06-12T14:13:56.74162598+03:00\",\"level\":\"INFO\",\"msg\":\"MQTT connection lost\"}\n{\"time\":\"2025-06-12T14:13:56.793894993+03:00\",\"level\":\"INFO\",\"msg\":\"Subscribe to MQTT topic completed successfully\",\"duration\":\"52.272009ms\"}\n{\"time\":\"2025-06-12T14:13:56.794210043+03:00\",\"level\":\"INFO\",\"msg\":\"manager service http server listening at localhost:7070 without TLS\"}\n</code></pre>"},{"location":"getting-started/#start-the-proplet","title":"Start the proplet","text":"<p>To start the proplet, run the following command</p> <pre><code>propeller-proplet\n</code></pre> <p>The logs from the proplet will look something like this:</p> <pre><code>{\"time\":\"2025-06-12T14:14:44.362072799+03:00\",\"level\":\"INFO\",\"msg\":\"MQTT connection lost\"}\n{\"time\":\"2025-06-12T14:14:44.398147897+03:00\",\"level\":\"INFO\",\"msg\":\"Proplet service is running.\"}\n</code></pre> <p>This will create a proplet automatically on the manager's side.</p>"},{"location":"getting-started/#start-the-proxy","title":"Start the proxy","text":"<p>To start the proxy, run the following command</p> <pre><code>export PROXY_REGISTRY_URL=\"docker.io\"\nexport PROXY_AUTHENTICATE=\"TRUE\"\nexport PROXY_REGISTRY_USERNAME=\"\"\nexport PROXY_REGISTRY_PASSWORD=\"\"\npropeller-proxy\n</code></pre> <p>The logs from the proxy will look something like this:</p> <pre><code>{\"time\":\"2025-06-12T14:15:18.438848211+03:00\",\"level\":\"INFO\",\"msg\":\"MQTT connection lost\"}\n{\"time\":\"2025-06-12T14:15:18.438823293+03:00\",\"level\":\"INFO\",\"msg\":\"successfully initialized MQTT and HTTP config\"}\n{\"time\":\"2025-06-12T14:15:18.438886395+03:00\",\"level\":\"INFO\",\"msg\":\"starting proxy service\"}\n{\"time\":\"2025-06-12T14:15:18.452592155+03:00\",\"level\":\"INFO\",\"msg\":\"successfully subscribed to topic\"}\n</code></pre>"},{"location":"getting-started/#postman-colletion","title":"Postman Colletion","text":"<p>This is a collection of the API calls that can be used to interact with the Propeller system.</p>"},{"location":"getting-started/#api","title":"API","text":""},{"location":"getting-started/#list-proplets","title":"List Proplets","text":"<pre><code>curl -X GET \"http://localhost:7070/proplets\"\n</code></pre> <p>This will output a response like the following</p> <pre><code>{\n  \"offset\": 0,\n  \"limit\": 100,\n  \"total\": 1,\n  \"proplets\": [\n    {\n      \"id\": \"fa407362-9c5f-41b8-9a09-9d0c0b039287\",\n      \"name\": \"Wojahn-Omohundro\",\n      \"task_count\": 1,\n      \"alive\": true,\n      \"alive_history\": [\n        \"2025-06-12T14:22:04.379038459+03:00\",\n        \"2025-06-12T14:22:14.378443596+03:00\",\n        \"2025-06-12T14:22:24.379305586+03:00\",\n        \"2025-06-12T14:22:34.378765631+03:00\",\n        \"2025-06-12T14:22:44.381274342+03:00\",\n        \"2025-06-12T14:22:54.378152057+03:00\",\n        \"2025-06-12T14:23:04.380171407+03:00\",\n        \"2025-06-12T14:23:14.379503767+03:00\",\n        \"2025-06-12T14:23:24.379971214+03:00\",\n        \"2025-06-12T14:23:34.378886406+03:00\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"getting-started/#create-task","title":"Create task","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"name\": \"add\", \"inputs\": [10, 20]}'\n</code></pre> <p>This will output a response like the following</p> <pre><code>{\n  \"id\": \"e9858e56-a1dd-4e5a-9288-130f7be783ed\",\n  \"name\": \"add\",\n  \"state\": 0,\n  \"cli_args\": null,\n  \"inputs\": [10, 20],\n  \"start_time\": \"0001-01-01T00:00:00Z\",\n  \"finish_time\": \"0001-01-01T00:00:00Z\",\n  \"created_at\": \"2025-06-12T14:25:22.407167091+03:00\",\n  \"updated_at\": \"0001-01-01T00:00:00Z\"\n}\n</code></pre>"},{"location":"getting-started/#get-a-task","title":"Get a task","text":"<pre><code>curl -X GET \"http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed\"\n</code></pre> <p>This will output a response like the following</p> <pre><code>{\n  \"id\": \"e9858e56-a1dd-4e5a-9288-130f7be783ed\",\n  \"name\": \"add\",\n  \"state\": 0,\n  \"cli_args\": null,\n  \"inputs\": [10, 20],\n  \"start_time\": \"0001-01-01T00:00:00Z\",\n  \"finish_time\": \"0001-01-01T00:00:00Z\",\n  \"created_at\": \"2025-06-12T14:25:22.407167091+03:00\",\n  \"updated_at\": \"0001-01-01T00:00:00Z\"\n}\n</code></pre>"},{"location":"getting-started/#upload-wasm-file","title":"Upload Wasm File","text":"<pre><code>curl -X PUT \"http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed/upload\" \\\n-F 'file=@&lt;propeller_path&gt;/build/addition.wasm'\n</code></pre>"},{"location":"getting-started/#start-a-task","title":"Start a task","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed/start\"\n</code></pre>"},{"location":"getting-started/#stop-a-task","title":"Stop a task","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed/stop\"\n</code></pre>"},{"location":"getting-started/#creating-tasks-from-oci-registry-images","title":"Creating Tasks from OCI Registry Images","text":"<p>For WebAssembly modules stored in an OCI registry, you can specify the image URL during task creation. The proxy will automatically retrieve the WASM file from the registry when the task starts, eliminating the need for manual file uploads.</p> <pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"name\": \"add\", \"inputs\": [10, 20], \"image_url\": \"docker.io/mrstevenyaga/add.wasm\"}'\n</code></pre> <p>The proxy will handle pulling the image from the specified OCI registry during task execution, streamlining the deployment process.</p>"},{"location":"manager/","title":"Manager","text":""},{"location":"manager/#overview","title":"Overview","text":"<p>The Manager service is a central component of the Propeller system, responsible for managing tasks and proplets. It provides a set of APIs for task and proplet management, handles task scheduling and execution, and monitors the state of tasks and proplets. The architecture of the Manager service is designed to be modular, scalable, and maintainable, leveraging various components and middleware to achieve these goals.</p>"},{"location":"manager/#architectural-components","title":"Architectural Components","text":""},{"location":"manager/#1-service-interface","title":"1. Service Interface","text":"<p>The <code>Service</code> interface defines the core functionalities provided by the Manager service. It includes methods for managing proplets and tasks, as well as for subscribing to MQTT topics. This interface ensures that the service can be easily extended or replaced with different implementations.</p>"},{"location":"manager/#2-api-endpoints","title":"2. API Endpoints","text":"<p>The Manager service exposes several HTTP endpoints for interacting with tasks and proplets. These endpoints are implemented using the Go-Kit library, which provides a structured way to define and handle HTTP requests and responses.</p>"},{"location":"manager/#3-middleware","title":"3. Middleware","text":"<p>The Manager service includes several middleware components that enhance its functionality:</p> <ul> <li>Logging Middleware: Logs the details of each service method call, including the duration and any errors that occurred.</li> <li>Metrics Middleware: Collects metrics for each service method call, such as the number of calls and the latency.</li> <li>Tracing Middleware: Adds tracing information to each service method call, using OpenTelemetry to provide distributed tracing capabilities.</li> </ul>"},{"location":"manager/#4-storage","title":"4. Storage","text":"<p>The Manager service uses storage components to persist tasks and proplets. These storage components are abstracted behind interfaces, allowing for different storage implementations (e.g., in-memory, database) to be used interchangeably. The storage components include:</p> <ul> <li>Tasks Storage: Stores task details.</li> <li>Proplets Storage: Stores proplet details.</li> <li>Task-Proplet Mapping Storage: Stores the mapping between tasks and proplets.</li> </ul>"},{"location":"manager/#5-scheduler","title":"5. Scheduler","text":"<p>The Manager service uses a scheduler to select the appropriate proplet for a task based on certain criteria. The scheduler is responsible for distributing tasks across available proplets in an efficient manner, ensuring optimal resource utilization. The current implementation uses a round-robin scheduler, which selects the next available proplet in a cyclic manner.</p>"},{"location":"manager/#6-pubsub","title":"6. PubSub","text":"<p>The Manager service uses a PubSub component to publish and subscribe to MQTT topics for task and proplet management. This component allows the service to communicate with other components of the Propeller system, such as proplets, to coordinate task execution and monitor their state.</p>"},{"location":"manager/#7-internal-handlers","title":"7. Internal Handlers","text":"<p>The Manager service includes internal handlers for managing proplets and tasks. These handlers are responsible for processing messages received from MQTT topics and updating the state of tasks and proplets accordingly. The handlers include:</p> <ul> <li>Proplet Handlers: Handle the creation, liveness updates, and result updates of proplets.</li> <li>Task Handlers: Handle the creation, updating, and deletion of tasks.</li> </ul>"},{"location":"manager/#8-health-and-metrics-endpoints","title":"8. Health and Metrics Endpoints","text":"<p>The Manager service includes endpoints for health checks and metrics collection:</p> <ul> <li>Health Endpoint: Provides a health check endpoint (<code>/health</code>) that returns the health status of the service.</li> <li>Metrics Endpoint: Provides a metrics endpoint (<code>/metrics</code>) that exposes Prometheus metrics for the service.</li> </ul>"},{"location":"manager/#data-flow","title":"Data Flow","text":""},{"location":"manager/#1-task-creation","title":"1. Task Creation","text":"<ul> <li>A client sends a <code>POST</code> request to the <code>/tasks</code> endpoint with the task details.</li> <li>The service creates a new task, assigns a unique ID, and stores it in the tasks storage.</li> <li>The service returns the created task to the client.</li> </ul>"},{"location":"manager/#2-task-execution","title":"2. Task Execution","text":"<ul> <li>A client sends a <code>POST</code> request to the <code>/tasks/{taskID}/start</code> endpoint to start a task.</li> <li>The service retrieves the task from the tasks storage and selects an appropriate proplet using the scheduler.</li> <li>The task can also specify which proplet to use.</li> <li>The service publishes a start message to the MQTT topic for the selected proplet.</li> <li>The proplet executes the task and publishes the results to the MQTT topic.</li> <li>The service processes the results and updates the task state in the tasks storage.</li> </ul>"},{"location":"manager/#3-proplet-management","title":"3. Proplet Management","text":"<ul> <li>Proplets periodically send liveness updates to the MQTT topic.</li> <li>The service processes the liveness updates and updates the state of the proplets in the proplets storage.</li> <li>The service can also handle the creation of new proplets and the updating of proplet details.</li> </ul>"},{"location":"proplet/","title":"Proplet","text":"<p>The <code>proplet</code> is a worker that executes WebAssembly functions. It can be configured to use either the embedded <code>wazero</code> runtime or an external WebAssembly runtime on the host system.</p>"},{"location":"proplet/#configuration","title":"Configuration","text":"<p>The <code>proplet</code> is configured using environment variables.</p> Environment Variable Description Default <code>PROPLET_LOG_LEVEL</code> Log level (e.g., <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>) <code>info</code> <code>PROPLET_INSTANCE_ID</code> A unique ID for this proplet instance. A new UUID <code>PROPLET_MQTT_ADDRESS</code> The address of the MQTT broker. <code>tcp://localhost:1883</code> <code>PROPLET_MQTT_TIMEOUT</code> The timeout for MQTT operations. <code>30s</code> <code>PROPLET_MQTT_QOS</code> The Quality of Service level for MQTT messages. <code>2</code> <code>PROPLET_LIVELINESS_INTERVAL</code> The interval at which the proplet sends liveliness messages. <code>10s</code> <code>PROPLET_DOMAIN_ID</code> The domain ID for this proplet. <code>PROPLET_CHANNEL_ID</code> The channel ID for this proplet. <code>PROPLET_CLIENT_ID</code> The client ID for MQTT authentication. <code>PROPLET_CLIENT_KEY</code> The client key for MQTT authentication. <code>PROPLET_EXTERNAL_WASM_RUNTIME</code> The path to an external WebAssembly runtime. If not set, the embedded <code>wazero</code> runtime will be used. <code>\"\"</code> (empty string)"},{"location":"proplet/#usage","title":"Usage","text":""},{"location":"proplet/#using-the-embedded-wazero-runtime","title":"Using the Embedded <code>wazero</code> Runtime","text":"<p>By default, <code>proplet</code> uses the embedded <code>wazero</code> runtime. To run it, simply set the required environment variables and start the application:</p> <pre><code>export PROPLET_DOMAIN_ID=\"your_domain_id\"\nexport PROPLET_CHANNEL_ID=\"your_channel_id\"\nexport PROPLET_CLIENT_ID=\"your_client_id\"\nexport PROPLET_CLIENT_KEY=\"your_client_key\"\npropeller-proplet\n</code></pre>"},{"location":"proplet/#using-a-host-webassembly-runtime","title":"Using a Host WebAssembly Runtime","text":"<p>To use an external WebAssembly runtime (e.g., <code>wasmtime</code>, <code>wasmer</code>), set the <code>PROPLET_EXTERNAL_WASM_RUNTIME</code> environment variable to the path of the runtime executable.</p> <p>For example, to use <code>wasmtime</code>:</p> <pre><code>export PROPLET_DOMAIN_ID=\"your_domain_id\"\nexport PROPLET_CHANNEL_ID=\"your_channel_id\"\nexport PROPLET_CLIENT_ID=\"your_client_id\"\nexport PROPLET_CLIENT_KEY=\"your_client_key\"\nexport PROPLET_EXTERNAL_WASM_RUNTIME=\"/usr/bin/wasmtime\"\nPROPLET_EXTERNAL_WASM_RUNTIME=wasmtime propeller-proplet\n</code></pre> <p>You will also need to provide cli arguments to the task so that the runtime can be started. For example, to run the <code>addition</code> example with <code>wasmtime</code>:</p> <pre><code>wasmtime --invoke add /home/rodneyosodo/code/absmach/propeller/db3d44e8-6e27-464a-aaeb-e643ec298dff.wasm 10 20\n</code></pre> <p>Hence the cli aguments are <code>--invoke</code> and <code>add</code> and the path to the wasm file. The task will then be created as follows:</p> <pre><code>{\n  \"name\": \"add\",\n  \"cli_args\": [\"--invoke\", \"add\"],\n  \"inputs\": [10, 20]\n}\n</code></pre>"},{"location":"proplet/#proplet-command-handling","title":"Proplet Command Handling","text":""},{"location":"proplet/#start-command-flow","title":"Start Command Flow","text":"<p>The start command is sent by the Manager to the Proplet on the topic <code>m/:domain_id/c/:channel_id/control/manager/start</code></p>"},{"location":"proplet/#1-parse-the-start-command","title":"1. Parse the Start Command","text":"<p>The MQTT message payload is unmarshaled into a <code>StartRequest</code> structure containing the <code>AppName</code> and any required parameters for the application. If the payload is invalid or <code>AppName</code> is missing, an error is logged, and no further action is taken.</p>"},{"location":"proplet/#2-publish-a-fetch-request","title":"2. Publish a Fetch Request","text":"<p>A fetch request is sent to the Registry Proxy to retrieve the WebAssembly (Wasm) binary chunks for the specified application. This request is published to the topic <code>m/:domain_id/c/:channel_id/registry/proplet</code>.</p>"},{"location":"proplet/#3-wait-for-wasm-binary-chunks","title":"3. Wait for Wasm Binary Chunks","text":"<p>The system monitors the reception of Wasm chunks from the Registry Proxy, which are published to the topic <code>m/:domain_id/c/:channel_id/registry/server</code> and processed by the <code>handleChunk</code> function.</p>"},{"location":"proplet/#4-assemble-and-validate-chunks","title":"4. Assemble and Validate Chunks","text":"<p>Once all chunks are received, as determined by comparing the number of received chunks to the <code>TotalChunks</code> field in the chunk metadata, the chunks are assembled into a complete Wasm binary and validated to ensure integrity.</p>"},{"location":"proplet/#5-deploy-and-run-the-application","title":"5. Deploy and Run the Application","text":"<p>The assembled Wasm binary is passed to the Wazero runtime for instantiation and execution, where the specified function (e.g., <code>main</code>) in the Wasm module is invoked.</p>"},{"location":"proplet/#runtime-functions-startapp","title":"Runtime Functions: StartApp","text":"<p>The <code>StartApp</code> function in <code>runtime.go</code> handles the instantiation and execution of Wasm modules. It:</p> <ol> <li>Validate Input Parameters: Ensures <code>appName</code>, <code>wasmBinary</code>, and <code>functionName</code> are provided and valid. Errors are returned if any parameter is missing or invalid.</li> <li>Acquire Mutex Lock: Locks the runtime to ensure thread-safe access to the <code>modules</code> map.</li> <li>Check for Existing App Instance: Verifies if the app is already running. If found, an error is returned to prevent duplicate instances.</li> <li>Instantiate the Wasm Module: Passes the <code>wasmBinary</code> to the Wazero runtime's <code>Instantiate</code> method to create a Wasm module.</li> <li>Retrieve the Exported Function: Locates the <code>functionName</code> in the module. If the function is missing, the module is closed, and an error is returned.</li> <li>Store the Module in the Runtime: Saves the instantiated module in the <code>modules</code> map for tracking running applications.</li> <li>Release Mutex Lock: Unlocks the runtime after the module is added to the map.</li> <li>Return the Exported Function: Returns the Wasm function for execution.</li> </ol>"},{"location":"proplet/#6-log-success-or-errors","title":"6. Log Success or Errors","text":"<p>A success message is logged if the application starts successfully, while detailed errors are logged if any step in the process (e.g., chunk assembly, instantiation, or execution) fails.</p>"},{"location":"proplet/#stop-command-flow","title":"Stop Command Flow","text":"<p>The stop command is sent by the Manager to the Proplet on the topic <code>m/:domain_id/c/:channel_id/control/manager/stop</code></p>"},{"location":"proplet/#1-parse-the-stop-command","title":"1. Parse the Stop Command","text":"<p>The MQTT message payload is unmarshaled into a <code>StopRequest</code> structure containing the <code>AppName</code> of the application to stop. If the payload is invalid or <code>AppName</code> is missing, an error is logged, and no further action is taken.</p>"},{"location":"proplet/#2-stop-the-application","title":"2. Stop the Application","text":"<p>The <code>StopApp</code> method in the Wazero runtime is invoked, which checks if the application is running, closes the corresponding Wasm module, and removes the application from the runtime's internal tracking.</p>"},{"location":"proplet/#runtime-functions-stopapp","title":"Runtime Functions: StopApp","text":"<p>The <code>StopApp</code> function in <code>runtime.go</code> stops and cleans up a running Wasm module. It:</p> <ol> <li>Validate Input Parameters: Checks if <code>appName</code> is provided. If missing, an error is returned.</li> <li>Acquire Mutex Lock: Locks the runtime to ensure thread-safe access to the <code>modules</code> map.</li> <li>Check for Running App: Looks up the app in the <code>modules</code> map. If the app is not found, an error is returned.</li> <li>Close the Wasm Module: Calls the module's <code>Close</code> method to release all resources associated with the app. If closing fails, an error is logged and returned.</li> <li>Remove the App from Runtime: Deletes the app entry from the <code>modules</code> map to update the runtime's state.</li> <li>Release Mutex Lock: Unlocks the runtime after the app has been removed from the map.</li> </ol>"},{"location":"proplet/#3-log-success-or-errors","title":"3. Log Success or Errors","text":"<p>A success message is logged with the text <code>\"App '&lt;AppName&gt;' stopped successfully.\"</code> if the application stops successfully. If the application is not running or an error occurs during the stop operation, detailed error information is logged.</p> <p>The Manager knows which Proplet is on which channel through the following mechanisms:</p> <ol> <li>Startup Notification (<code>create</code> topic):</li> </ol> <p>When a Proplet starts, it publishes a message on the topic:</p> <p><code>bash    m/:domain_id/c/:manager_channel_id/messages/control/proplet/create</code></p> <p>The payload of this message includes the <code>PropletID</code> and <code>ChannelID</code>, notifying the Manager about the mapping of Proplet IDs to their respective channels:</p> <p><code>json    {      \"PropletID\": \"{PropletID}\",      \"ChanID\": \"{ChannelID}\"    }</code></p> <ol> <li>Liveliness Updates (<code>alive</code> topic):</li> </ol> <p>To ensure that the Proplet is still active, it periodically publishes messages on the topic:</p> <p><code>bash    m/:domain_id/c/:manager_channel_id/messages/control/proplet/alive</code></p> <p>The payload contains the same <code>PropletID</code> and <code>ChannelID</code> information. This helps the Manager maintain an updated map of active Proplets and their channels:</p> <p><code>json    {      \"status\": \"alive\",      \"PropletID\": \"{PropletID}\",      \"ChanID\": \"{ChannelID}\"    }</code></p> <ol> <li>Last Will &amp; Testament (LWT):</li> </ol> <p>If the Proplet goes offline unexpectedly, the MQTT broker automatically publishes a message on the same <code>alive</code> topic with a payload indicating the Proplet's offline status:</p> <p><code>json    {      \"status\": \"offline\",      \"PropletID\": \"{PropletID}\",      \"ChanID\": \"{ChannelID}\"    }</code></p> <p>These mechanisms ensure that the Manager is always aware of the active Proplets and their corresponding channels. The Manager can utilize this data to send specific control commands or monitor the Proplets effectively.</p>"},{"location":"proplet/#registry-workflow","title":"Registry Workflow","text":"<ol> <li> <p>Proplet Fetches Wasm Binary:</p> </li> <li> <p>Publishes a fetch request on the <code>proplet</code> topic.</p> </li> <li> <p>Waits for chunks on the <code>server</code> topic.</p> </li> <li> <p>Proplet Handles Registry Updates:</p> </li> <li>Subscribes to the <code>updateRegistry</code> topic.</li> <li>Updates the registry configuration upon receiving a valid payload.</li> <li>Publishes the status (success or failure) to the <code>registry</code> topic.</li> </ol>"},{"location":"proplet/#1-fetch-request","title":"1. Fetch Request","text":"<p>The Proplet uses this topic to request Wasm binary chunks for a specific application from the Registry Proxy.</p> <ul> <li>Topic:</li> </ul> <p><code>bash   m/:domain_id/c/:channel_id/registry/proplet</code></p> <ul> <li>Payload is a JSON object containing the name of the application (<code>app_name</code>) for which the WebAssembly (Wasm) binary chunks are requested:</li> </ul> <p><code>json   {     \"app_name\": \"{AppName}\"   }</code></p>"},{"location":"proplet/#2-image-chunks-delivery","title":"2. Image Chunks Delivery","text":"<p>The Registry Proxy publishes Wasm binary chunks to this topic for the Proplet to assemble into a complete binary. The Proplet monitors this topic to receive the chunks sequentially.</p> <ul> <li>Topic:</li> </ul> <p><code>bash   m/:domain_id/c/:channel_id/registry/server</code></p> <ul> <li>Payload is a JSON object representing a single chunk of the requested Wasm binary:</li> </ul> <p><code>json   {     \"app_name\": \"{AppName}\",     \"chunk_idx\": {ChunkIndex},     \"total_chunks\": {TotalChunks},     \"data\": \"{Base64EncodedChunkData}\"   }</code></p>"},{"location":"proplet/#3-registry-configuration-update","title":"3. Registry Configuration Update","text":"<ul> <li>Allows the Manager to update the Proplet's registry configuration dynamically.</li> </ul> <p><code>bash   m/:domain_id/c/:channel_id/control/manager/updateRegistry</code></p> <ul> <li>Payload is a JSON object containing the new registry URL and token for updating the Proplet's registry configuration:</li> </ul> <p><code>json   {     \"registry_url\": \"{NewRegistryURL}\",     \"registry_token\": \"{NewRegistryToken}\"   }</code></p>"},{"location":"proplet/#4-acknowledgment-for-registry-updates","title":"4. Acknowledgment for Registry Updates","text":"<ul> <li>The Proplet uses this topic to acknowledge whether the registry configuration update was successful or failed.</li> </ul> <p><code>bash   m/:domain_id/c/:channel_id/control/manager/registry</code></p> <ul> <li> <p>Payload is a JSON object indicating the success or failure of a registry update:</p> </li> <li> <p>Success:</p> <p><code>json {   \"status\": \"success\" }</code></p> </li> <li> <p>Failure:</p> <p><code>json {   \"status\": \"failure\",   \"error\": \"{ErrorMessage}\" }</code></p> </li> </ul>"},{"location":"proxy/","title":"Proxy Service","text":"<p>The Proxy Service acts as a bridge between MQTT and HTTP protocols in the Propeller system. It enables bidirectional communication between MQTT clients and HTTP endpoints, allowing for seamless integration of different protocols. The proxy service is responsible for fetching WebAssembly modules from an OCI-compliant registry, chunking them, and publishing them over MQTT for <code>proplet</code> instances to consume.</p>"},{"location":"proxy/#overview","title":"Overview","text":"<p>The proxy service performs two main functions:</p> <ol> <li>Subscribes to MQTT topics and forwards messages to HTTP endpoints</li> <li>Streams data between MQTT and HTTP protocols</li> </ol>"},{"location":"proxy/#usage","title":"Usage","text":"<p>To use the proxy service, you need to set the required environment variables and run the <code>main.go</code> file in the <code>cmd/proxy</code> directory.</p> <pre><code>PROXY_REGISTRY_URL=\"docker.io\"\nPROXY_AUTHENTICATE=\"TRUE\"\nPROXY_REGISTRY_USERNAME=\"docker_username\"\nPROXY_REGISTRY_PASSWORD=\"docker_password\"\npropeller-proxy\n</code></pre> <p>This will change the task definition. Since we are using hosted wasm modules, we need to specify the image URL. Hence the task definition will look like this:</p> <pre><code>{\n  \"name\": \"add\",\n  \"inputs\": [10, 20],\n  \"image_url\": \"docker.io/mrstevenyaga/add.wasm\"\n}\n</code></pre>"},{"location":"proxy/#how-it-works","title":"How It Works","text":"<p>The proxy service facilitates the download of WebAssembly (WASM) containers through a multi-step process:</p> <p></p> <ol> <li> <p>Initial Request    The proplet sends a download request via the MQTT topic: <code>m/:domain_id/c/:channel_id/messages/registry/proplet</code>    This request is received by the proxy service's MQTT subscriber</p> </li> <li> <p>OCI Registry Download    The HTTP side of the proxy service receives this request    It then sends a download request to the OCI registry to fetch the WASM container    The container is downloaded as an OCI image</p> </li> <li> <p>Chunked Data Transfer    Once downloaded, the WASM image is split into chunks    These chunks are sent back to the proplet via the MQTT topic: <code>m/:domain_id/c/:channel_id/messages/registry/server</code>    This chunked approach ensures efficient handling of large WASM files</p> </li> </ol>"},{"location":"proxy/#architecture-details","title":"Architecture Details","text":""},{"location":"proxy/#streaming-system","title":"Streaming System","text":"<p>The proxy service implements a concurrent streaming architecture with two main components:</p> <ol> <li> <p>HTTP Stream    Handles container fetching from the OCI registry.    Splits containers into configurable chunk sizes    Forwards chunks to the MQTT stream via an internal channel.    Implements context-based cancellation for graceful shutdown.</p> </li> <li> <p>MQTT Stream    Receives chunks from the HTTP stream.    Publishes chunks to MQTT topics.    Tracks chunk delivery progress.    Maintains a map of container chunks to ensure complete delivery.</p> </li> </ol>"},{"location":"proxy/#chunk-management","title":"Chunk Management","text":"<ul> <li>Uses a buffered channel system with a capacity of 10 chunks</li> <li>Tracks the progress of chunk delivery for each container</li> <li>Provides completion notifications when all chunks are successfully sent</li> <li>Automatically cleans up tracking data after successful delivery</li> </ul>"},{"location":"proxy/#performance-features","title":"Performance Features","text":"<ul> <li>Buffered Operations: Implements chunk buffering to optimize memory usage and transfer speed</li> <li>Concurrent Processing: Separate goroutines for HTTP and MQTT operations</li> <li>Progress Tracking: Real-time tracking of chunk delivery status</li> <li>Memory Management: Automatic cleanup of completed transfers</li> </ul>"},{"location":"proxy/#configuration","title":"Configuration","text":"<p>The proxy service is configured using environment variables.</p>"},{"location":"proxy/#environment-variables","title":"Environment Variables","text":"Environment Variable Description <code>PROXY_LOG_LEVEL</code> Log level (e.g., <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>). <code>PROXY_INSTANCE_ID</code> A unique ID for this proxy instance."},{"location":"proxy/#mqtt-configuration","title":"MQTT Configuration","text":"Variable Description Default Required <code>PROXY_MQTT_ADDRESS</code> URL of the MQTT broker <code>tcp://localhost:1883</code> Yes <code>PROXY_MQTT_TIMEOUT</code> The timeout for MQTT operations. <code>30s</code> No <code>PROXY_MQTT_QOS</code> The Quality of Service level for MQTT messages. <code>2</code> No <code>PROXY_DOMAIN_ID</code> The domain ID for this proxy. <code>\"\"</code> Yes <code>PROXY_CLIENT_ID</code> Unique identifier for the proplet <code>\"\"</code> Yes <code>PROXY_CHANNEL_ID</code> Channel identifier for MQTT <code>\"\"</code> Yes <code>PROXY_CLIENT_KEY</code> Password for MQTT authentication <code>\"\"</code> Yes"},{"location":"proxy/#registry-configuration","title":"Registry Configuration","text":"Variable Description Default Required <code>PROXY_REGISTRY_URL</code> URL of the OCI registry <code>\"\"</code> Yes <code>PROXY_AUTHENTICATE</code> Enable/disable registry authentication <code>false</code> No <code>PROXY_REGISTRY_USERNAME</code> Username for registry authentication <code>\"\"</code> Only if <code>PROXY_AUTHENTICATE=true</code> <code>PROXY_REGISTRY_PASSWORD</code> Password for registry authentication <code>\"\"</code> Only if <code>PROXY_AUTHENTICATE=true</code> <code>PROXY_REGISTRY_TOKEN</code> Access token for registry authentication <code>\"\"</code> Alternative to username/password <code>PROXY_CHUNK_SIZE</code> The size of the chunks to split the Wasm module into <code>512000</code> No"},{"location":"proxy/#example-configuration","title":"Example Configuration","text":"<p>Export the required environment variables in your terminal:</p> <pre><code># Registry Configuration\nexport PROXY_REGISTRY_URL=\"&lt;registry_url&gt;\"\nexport PROXY_AUTHENTICATE=\"TRUE\"\nexport PROXY_REGISTRY_USERNAME=\"&lt;your_docker_username&gt;\"\nexport PROXY_REGISTRY_PASSWORD=\"&lt;your_docker_password&gt;\"\n\n# MQTT Configuration\nexport PROPLET_THING_KEY=\"&lt;secret&gt;\"\nexport PROPLET_THING_ID=\"&lt;proplet_id&gt;\"\nexport PROPLET_CHANNEL_ID=\"&lt;channel_id&gt;\"\n</code></pre>"},{"location":"proxy/#authentication","title":"Authentication","text":"<p>If your registry requires authentication, you can set the <code>PROXY_AUTHENTICATE</code> environment variable to <code>true</code> and provide either a token or a username and password.</p>"},{"location":"proxy/#token-authentication","title":"Token Authentication","text":"<pre><code>export PROXY_AUTHENTICATE=\"true\"\nexport PROXY_REGISTRY_TOKEN=\"your_token\"\n</code></pre>"},{"location":"proxy/#usernamepassword-authentication","title":"Username/Password Authentication","text":"<pre><code>export PROXY_AUTHENTICATE=\"true\"\nexport PROXY_REGISTRY_USERNAME=\"your_username\"\nexport PROXY_REGISTRY_PASSWORD=\"your_password\"\n</code></pre>"},{"location":"proxy/#running-the-service","title":"Running the Service","text":"<p>After exporting the environment variables, you can run the proxy service as shown:</p> <pre><code>make all &amp;&amp; make install\npropeller-proxy\n</code></pre> <p>This will install the binary in your GOBIN directory (ensure your GOBIN is configured correctly).</p>"},{"location":"proxy/#deploying-a-local-oci-registry","title":"Deploying a Local OCI Registry","text":"<p>Propeller supports pulling Wasm modules from any OCI-compliant registry. You can use a public registry like Docker Hub or set up your own private registry. You can deploy your own OCI registry using Docker and configure the proxy to pull WASM modules from it. This is useful for development and testing purposes.</p>"},{"location":"proxy/#1-run-a-local-registry","title":"1. Run a Local Registry","text":"<p>First, run a local OCI registry using the official Docker image:</p> <pre><code>docker run -d -p 5000:5000 --name registry registry:3.0.0\n</code></pre> <p>This command will start a local registry in detached mode and map port 5000 on your host to port 5000 on the container.</p>"},{"location":"proxy/#2-push-a-wasm-module-to-the-local-registry","title":"2. Push a WASM Module to the Local Registry","text":"<p>Next, you need to push a WASM module to your local registry. You can use a tool like <code>oras</code> or <code>wasm-to-oci</code> to do this. First, create WASM module. We can use the <code>addition.wasm</code> module from the propeller example after building the wasm module.</p> <pre><code>git clone https://github.com/absmach/propeller.git\ncd propeller\nmake all\n</code></pre> <p>Now, push the <code>addition.wasm</code> file to your local registry using <code>wasm-to-oci</code>:</p> <pre><code>wasm-to-oci push ./build/addition.wasm localhost:5000/rodneydav/addition.wasm\nwasm-to-oci push ./build/addition.wasm docker.io/rodneydav/addition.wasm\n</code></pre>"},{"location":"proxy/#3-configure-the-proxy","title":"3. Configure the Proxy","text":"<p>Finally, configure the proxy to use your local registry by setting the following environment variables:</p> <pre><code>export PROXY_REGISTRY_URL=\"localhost:5000\"\nexport PROXY_AUTHENTICATE=\"false\"  # No authentication for local registry\n</code></pre> <p>Now, when you run the proxy, it will pull the <code>addition.wasm</code> module from your local registry when a request for <code>localhost:5000/addition</code> is made.</p>"},{"location":"proxy/#service-flow","title":"Service Flow","text":"<ol> <li> <p>Initialization    Loads configuration from environment variables.    Sets up logging with structured logging support.    Creates a new proxy service instance.    Initializes MQTT client and communication channels.</p> </li> <li> <p>Connection    Establishes connection to the MQTT broker.    Subscribes to configured topics.    Sets up HTTP streaming with the registry.    Initializes chunk buffering system.</p> </li> <li> <p>Operation    Runs two concurrent streams:</p> </li> <li> <p>StreamHTTP: Handles HTTP communication with the OCI registry.</p> </li> <li>StreamMQTT: Handles MQTT communication for proplet requests and responses.</li> </ol> <p>Uses error groups for graceful error handling and shutdown. Maintains chunk delivery tracking. Provides real-time progress logging.</p> <ol> <li>Error Handling    Implements comprehensive error logging with context. Graceful shutdown with proper resource cleanup. Automatic disconnection from MQTT broker on service termination. Retry mechanisms for failed operations. Context-based cancellation support.</li> </ol>"},{"location":"proxy/#http-registry-operations","title":"HTTP Registry Operations","text":"<p>The HTTP configuration supports:</p> <ul> <li>Registry operations with optional authentication (username/password or token)</li> <li>Automatic retry mechanism for failed requests</li> <li>Chunked data handling with configurable chunk size (512KB default)</li> <li>Static credential caching for authenticated requests</li> <li>Progress tracking for multi-chunk transfers</li> </ul>"},{"location":"zephyr/","title":"Deploying WAMR on Zephyr for ESP32","text":""},{"location":"zephyr/#1-set-up-zephyr-development-environment","title":"1. Set Up Zephyr Development Environment","text":""},{"location":"zephyr/#install-dependencies-on-your-development-machine","title":"Install Dependencies on your development machine","text":"<p>Update your system. For debian based systems you can use the following command:</p> <pre><code>sudo apt update\nsudo apt upgrade\n</code></pre> <p>Install the required tools:</p> <pre><code>sudo apt install --no-install-recommends git cmake ninja-build gperf \\\nccache dfu-util device-tree-compiler wget \\\npython3-dev python3-pip python3-setuptools python3-tk python3-wheel xz-utils file \\\nmake gcc gcc-multilib g++-multilib libsdl2-dev libmagic1\n</code></pre> <p>Verify tool versions:</p> <pre><code>cmake --version\npython3 --version\ndtc --version\n</code></pre> <p>Ensure versions meet the minimum requirements: CMake 3.20.5, Python 3.10, and Devicetree Compiler 1.4.6.</p>"},{"location":"zephyr/#get-zephyr-and-python-dependencies-on-your-development-machine","title":"Get Zephyr and Python Dependencies on your development machine","text":"<p>Install Python venv package::</p> <pre><code>sudo apt install python3-venv\n</code></pre> <p>Create a new virtual environment:</p> <pre><code>python3 -m venv ~/zephyrproject/.venv\n</code></pre> <p>Activate the virtual environment:</p> <pre><code>source ~/zephyrproject/.venv/bin/activate\n</code></pre> <p>Install west:</p> <pre><code>pip install west\n</code></pre> <p>Create a Zephyr workspace and clone the repository:</p> <pre><code>west init ~/zephyrproject\ncd ~/zephyrproject\nwest update\n</code></pre> <p>Export Zephyr CMake package:</p> <pre><code>west zephyr-export\n</code></pre> <p>Install Python dependencies:</p> <pre><code>west packages pip --install\n</code></pre> <p>Install the Zephyr SDK:</p> <pre><code>cd ~/zephyrproject/zephyr\nwest sdk install\n</code></pre> <p>You can also install Zephyr SDK without using the west sdk command, as described in this Zephyr SDK installation guide.</p> <p>Fetch Espressif binary blobs:</p> <pre><code>west blobs fetch hal_espressif\n</code></pre> <p>The <code>ZEPHYR_BASE</code> environment variable is essential for locating Zephyr's core build system, CMake scripts, and modules. Without this variable set, Zephyr tools like <code>west</code> will fail to build applications.</p> <p>To confirm whether the <code>ZEPHYR_BASE</code> environment variable is configured correctly, use the following command:</p> <pre><code>echo $ZEPHYR_BASE\n</code></pre> <p>If the output is empty or incorrect, follow the steps below to set it.</p> <ol> <li>Activate your Zephyr Virtual Environment:</li> </ol> <p>If you're using a virtual environment for Zephyr, activate it first:</p> <p><code>bash    source ~/zephyrproject/.venv/bin/activate</code></p> <ol> <li>Set the <code>ZEPHYR_BASE</code> Variable:</li> </ol> <p>Once activated, set the <code>ZEPHYR_BASE</code> variable to point to the Zephyr directory:</p> <p><code>bash    export ZEPHYR_BASE=~/zephyrproject/zephyr</code></p> <ol> <li>Make the Change Permanent:</li> </ol> <p>To ensure the <code>ZEPHYR_BASE</code> variable is set automatically in future sessions, add the following line to your shell's configuration file (<code>.bashrc</code> for Bash or <code>.zshrc</code> for Zsh):</p> <p><code>bash    export ZEPHYR_BASE=~/zephyrproject/zephyr</code></p> <p>After adding the line, apply the changes by running:</p> <p><code>bash    source ~/.bashrc   # For Bash users    source ~/.zshrc    # For Zsh users</code></p> <ul> <li>For more information on Zephyr environment variables, visit the Zephyr Environment Variables Documentation.</li> <li>For a comprehensive guide on setting up Zephyr, refer to the official Zephyr Getting Started Guide.</li> <li>For board-specific information, such as the Espressif ESP32-S3 DevKitC, refer to the official documentation for setup and configuration details.</li> <li>To see the full list of supported boards, refer to the Zephyr Board Documentation.</li> </ul>"},{"location":"zephyr/#2-install-esp-idf-on-your-development-machine","title":"2. Install ESP-IDF on your development machine","text":"<p>Do not install ESP-IDF inside the Zephyr virtual environment. ESP-IDF is a separate development framework with its own setup and toolchain requirements, which should be installed and managed globally or in its own isolated environment. Global Installation (Preferred). This way, its tools and environment are available for any project on the ESP32, including Zephyr.</p> <p>Without ESP-IDF:</p> <ul> <li>You cannot compile or flash code for the ESP32.</li> <li>Zephyr won\u2019t be able to recognize or support the ESP32-S3 during build or runtime.</li> </ul>"},{"location":"zephyr/#option-1-using-vs-code-extension-recommended","title":"Option 1: Using VS Code Extension (Recommended)","text":"<p>Install the ESP-IDF extension:</p> <ul> <li>Navigate to View &gt; Extensions in VS Code.</li> <li>Search for \"ESP-IDF Extension\" and install it.</li> </ul> <p>Configure the ESP-IDF extension:</p> <ul> <li>Open Command Palette (<code>Ctrl+Shift+P</code> or <code>Cmd+Shift+P</code>).</li> <li>Run <code>ESP-IDF: Configure ESP-IDF Extension</code>.</li> <li>Follow the setup wizard to download and install ESP-IDF.</li> </ul> <p>Ensure correct paths for IDF:</p> <ul> <li>Set <code>IDF_PATH</code> and <code>IDF_TOOLS_PATH</code> appropriately (default: <code>$HOME/.espressif</code>).</li> </ul> <p>Add OpenOCD rules for Linux. The command typically looks like:</p> <pre><code>sudo cp --update=none /home/&lt;username&gt;/.espressif/tools/openocd-esp32/&lt;version&gt;/share/openocd/contrib/60-openocd.rules /etc/udev/rules.d/\n</code></pre> <p>then reload udev rules to apply the changes:</p> <pre><code>sudo udevadm control --reload-rules\nsudo udevadm trigger\n</code></pre> <p>For more detailed information, refer to the official ESP-IDF Extension Guide.</p>"},{"location":"zephyr/#option-2-manual-installation","title":"Option 2: Manual Installation","text":"<p>Download ESP-IDF:</p> <pre><code>mkdir -p ~/esp\ncd ~/esp\nwget https://github.com/espressif/esp-idf/releases/download/v5.3.2/esp-idf-v5.3.2.zip\nunzip esp-idf-v5.3.2.zip -d v5.3.2\n</code></pre> <p>Ensure the directory structure is correct after unzipping. The export script requires paths to be consistent.</p> <p>Export the ESP-IDF environment:</p> <pre><code>source ~/esp/v5.3.2/esp-idf/export.sh\n</code></pre> <p>Run this command in every new terminal session, or automate it by adding the export command to your shell's startup script (~/.bashrc, ~/.zshrc, etc.).</p> <p>Verify the installation:</p> <p>Check the installed ESP-IDF version:</p> <pre><code>idf.py --version\n\n</code></pre> <p>If the <code>idf.py</code> command fails with <code>command not found</code>, source the ESP-IDF Environment in VS Code. To avoid manually sourcing the <code>export.sh</code> script every time you open a terminal:</p> <ul> <li>Open your shell configuration file (<code>~/.zshrc</code> or <code>~/.bashrc</code>):</li> </ul> <p><code>bash   nano ~/.zshrc</code></p> <ul> <li>Add this line at the bottom:</li> </ul> <p><code>bash   source ~/esp/v5.3.2/esp-idf/export.sh</code></p> <ul> <li>Save and reload the shell configuration:</li> </ul> <p><code>bash   source ~/.zshrc</code></p> <ul> <li> <p>Once the environment is sourced:</p> </li> <li> <p>Check the Xtensa toolchain:</p> <p><code>bash xtensa-esp32s3-elf-gcc --version</code></p> </li> <li> <p>Verify <code>idf.py</code> again:</p> <p><code>bash idf.py --version</code></p> </li> </ul>"},{"location":"zephyr/#3-test-zephyrs-integration-with-esp-idf","title":"3. Test Zephyr's Integration with ESP-IDF","text":"<p>Navigate to your Zephyr workspace:</p> <pre><code>cd ~/zephyrproject\n</code></pre> <p>Activate the virtual environment. This ensures that Zephyr tools (e.g., west, CMake) and configurations are properly used during the build process.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Build the Hello World sample:</p> <pre><code>west build -b esp32s3_devkitc/esp32s3/procpu zephyr/samples/hello_world\n</code></pre> <p>Flash the firmware:</p> <pre><code>west flash\n</code></pre> <p>Monitor the output:</p> <pre><code>west espressif monitor\n</code></pre> <p>A successful run shows that the entire build-flash-boot-debug toolchains are functional for your development board.</p> <p>NOTE:</p> <ul> <li>Before building, list all supported boards to verify the correct target name. Look for your desired board in the output of:</li> </ul> <p><code>bash   west boards</code></p> <p>In Zephyr\u2019s newer versions, boards like esp32s3_devkitc are split into multiple \u201csub-boards\u201d for each core. So instead of building with:</p> <p><code>bash   west build -b esp32s3_devkitc zephyr/samples/hello_world</code></p> <p>you need to specify which core to target, e.g. <code>esp32s3_devkitc/esp32s3/procpu</code> (for the primary processor core, which we will use in this example) or the <code>esp32s3_devkitc/esp32s3/appcpu</code> (for the application processor core)</p> <ul> <li>If you see the message <code>ninja: no work to do</code>, it means the build system has detected no changes since the last build, and no new compilation is needed. Use the <code>--pristine</code> flag to ensure a completely clean build environment:</li> </ul> <p><code>bash   west build -b esp32s3_devkitc/esp32s3/procpu zephyr/samples/hello_world --pristine</code></p> <ul> <li>Use <code>west flash --erase</code> if the board has residual firmware causing conflicts.</li> <li>Ensure that <code>west espressif monitor</code> is not running when you attempt to flash the firmware. It keeps the serial port busy, preventing the <code>west flash</code> command from accessing it.</li> </ul>"},{"location":"zephyr/#using-webassembly-micro-runtime-wamr-with-zephyr","title":"Using WebAssembly Micro Runtime (WAMR) with Zephyr","text":""},{"location":"zephyr/#step-1-clone-wamr-repository","title":"Step 1: Clone WAMR repository","text":"<pre><code>cd ~/zephyrproject\ngit clone https://github.com/bytecodealliance/wasm-micro-runtime.git\n</code></pre> <p>After running the above commands, your folder structure will look like this:</p> <pre><code>~/zephyrproject/\n\u251c\u2500\u2500 zephyr/\n\u251c\u2500\u2500 modules/\n\u251c\u2500\u2500 wasm-micro-runtime/\n</code></pre> <p>Note: It's not necessary to clone WAMR inside the <code>zephyrproject</code> folder, but it\u2019s easier to keep everything organized in one place. If you choose to place it elsewhere, you will need to update some configuration files to point to the correct location of the WAMR repository.</p>"},{"location":"zephyr/#step-2-update-cmakeliststxt-optional","title":"Step 2: Update CMakeLists.txt (Optional)","text":"<p>If you decided to place the WAMR repository outside of the <code>zephyrproject</code> folder, you will need to tell Zephyr where to find it. You can do this by updating your <code>CMakeLists.txt</code> file.</p> <p>Add these lines:</p> <pre><code>set(WAMR_ROOT /path/to/wasm-micro-runtime)\ninclude(${WAMR_ROOT}/build-scripts/runtime_lib.cmake)\n</code></pre> <p>Make sure to replace <code>/path/to/wasm-micro-runtime</code> with the actual path where you placed the WAMR source.</p>"},{"location":"zephyr/#step-3-test-your-installation","title":"Step 3: Test Your Installation","text":"<p>To make sure everything is set up correctly, build and run a test application.</p> <ol> <li>Go to the <code>basic</code> sample directory:</li> </ol> <p><code>bash    cd samples/basic</code></p> <ol> <li>Inside the <code>basic</code> sample folder, you\u2019ll find a script called <code>build.sh</code>. This script compiles both the native application and the WebAssembly (WASM) application. To build the project, run:</li> </ol> <p><code>bash    ./build.sh</code></p> <ol> <li>After the build finishes, you will find the output files in the <code>out</code> directory. To run the test application, go to the <code>out</code> folder:</li> </ol> <p><code>bash    cd out</code></p> <ol> <li>Run the application with the following command:</li> </ol> <p><code>bash    ./basic -f wasm-apps/testapp.wasm</code></p> <p>You should see output like this:</p> <pre><code>calling into WASM function: generate_float\nNative finished calling wasm function generate_float(), returned a float value: 102009.921875f\ncalling into WASM function: float_to_string\ncalling into native function: intToStr\ncalling into native function: get_pow\ncalling into native function: intToStr\nNative finished calling wasm function: float_to_string, returned a formatted string: 102009.921\n</code></pre>"},{"location":"zephyr/#step-4-clean-build-artifacts","title":"Step 4: Clean Build Artifacts","text":"<p>If you want to clean up the build files, simply run:</p> <pre><code>./build.sh clean\n</code></pre>"},{"location":"zephyr/#step-5-deploy-wamr-on-zephyr-for-esp32","title":"Step 5: Deploy WAMR on Zephyr for ESP32","text":"<p>After testing WAMR locally, deploy it to the ESP32 board using Zephyr.</p> <ol> <li>Go to the WAMR example directory for Zephyr:</li> </ol> <p><code>bash    cd ~/zephyrproject/wasm-micro-runtime/product-mini/platforms/zephyr/simple</code></p> <ol> <li>If you haven\u2019t already, activate your Zephyr virtual environment:</li> </ol> <p><code>bash    source ~/zephyrproject/.venv/bin/activate</code></p> <ol> <li>Build the WAMR example for your ESP32 board. Replace <code>&lt;your_board&gt;</code> with your specific board name, like <code>esp32s3_devkitc</code>:</li> </ol> <p><code>bash    west build -b &lt;your_board&gt;</code></p> <ol> <li>Flash the firmware to your ESP32 board:</li> </ol> <p><code>bash    west flash</code></p> <ol> <li>To see what's happening on the board, open the serial monitor:</li> </ol> <p><code>bash    west espressif monitor</code></p>"},{"location":"zephyr/#using-a-webassembly-module-with-zephyr","title":"Using a WebAssembly Module with Zephyr","text":"<p>The sample C code is in <code>src/wasm-app-riscv64/main.c</code>. To generate a <code>.wasm</code> file, run the build script located in <code>src/wasm-app-riscv64/build.sh</code>.</p> <pre><code>./build.sh\n</code></pre> <p>This creates <code>test.wasm</code>, <code>test_wasm.h</code>, and <code>test_wasm_riscv64.h</code>. Replace <code>src/test_wasm.h</code> and <code>src/test_wasm_riscv64.h</code> with the newly generated files from <code>src/wasm-app-riscv64</code>.</p> <p>Build the firmware (replace <code>&lt;your_board&gt;</code> with the board name):</p> <pre><code>west build -b &lt;your_board&gt;\n</code></pre> <p>Flash the firmware:</p> <pre><code>west flash\n</code></pre> <p>Use the serial monitor to see output:</p> <pre><code>west espressif monitor\n</code></pre>"},{"location":"zephyr/#potential-pitfalls-and-solutions","title":"Potential Pitfalls and Solutions","text":""},{"location":"zephyr/#1-permission-denied-for-devttyusb0","title":"1. Permission Denied for <code>/dev/ttyUSB0</code>","text":"<p>Add your user to the <code>dialout</code> group then log out and log back in or restart the system.:</p> <pre><code>sudo usermod -aG dialout $USER\n</code></pre>"},{"location":"zephyr/#2-west-not-found","title":"2. <code>west</code> Not Found","text":"<p>Activate the virtual environment:</p> <pre><code>source ~/zephyrproject/.venv/bin/activate\n</code></pre>"},{"location":"zephyr/#3-build-fails-with-missing-board-qualifiers","title":"3. Build Fails with Missing Board Qualifiers","text":"<p>Use the correct board target as described in The board qualifiers. For ESP32s3, for example:</p> <pre><code>west build -b esp32s3_devkitc/esp32s3/procpu zephyr/samples/hello_world\n</code></pre>"},{"location":"zephyr/#4-serial-port-already-in-use","title":"4. Serial Port Already in Use","text":"<ol> <li>Identify the process using the port and kill it:</li> </ol> <p><code>bash    lsof /dev/ttyUSB0    kill &lt;PID&gt;</code></p>"},{"location":"zephyr/#5-cmake-source-directory-mismatch","title":"5. CMake source directory mismatch","text":"<p>Clear the existing CMake cache to resolve the mismatch by deleting the <code>build</code> directory and then re-run the <code>west build</code> command.</p> <pre><code>rm -rf ~/zephyrproject/zephyr/build\n</code></pre>"}]}