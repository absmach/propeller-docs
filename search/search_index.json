{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Propeller","text":"<p>Propeller is a cutting-edge orchestrator for WebAssembly (Wasm) workloads across the Cloud-Edge continuum. It enables seamless deployment of Wasm applications from powerful cloud servers to constrained microcontrollers, combining flexibility, security, and performance.</p>"},{"location":"#features","title":"\ud83c\udf1f Features","text":"<ul> <li>\ud83c\udf10 Cloud-Edge Orchestration: Deploy Wasm workloads effortlessly across diverse environments, from robust cloud servers to lightweight microcontrollers.</li> <li>\u26a1 Fast Boot Times: Take advantage of Wasm's near-instant startup for efficient workload execution.</li> <li>\ud83d\udce6 FaaS Deployment: Enable Function-as-a-Service (FaaS) capabilities for scalable and event-driven applications.</li> <li>\ud83d\udda5\ufe0f OCI Registry Support: Push and pull Wasm workloads from OCI-compliant registries for streamlined workflow integration.</li> <li>\ud83d\udd27 WAMR on Zephyr RTOS: Deploy lightweight Wasm workloads on constrained devices running Zephyr RTOS via the WebAssembly Micro Runtime (WAMR).</li> <li>\ud83d\udee0\ufe0f Powerful Service Mesh: Integrates with SuperMQ for secure, efficient IoT device communication.</li> <li>\ud83d\udd12 Security at the Core: Propeller ensures secure workload execution and communication for IoT environments.</li> </ul>"},{"location":"#how-it-works","title":"\ud83d\udee0\ufe0f How It Works","text":"<ol> <li>Develop in WebAssembly: Write portable, lightweight Wasm workloads for your application.</li> <li>Register Workloads: Push your workloads to an OCI-compliant registry for easy deployment.</li> <li>Deploy Anywhere: Use Propeller to orchestrate and manage workload deployment across the cloud, edge, and IoT devices.</li> <li>Monitor &amp; Scale: Leverage real-time monitoring and dynamic scaling to optimize your system's performance.</li> </ol>"},{"location":"architecture/","title":"System Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>The Propeller system is a distributed computing platform designed to manage and execute tasks across multiple nodes (proplets). It leverages MQTT for communication, a manager service for task orchestration, and a proxy service for container image distribution. The system is composed of several key components:</p> <ol> <li>CLI: Command Line Interface for interacting with the Propeller system.</li> <li>Manager: Central service responsible for task management and proplet coordination.</li> <li>Proplet: Worker nodes that execute tasks.</li> <li>Proxy: Service for fetching and distributing container images from a registry.</li> <li>SuperMQ: Internal Event Driven Infrastructure for creation and coommunication between services.</li> </ol> <p></p>"},{"location":"architecture/#components","title":"Components","text":""},{"location":"architecture/#cli","title":"CLI","text":"<p>The CLI provides a command-line interface for users to interact with the Propeller system. It allows users to create, list, update, and delete tasks, as well as start and stop tasks. The CLI also allows you to provision manager and proplets.</p>"},{"location":"architecture/#manager","title":"Manager","text":"<p>The Manager is the central service responsible for managing tasks and coordinating proplets. It handles task creation, updates, deletion, and execution and maintains an internal database for tracking tasks and proplets. It also manages the lifecycle of proplets and ensures they are alive and healthy. The Manager uses MQTT for communication between services. It exposes REST endpoints for task management and proplet coordination. Currently, the system supports 1 manager : multiple workers. In the future, the system will be expanded to support multiple managers : multiple workers.</p>"},{"location":"architecture/#proplet","title":"Proplet","text":"<p>Proplets are worker nodes that execute tasks. They receive tasks from the Manager, execute them, and report the results back. Proplets also send periodic liveliness updates to the Manager to indicate they are alive.</p>"},{"location":"architecture/#proxy","title":"Proxy","text":"<p>The Proxy service is responsible for fetching container images from a registry and distributing them to proplets. It handles authentication with the registry and splits the container images into chunks for efficient distribution. This is for OCI registry to fetch image from OCI registry and split the image into chunks for proplets to assemble and execute.</p>"},{"location":"architecture/#supermq","title":"SuperMQ","text":"<p>SuperMQ is an Event Driven Infrastructure (EDI) for creating and coordinating services. It provides a way to create and manage entities, as well as handle communication between services. SuperMQ uses MQTT for communication and provides a set of APIs for entity creation, management, and communication.</p>"},{"location":"architecture/#communication","title":"Communication","text":""},{"location":"architecture/#mqtt","title":"MQTT","text":"<p>MQTT is used for communication between the Manager, Proplets, and Proxy. The Manager publishes tasks to proplets, and proplets send liveliness updates and task results back to the Manager. The Proxy fetches container images and distributes them to proplets.</p>"},{"location":"architecture/#http","title":"HTTP","text":"<p>HTTP is used for the CLI to interact with the Manager. The Manager exposes REST endpoints for task management and proplet coordination.</p>"},{"location":"architecture/#task-lifecycle","title":"Task Lifecycle","text":"<ol> <li>Task Creation: A user creates a task using the CLI or HTTP API, which sends a request to the Manager.</li> <li>Task Scheduling: The Manager selects a proplet to execute the task based on the scheduling algorithm.</li> <li>Task Execution: The selected proplet receives the task, executes it, and reports the results back to the Manager.</li> <li>Task Completion: The Manager updates the task status and stores the results.</li> </ol>"},{"location":"architecture/#proplet-liveliness","title":"Proplet Liveliness","text":"<p>Proplets send periodic liveliness updates to the Manager to indicate they are alive. The Manager uses these updates to monitor the health of proplets and ensure they are available for task execution.</p>"},{"location":"architecture/#container-image-distribution","title":"Container Image Distribution","text":"<p>The Proxy fetches container images from a registry, splits them into chunks, and distributes them to proplets. Proplets assemble the chunks and execute the container image.</p>"},{"location":"developer-guide/","title":"Developer's Guide","text":""},{"location":"developer-guide/#getting-propeller","title":"Getting Propeller","text":"<p>Propeller source can be found in the official Propeller GitHub repository. You should fork this repository in order to make changes to the project. The forked version of the repository should be cloned using the following:</p> <pre><code>git clone https://github.com/your-github-username/propeller.git $SOMEPATH/propeller\ncd $SOMEPATH/propeller\n</code></pre>"},{"location":"developer-guide/#building-propeller","title":"Building Propeller","text":""},{"location":"developer-guide/#prerequisites","title":"Prerequisites","text":"<p>To build Propeller, you will need the following:</p> <ul> <li>A Go compiler (Go 1.23 or later)</li> <li>Make</li> <li>Docker</li> <li>Wasmtime</li> <li>TinyGo</li> </ul>"},{"location":"developer-guide/#building","title":"Building","text":"<p>Use the GNU Make tool to build all Propeller services:</p> <pre><code>make all\n</code></pre> <p>This will build Propeller for your platforms.</p> <p>To build Propeller for other platforms, use the following:</p> OS Architecture Command Linux amd64 <code>GOOS=linux GOARCH=amd64 make all</code> Linux arm64 <code>GOOS=linux GOARCH=arm64 make all</code> Windows amd64 <code>GOOS=windows GOARCH=amd64 make all</code> Darwin amd64 <code>GOOS=darwin GOARCH=amd64 make all</code>"},{"location":"developer-guide/#building-an-individual-service","title":"Building an individual service","text":"<p>You can build individual services using the following:</p> <pre><code>make &lt;service&gt;\n</code></pre> <p>For example, to build the <code>manager</code> service, use the following:</p> <pre><code>make manager\n</code></pre> <p>The built binaries will be located in the <code>build</code> directory.</p>"},{"location":"developer-guide/#building-examples","title":"Building examples","text":"<p>You can build examples using the following:</p> <pre><code>make &lt;example&gt;\n</code></pre> <p>For example, to build the <code>addition</code> example, use the following:</p> <pre><code>make addition\n</code></pre> <p>This compiles the addition example to wasm and can be located in the <code>build</code> directory.</p> <p>To test the addition example, use the following:</p> <pre><code>wasmtime --invoke add ./build/addition.wasm 1 2\n</code></pre> <p>This will output something like:</p> <pre><code>warning: using `--invoke` with a function that takes arguments is experimental and may break in the future\nwarning: using `--invoke` with a function that returns values is experimental and may break in the future\n3\n</code></pre>"},{"location":"developer-guide/#installing","title":"Installing","text":"<p>Once you have built Propeller, you can install it using the following:</p> <pre><code>make install\n</code></pre> <p>This will install Propeller to the <code>GOBIN</code> directory.</p>"},{"location":"developer-guide/#linter","title":"Linter","text":"<p>Propeller uses golangci-lint to lint the code. You can run the linter using the following:</p> <pre><code>make lint\n</code></pre>"},{"location":"developer-guide/#supermq","title":"SuperMQ","text":""},{"location":"developer-guide/#starting-supermq","title":"Starting SuperMQ","text":"<p>To start SuperMQ, use the following:</p> <pre><code>make start-supermq\n</code></pre> <p>This will in the background run <code>docker compose -f docker/compose.yaml up -d</code> which will start the SuperMQ services.</p> <p>You can override the configuration or add some extra parameters to the docker compose configuration.</p>"},{"location":"developer-guide/#stopping-supermq","title":"Stopping SuperMQ","text":"<p>SuperMQ can be stopped using the following:</p> <pre><code>make stop-supermq\n</code></pre>"},{"location":"embedded-proplet/","title":"Embedded Proplet","text":""},{"location":"embedded-proplet/#wamr-integration-in-the-embedded-proplet","title":"WAMR Integration in the Embedded Proplet","text":"<p>Propeller integrates WAMR within its decentralized worker-node framework, enabling distributed execution of WASM workloads on Zephyr-based embedded devices through the embedded proplet. The WAMR runtime is integrated into the Propeller project as a Git submodule, ensuring modular dependency management and streamlined updates. The integration is defined within the CMakeLists.txt configuration, where WAMR is compiled as part of the Zephyr build system. The embedded proplet explicitly configures WAMR for the ESP32-S3 (XTENSA) architecture by setting <code>WAMR_BUILD_PLATFORM=\"zephyr\"</code> and <code>WAMR_BUILD_TARGET=\"XTENSA\"</code>. Other target options include <code>\"ARM\"</code>, <code>\"RISCV\"</code>, <code>\"X86_64\"</code>, and <code>\"MIPS\"</code>, making the embedded proplet adaptable to a wide range of embedded architectures beyond XTENSA.</p> <p>To ensure an optimal balance between performance and flexibility in embedded environments, the embedded proplet is configured to support both interpreter mode (<code>WAMR_BUILD_INTERP=1</code>) and ahead-of-time (AOT) compilation (<code>WAMR_BUILD_AOT=1</code>). The above configuration allows for efficient execution of pre-compiled WASM modules while retaining the ability to interpret dynamically loaded binaries. Disabling the interpreter (<code>WAMR_BUILD_INTERP=0</code>) mandates the use of AOT-compiled modules, potentially improving runtime efficiency but limiting flexibility. Conversely, disabling AOT (<code>WAMR_BUILD_AOT=0</code>) forces reliance on interpretation, which may introduce performance overhead but ensures broader compatibility for modules that have not been precompiled. The built-in WAMR libc (<code>WAMR_BUILD_LIBC_BUILTIN=1</code>) is utilized instead of WASI, as full WASI support in Zephyr is still evolving. Furthermore, a global heap pool (<code>WAMR_BUILD_GLOBAL_HEAP_POOL=1</code>) is allocated with a size of 40 KB (<code>WAMR_BUILD_GLOBAL_HEAP_SIZE=40960</code>), ensuring efficient memory management for WASM execution.</p>"},{"location":"embedded-proplet/#extending-the-zephyr-build-system-for-wamr-integration","title":"Extending the Zephyr Build System for WAMR Integration","text":"<p>To integrate WAMR seamlessly within the Zephyr build system, the following configurations and module definitions are applied. First, the build system includes <code>runtime_lib.cmake</code> from the WAMR repository, ensuring that all necessary runtime components are compiled as part of the Zephyr application. The approach enables the embedded proplet to efficiently execute WASM workloads while using Zephyr\u2019s build and dependency management capabilities. Additionally, the Zephyr build system is extended to recognize WAMR as an integral part of the embedded proplet by modifying the <code>ZEPHYR_EXTRA_MODULES</code> variable. The modification ensures that the WAMR repository path is explicitly included, allowing Zephyr to treat WAMR as a native library. Consequently, WAMR\u2019s runtime components are automatically included during the firmware compilation process, avoiding manual dependency management.</p> <p>To establish a direct connection between the application and WAMR\u2019s execution environment, the build system explicitly includes WAMR\u2019s core runtime headers and source files. This guarantees that the WebAssembly engine is properly compiled and linked within the firmware, ensuring smooth execution of WASM workloads.</p> <p>Finally, WAMR is embedded into the Zephyr application as a dedicated library using <code>zephyr_library_named(wamr_lib)</code>. The application then links WAMR with the Zephyr build system through <code>target_link_libraries(app PRIVATE wamr_lib)</code>, allowing the WASM execution environment to be tightly integrated with the Zephyr firmware.</p>"},{"location":"embedded-proplet/#wasm-handler","title":"WASM Handler","text":"<p>The WASM handler, implemented in <code>wasm_handler.c</code> and <code>wasm_handler.h</code>, serves as the primary interface between the embedded proplet and the embedded device. It is responsible for reading binary WebAssembly modules, validating their integrity, and loading the wasm modules into WAMR\u2019s runtime. The validation step ensures that corrupted or malformed modules do not compromise system stability. Once a WASM module is loaded, the handler initializes the runtime environment to ensure proper execution. The initialization includes allocating a dedicated stack (16 KB) and heap (16 KB) using <code>wasm_runtime_instantiate()</code>. To support concurrent execution of multiple WASM workloads, the handler maintains an array where each running module is tracked with a unique task ID. The implementation of the embedded proplet also ensures that WASM modules can be explicitly terminated, freeing memory and execution slots when no longer needed.</p> <p>For WASM modules to interact with external hardware and networking components, the embedded proplet exposes controlled system interfacing methods. The methods provide secure access to essential embedded system capabilities, including:</p> <ul> <li>Publishing results over MQTT: The handler enables the embedded proplet to send execution results to the Manager using <code>publish_results()</code>, facilitating seamless communication with the Manager.</li> <li>Interacting with external inputs: Embedded Proplets receive dynamic inputs through a defined input structure (<code>inputs[MAX_INPUTS]</code>), allowing parameterized execution of WebAssembly code</li> <li>Performing logging and debugging: The embedded proplet integrates with Zephyr\u2019s logging framework, ensuring that execution logs and error messages are captured for real-time monitoring and debugging.</li> </ul> <p>Since embedded devices have limited resources, the WASM handler enforces strict memory isolation and execution constraints to maintain system reliability. This is achieved through:</p> <ul> <li>Creating execution environments: Each WASM module operates within a sandboxed memory region, using <code>wasm_runtime_create_exec_env()</code>, preventing unintended access to system memory.</li> <li>Limiting execution time and memory usage: The WASM handler enforces a predefined memory allocation (e.g., a global heap size of 40 KB) to prevent system-wide memory exhaustion.</li> <li>Handling runtime exceptions: The system continuously monitors for execution errors using <code>wasm_runtime_get_exception()</code>. If an error occurs, it is logged, and the execution is halted to prevent cascading failures.</li> </ul> <p>For WebAssembly modules to interact with hardware and networking components, the WASM handler facilitates controlled access to system interfaces. The controlled access is achieved by exposing custom host functions, which allow WebAssembly code to:</p> <ul> <li>Publish results over MQTT: Using <code>publish_results()</code>, execution results from a WASM module can be sent over an MQTT channel.</li> <li>Interact with external inputs: WASM functions can receive input values (<code>inputs[MAX_INPUTS]</code>) that modify their behavior dynamically.</li> <li>Perform logging and debugging: The handler integrates with Zephyr\u2019s logging system, providing real-time execution feedback.</li> </ul>"},{"location":"embedded-proplet/#ensuring-memory-isolation-and-stability","title":"Ensuring Memory Isolation and Stability","text":"<p>Since embedded devices have limited resources, the WASM handler enforces strict memory constraints and execution limits. This is done by:</p> <ul> <li>Creating execution environments using <code>wasm_runtime_create_exec_env()</code>, which ensures each WASM module operates in a sandboxed memory region.</li> <li>Limiting execution time by enforcing predefined memory allocations (e.g., 40 KB global heap) to prevent system-wide memory exhaustion.</li> <li>Handling runtime exceptions by checking for error messages from <code>wasm_runtime_get_exception()</code>, preventing runtime crashes caused by invalid operations.</li> </ul> <p>A key aspect of WAMR integration is ensuring sandboxed execution. Each WASM module operates in an isolated environment, with controlled access to system resources. The WASM handler enforces strict memory and execution limits, preventing any single module from consuming excessive resources or interfering with other processes. Additionally, the system enables secure inter-process communication between WASM modules and native Zephyr components, allowing WebAssembly workloads to interact with hardware peripherals and networking functions through a well-defined API.</p> <p>Propeller also leverages WAMR\u2019s extensibility by incorporating custom host functions. These functions allow WASM modules to perform operations such as network communication, sensor data acquisition, and logging. By defining specific host functions, Propeller enables WASM workloads to execute efficiently while maintaining security and stability within the embedded environment.</p> <p>Another critical component of the WAMR integration is task scheduling and workload management. The orchestrator assigns WASM tasks to available proplets based on resource availability, with the WASM handler dynamically managing execution priorities. Each proplet periodically reports its workload status to the orchestrator, enabling real-time load balancing and task reassignment if needed.</p>"},{"location":"embedded-proplet/#task-scheduling-and-resource-management","title":"Task Scheduling and Resource Management","text":"<p>The Propeller Orchestrator dynamically assigns workloads to proplets based on resource availability, power constraints, and scheduling priorities. Each proplet operates independently while receiving tasks from the orchestrator, executing them in an isolated runtime environment. This design guarantees security and stability while preventing resource contention among different workloads.</p> <p>The embedded proplet system is structured into the following components:</p> <p>The networking and connectivity components of the embedded proplet are built upon the networking stack of Zephyr, providing robust support for WiFi and IP-based communication. The configuration file enables WiFi networking and network management, allowing devices to establish and maintain wireless connections effectively. The system also supports general networking capabilities through the network management layer of Zephyr, which enables runtime control and configuration of networking interfaces.</p> <p>The system relies on DHCPv4 for dynamic IP address allocation, ensuring that each embedded proplet can automatically obtain an IP address when connecting to the network. The above eliminates the need for static IP configurations and allows seamless integration into existing network infrastructures. Additionally, the networking stack supports both TCP and UDP, ensuring compatibility with various communication protocols used in distributed systems. To manage multiple network interfaces, the configuration allows up to two IPv4 addresses, configured through <code>CONFIG_NET_IF_MAX_IPV4_COUNT=2</code>, per network interface. Though IPv6 support is available, it is disabled in the configuration file, as the embedded proplet currently prioritizes IPv4 networking. At the link-layer level, the system enables Ethernet and WiFi management, ensuring that edge devices connect using standard networking interfaces. The configuration file also specifies a maximum of two managed WiFi interfaces, allowing the system to handle multiple WiFi connections efficiently.</p> <p>Packet and buffer management is fine-tuned to optimize networking performance for embedded devices, where memory and processing power are constrained and can lead to dropped packets, increased retransmissions, and degraded communication efficiency. The configuration sets <code>CONFIG_NET_BUF_RX_COUNT=64</code> and <code>CONFIG_NET_BUF_TX_COUNT=64</code>, ensuring that sufficient buffers are allocated for incoming and outgoing network packets to reduce packet loss and improve transmission reliability. Similarly, <code>CONFIG_NET_PKT_RX_COUNT=32</code> and <code>CONFIG_NET_PKT_TX_COUNT=32</code> define the number of packet descriptors available for processing network traffic, balancing memory usage and network performance. The dedicated memory allocations for networking tasks <code>CONFIG_NET_RX_STACK_SIZE=2048</code> and <code>CONFIG_NET_TX_STACK_SIZE=2048</code>, further improve the responsiveness and stability of the system in handling concurrent network operations. Additionally, <code>CONFIG_NET_MAX_CONTEXTS=10</code> ensures that multiple networking contexts can be managed concurrently, allowing seamless handling of multiple network sockets, connections, or protocols.</p> <p>A key aspect of connectivity in the embedded proplet is the integration of MQTT for message-based communication. The configuration enables the MQTT library and socket support for seamless data exchange between Propeller nodes and the orchestrator. The MQTT client is configured to maintain session state and use a keep-alive mechanism to ensure continuous connectivity.</p> <p>To enhance reliability, the embedded proplet supports the Last Will and Testament (LWT) feature of MQTT. The feature ensures that in the event of an unexpected disconnection of the embedded proplet, a predefined message is sent to the broker, notifying the Manager of the disconnection event. Additionally, the embedded proplet leverages Quality of Service (QoS) levels to provide varying degrees of message reliability, ensuring that critical messages are received without duplication or loss. The configuration also allows for adaptive reconnection strategies, ensuring that embedded proplets can re-establish connections in case of temporary network disruptions.</p> <p>For debugging and diagnostics, the configuration enables logging with a default logging level of 3. This provides useful insights into networking operations without excessive verbosity. The system also supports early console output (<code>CONFIG_EARLY_CONSOLE=y</code>) and network statistics tracking (<code>CONFIG_NET_STATISTICS=y</code>), allowing developers to monitor network performance and diagnose potential issues efficiently.</p> <ul> <li>WASM Handler : Interfaces with WAMR to load, execute, and manage WASM modules on the embedded device, enforcing isolation and resource constraints.</li> <li>Configuration and Build System: Defines system parameters, dependencies, and build instructions to streamline deployment on Zephyr OS.</li> <li>Data Serialization: Handles encoding and decoding of structured data in JSON format for efficient message parsing within the Propeller network.</li> </ul>"},{"location":"embedded-proplet/#setup","title":"Setup","text":"<p>When running:</p> <pre><code>west build -b esp32s3_devkitc/esp32s3/procpu -p auto .\n</code></pre> <p>CMake might stop with:</p> <pre><code>Could NOT find Threads (missing: Threads_FOUND)\n...\nFATAL ERROR: command exited with status 1: ...\n</code></pre> <p>This is triggered by WAMR\u2019s top-level <code>CMakeLists.txt</code> in <code>wasm-micro-runtime/</code>, specifically the lines:</p> <pre><code>set (THREADS_PREFER_PTHREAD_FLAG ON)\nfind_package(Threads REQUIRED)\n</code></pre> <p>because <code>WAMR</code> tries to detect and link <code>pthread</code> on the <code>host</code> system (Linux, Windows, macOS).</p> <ul> <li>However, on <code>Zephyr</code>, especially for an <code>ESP32-S3</code> target, we do not use the host\u2019s pthread library at all. There\u2019s no concept of a local Linux \u201cThreads\u201d library in a cross-compile for an Xtensa SoC.</li> <li>So CMake\u2019s <code>find_package(Threads REQUIRED)</code> fails with \u201cCould NOT find Threads\u201d because there\u2019s no suitable host pthread dev package to fulfill that requirement in the cross-compilation environment.</li> </ul> <p>Installing host pthread dev files sometimes helps in a purely local scenario, but it can still fail or is semantically incorrect for embedded cross-builds.</p> <p>The Solution is to bypass <code>find_package(Threads REQUIRED)</code> on Zephyr. So, in your WAMR repo file <code>wasm-micro-runtime/CMakeLists.txt</code>, locate where it calls:</p> <pre><code>find_package(Threads REQUIRED)\n</code></pre> <p>and wrap that call in a conditional so it does not run on Zephyr:</p> <pre><code>if (NOT WAMR_BUILD_PLATFORM STREQUAL \"zephyr\")\n  set (THREADS_PREFER_PTHREAD_FLAG ON)\n  find_package(Threads REQUIRED)\nendif()\n</code></pre> <p>then clean and rebuild:</p> <pre><code>rm -rf build\nwest build -b esp32s3_devkitc/esp32s3/procpu -p auto .\n</code></pre>"},{"location":"embedded-proplet/#dynamic-linking","title":"Dynamic Linking","text":"<p>Zephyr does not support dynamic linking on most embedded targets (including ESP32-S3). When WAMR\u2019s CMakeLists tries:</p> <pre><code>add_library(iwasm_shared SHARED ...)\n</code></pre> <p>you see the warning:</p> <pre><code>ADD_LIBRARY called with SHARED option but the target platform does not support\ndynamic linking. Building a STATIC library instead. This may lead to problems.\n</code></pre> <p>This is harmless on Zephyr\u2014it just forces the shared library to become a static library\u2014but it can be confusing. To fix it, you should skip building a shared library entirely when you are on Zephyr.</p> <p>In your <code>modules/wamr/wasm-micro-runtime/CMakeLists.txt</code>, right after you set <code>WAMR_BUILD_PLATFORM=\"zephyr\"</code>, force shared libs off:</p> <pre><code>if (WAMR_BUILD_PLATFORM STREQUAL \"zephyr\")\n  set(WAMR_BUILD_SHARED 0 CACHE BOOL \"Disable shared library on Zephyr\" FORCE)\nendif ()\n</code></pre> <p>If that\u2019s in place, the <code>if (WAMR_BUILD_SHARED)</code> block that calls:</p> <pre><code>add_library (iwasm_shared SHARED ${WAMR_RUNTIME_LIB_SOURCE})\n...\n</code></pre> <p>will not run. Hence, no \u201cshared library\u201d warning on Zephyr.</p> <p>Alternatively, you can guard the <code>iwasm_shared</code> block with:</p> <pre><code># SHARED LIBRARY\nif (WAMR_BUILD_SHARED AND NOT WAMR_BUILD_PLATFORM STREQUAL \"zephyr\")\n    add_library (iwasm_shared SHARED ${WAMR_RUNTIME_LIB_SOURCE})\n    ...\nendif ()\n</code></pre> <p>That way, the shared library part is skipped on Zephyr.</p> <p>Either approach ensures the warning disappears, and you end up only with a static WAMR build (<code>iwasm_static</code>) on Zephyr, which is what you actually need.</p>"},{"location":"embedded-proplet/#configuration-files","title":"Configuration Files","text":"<p>Configuration options are split between <code>prj.conf</code> and <code>esp32s3-devkitc.conf</code>, which Zephyr's build system merges based on the board and build target. Follow best practices to avoid conflicting settings.</p>"},{"location":"embedded-proplet/#purpose-of-each-file","title":"Purpose of Each File","text":"<ol> <li> <p><code>prj.conf</code>:</p> </li> <li> <p>Application-specific settings.</p> </li> <li> <p>Defines project-specific features, libraries, and behaviors.</p> </li> <li> <p><code>esp32s3-devkitc.conf</code>:</p> </li> <li> <p>Board-specific settings.</p> </li> <li> <p>Configures hardware-specific options for the ESP32-S3.</p> </li> <li> <p><code>esp32s3-devkitc.overlay</code>:</p> </li> <li>Extends or modifies the board's Devicetree source.</li> </ol>"},{"location":"embedded-proplet/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<p>Zephyr processes files in this order:</p> <ol> <li>Default Kconfig files: Zephyr subsystems and modules.</li> <li>Board files: <code>esp32s3-devkitc.conf</code> overrides defaults.</li> <li>Application files: <code>prj.conf</code> overrides earlier settings.</li> </ol> <p>If a setting appears in both <code>prj.conf</code> and <code>esp32s3-devkitc.conf</code>, the value in <code>prj.conf</code> takes precedence. Avoid duplicate definitions to prevent conflicts.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Before proceeding, install the following prerequisites:</p> <ul> <li>A Go compiler (Go 1.24 or later)</li> <li>Make</li> <li>Docker</li> <li>Wasmtime</li> <li>TinyGo</li> <li>Mosquitto Tools</li> <li>rustup</li> </ul> <p>Note: <code>rustup</code> will install the Rust toolchain and <code>cargo</code>. You will also use it to add WebAssembly targets.</p>"},{"location":"getting-started/#clone-the-repository","title":"Clone the repository","text":"<p>Clone the repository:</p> <pre><code>git clone https://github.com/absmach/propeller.git\ncd propeller\n</code></pre>"},{"location":"getting-started/#build-and-install-the-artifacts","title":"Build and Install the Artifacts","text":"<p>To install the Magistrala CLI, follow the instructions.</p> <p>This step compiles all Propeller components (manager, proplet, CLI, proxy, and example WASM modules). Run the following:</p> <pre><code>make all -j $(nproc)\nmake install\n</code></pre>"},{"location":"getting-started/#if-make-install-fails","title":"If <code>make install</code> fails","text":"<p>You likely don\u2019t have your Go binary path (<code>$GOBIN</code>) configured. Set it up like this:</p> <pre><code>export GOBIN=$HOME/go/bin\nexport PATH=$PATH:$GOBIN\n</code></pre> <p>Run <code>make install</code> again afterward.</p>"},{"location":"getting-started/#what-the-build-process-does","title":"What the build process does","text":"<p>During the build, you will see output similar to:</p> <pre><code>CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build ... -o build/manager cmd/manager/main.go\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build ... -o build/proplet cmd/proplet/main.go\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build ... -o build/cli cmd/cli/main.go\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build ... -o build/proxy cmd/proxy/main.go\n\nGOOS=js GOARCH=wasm tinygo build -buildmode=c-shared -o build/addition.wasm     -target wasip1 examples/addition/addition.go\nGOOS=js GOARCH=wasm tinygo build -buildmode=c-shared -o build/compute.wasm      -target wasip1 examples/compute/compute.go\nGOOS=js GOARCH=wasm tinygo build -buildmode=c-shared -o build/hello-world.wasm  -target wasip1 examples/hello-world/hello-world.go\n</code></pre> <p>This means:</p> <ul> <li>All Go binaries were built and placed into <code>build/</code></li> <li>All example WASM modules were built using TinyGo into <code>build/</code></li> </ul>"},{"location":"getting-started/#installing-the-artifacts","title":"Installing the artifacts","text":"<p><code>make install</code> copies the compiled binaries into your <code>$GOBIN</code> directory so you can run them directly from your terminal:</p> <pre><code>cp build/cli      $GOBIN/propeller-cli\ncp build/manager  $GOBIN/propeller-manager\ncp build/proplet  $GOBIN/propeller-proplet\ncp build/proxy    $GOBIN/propeller-proxy\n</code></pre> <p>Once installed, you can run the commands simply as:</p> <pre><code>propeller-manager\npropeller-proplet\npropeller-cli\npropeller-proxy\n</code></pre>"},{"location":"getting-started/#working-with-the-rust-wasi-http-example","title":"Working with the Rust WASI HTTP Example","text":"<p>Propeller includes an example Rust WebAssembly HTTP component: <code>sample-wasi-http-rust</code>. Running the Rust WASI example validates your Rust/WASM setup and shows how a single WASI HTTP component works before integrating it with Propeller. This section shows you how to fetch it, build it, run it, and test it.</p> <p>You can also refer to the original project\u2019s instructions here: https://github.com/bytecodealliance/sample-wasi-http-rust#sample-wasihttp-in-rust</p>"},{"location":"getting-started/#1-initialize-the-git-submodules","title":"1. Initialize the Git submodules","text":"<p>From the root of the <code>propeller</code> repository:</p> <pre><code>git submodule update --init\ncd examples/sample-wasi-http-rust\n</code></pre> <p>This pulls in the <code>sample-wasi-http-rust</code> example code.</p>"},{"location":"getting-started/#2-install-the-required-rust-target","title":"2. Install the required Rust target","text":"<p>The example builds to a WebAssembly target. If you see errors about missing <code>wasm32-wasip2</code> or <code>wasm32-wasip1</code>, you need to add the target.</p> <p>A safe default is to add the Preview 2 target:</p> <pre><code>rustup target add wasm32-wasip2\n</code></pre> <p>If this command fails, update Rust first:</p> <pre><code>rustup update\nrustup target add wasm32-wasip2\n</code></pre>"},{"location":"getting-started/#3-build-the-rust-example","title":"3. Build the Rust example","text":"<p>Build the example for the WebAssembly target:</p> <pre><code>cargo build --target wasm32-wasip2\n</code></pre> <p>If the build completes successfully, you will see a message similar to:</p> <pre><code>Finished `dev` profile [unoptimized + debuginfo] target(s) in X.XXs\n</code></pre> <p>At this point, you have a compiled WASI HTTP component.</p>"},{"location":"getting-started/#4-install-cargo-component-once","title":"4. Install <code>cargo-component</code> (once)","text":"<p><code>cargo-component</code> makes it easy to work with Wasm components and run them with Wasmtime.</p> <p>Install it using <code>cargo</code>:</p> <pre><code>cargo install cargo-component\n</code></pre> <p>You only need to do this once on your machine.</p>"},{"location":"getting-started/#5-serve-the-rust-component-locally","title":"5. Serve the Rust component locally","text":"<p>From inside <code>examples/sample-wasi-http-rust</code>:</p> <pre><code>cargo component serve\n</code></pre> <p>On first run, this may automatically install the <code>wasm32-wasip1</code> component standard library and then print something like:</p> <pre><code>Creating component target/wasm32-wasip1/debug/sample_wasi_http_rust.wasm\nRunning `target/wasm32-wasip1/debug/sample_wasi_http_rust.wasm`\nServing HTTP on http://0.0.0.0:8080/\n</code></pre> <p>This means your WASI HTTP component is now running as an HTTP server on port <code>8080</code>.</p> <p>Leave this terminal open while the server is running.</p>"},{"location":"getting-started/#6-test-the-rust-http-endpoints","title":"6. Test the Rust HTTP endpoints","text":"<p>Open a new terminal and run the following commands to test the different routes:</p>"},{"location":"getting-started/#hello-world-route","title":"Hello world route","text":"<pre><code>curl -v http://127.0.0.1:8080/\n</code></pre> <p>You should see a <code>200 OK</code> response with a body similar to:</p> <pre><code>Hello, wasi:http/proxy world!\n</code></pre>"},{"location":"getting-started/#wait-route","title":"Wait route","text":"<pre><code>curl -v http://127.0.0.1:8080/wait\n</code></pre> <p>This route sleeps briefly before responding, and you should see:</p> <pre><code>slept for 1001 millis\n</code></pre>"},{"location":"getting-started/#echo-body-route","title":"Echo body route","text":"<pre><code>curl -v http://127.0.0.1:8080/echo -d 'hello from John Doe'\n</code></pre> <p>The response will echo the request body back:</p> <pre><code>hello from John Doe\n</code></pre>"},{"location":"getting-started/#echo-headers-route","title":"Echo headers route","text":"<pre><code>curl -v http://127.0.0.1:8080/echo-headers -H 'X-Test: 123' -H 'X-Foo: bar'\n</code></pre> <p>You will see the headers reflected in the response:</p> <pre><code>x-foo: bar\nuser-agent: curl/...\naccept: */*\nx-test: 123\n</code></pre>"},{"location":"getting-started/#echo-trailers-route","title":"Echo trailers route","text":"<pre><code>curl -v http://127.0.0.1:8080/echo-trailers\n</code></pre> <p>This demonstrates handling of HTTP trailers over WASI HTTP.</p> <p>When you are done: Go back to the terminal running <code>cargo component serve</code> and press <code>Ctrl+C</code> to stop the server.</p>"},{"location":"getting-started/#run-supermq-and-propeller","title":"Run SuperMQ and Propeller","text":"<p>Propeller needs to talk to a running SuperMQ instance. To get everything working, you\u2019ll always do these three high-level steps:</p> <ol> <li>Start SuperMQ \u2013 so the CLI has something to talk to.</li> <li>Provision SuperMQ with <code>propeller-cli provision</code> \u2013 this creates the domain, clients, channels, and writes a <code>config.toml</code> file with all the IDs and keys.</li> <li>Start (or restart) the Propeller services \u2013 so <code>propeller-manager</code>, <code>propeller-proplet</code>, and <code>propeller-proxy</code> can read <code>config.toml</code> and connect correctly.</li> </ol> <p>You can run the services in two ways:</p> <ul> <li>Option 1 (recommended): everything via Docker</li> <li>Option 2: run the Propeller binaries directly on your machine</li> </ul> <p>Pick one option and follow it from start to finish.</p>"},{"location":"getting-started/#option-1-run-everything-with-docker-recommended","title":"Option 1: Run everything with Docker (recommended)","text":"<p>In this mode, Docker runs:</p> <ul> <li>SuperMQ core services (auth, users, clients, domains, channels, adapters, etc.)</li> <li>Propeller services: manager, proplet, and proxy</li> </ul> <p>When you run <code>make start-supermq</code>, you are starting both SuperMQ and the Propeller services defined in <code>docker/compose.yaml</code>.</p>"},{"location":"getting-started/#1-start-the-supermq-docker-stack-first-time","title":"1. Start the SuperMQ Docker stack (first time)","text":"<p>From the root of the <code>propeller</code> repo:</p> <pre><code>cd propeller\nmake start-supermq\n</code></pre> <p>This runs:</p> <pre><code>docker compose -f docker/compose.yaml --env-file docker/.env up -d\n</code></pre> <p>At this point:</p> <ul> <li>SuperMQ is up and reachable.</li> <li>Propeller containers (manager, proplet, proxy) will fail to start correctly on the first run.   That\u2019s OK - they don\u2019t have credentials yet because <code>config.toml</code> doesn\u2019t exist.</li> </ul> <p>We only need SuperMQ up now so we can provision it.</p>"},{"location":"getting-started/#2-provision-supermq-with-propeller-cli","title":"2. Provision SuperMQ with <code>propeller-cli</code>","text":"<p>Now we create everything Propeller needs inside SuperMQ and generate the config file.</p> <p>Run:</p> <pre><code>propeller-cli provision\n</code></pre> <p>This command will:</p> <ul> <li>Log you into SuperMQ (you must have a SuperMQ user already created; if not, create one using the supermq-cli, <code>curl</code>, or the web UI).</li> <li>Create a domain</li> <li>Log your user into that domain</li> <li>Create a manager client</li> <li>Create a proplet client</li> <li>Create a manager channel</li> <li>Connect the manager client to the manager channel</li> <li>Connect the proplet client to the manager channel</li> <li>Write all of these IDs and keys into a <code>config.toml</code> file in the current directory</li> </ul> <p>The process will look something like this:</p> <p></p> <p>If it succeeds, you\u2019ll see:</p> <pre><code>Successfully created config.toml file\n</code></pre> <p>Your <code>config.toml</code> will look like:</p> <pre><code># SuperMQ Configuration\n\n[manager]\ndomain_id = \"182c0907-002c-4bfd-8bf3-e4f40c58dde6\"\nclient_id = \"f2fe9a33-144a-4346-a5d6-38e2eb07815e\"\nclient_key = \"ef7da52b-c01f-4b62-9502-6723d639405b\"\nchannel_id = \"8c6e1e6c-fc89-43b4-b00b-884a690c7419\"\n\n[proplet]\ndomain_id = \"182c0907-002c-4bfd-8bf3-e4f40c58dde6\"\nclient_id = \"fa407362-9c5f-41b8-9a09-9d0c0b039287\"\nclient_key = \"991c4d03-2f2c-4ba5-97a6-45bead85457e\"\nchannel_id = \"8c6e1e6c-fc89-43b4-b00b-884a690c7419\"\n\n[proxy]\ndomain_id = \"182c0907-002c-4bfd-8bf3-e4f40c58dde6\"\nclient_id = \"fa407362-9c5f-41b8-9a09-9d0c0b039287\"\nclient_key = \"991c4d03-2f2c-4ba5-97a6-45bead85457e\"\nchannel_id = \"8c6e1e6c-fc89-43b4-b00b-884a690c7419\"\n</code></pre>"},{"location":"getting-started/#3-mount-configtoml-into-the-docker-services","title":"3. Mount <code>config.toml</code> into the Docker services","text":"<p>For the Docker containers to see <code>config.toml</code>, we need to mount it.</p> <p>If the compose file uses a path under <code>docker/</code>, copy the file:</p> <pre><code>cp config.toml docker/config.toml\n</code></pre> <p>Then, in <code>docker/compose.yaml</code>, make sure the Propeller services (manager, proplet, proxy) have a volume like this:</p> <pre><code>volumes:\n  - ./config.toml:/config.toml\n# or, if you copied it into docker/:\n#  - ./config.toml:/config.toml\n</code></pre> <p>Uncomment or add these lines as needed.</p>"},{"location":"getting-started/#4-restart-the-docker-stack-so-propeller-reads-configtoml","title":"4. Restart the Docker stack so Propeller reads <code>config.toml</code>","text":"<p>Now that:</p> <ul> <li>SuperMQ is provisioned, and</li> <li><code>config.toml</code> exists and is mounted into the containers,</li> </ul> <p>we restart the stack:</p> <pre><code>make stop-supermq\nmake start-supermq\n</code></pre> <p>On this second start:</p> <ul> <li><code>propeller-manager</code>, <code>propeller-proplet</code>, and <code>propeller-proxy</code> start up,</li> <li>They see <code>/config.toml</code> inside the container,</li> <li>They read the <code>[manager]</code>, <code>[proplet]</code>, and <code>[proxy]</code> sections,</li> <li>They connect to SuperMQ using the correct domain, client IDs, client keys, and channel IDs.</li> </ul> <p>At this point, your system is up and ready to use.</p>"},{"location":"getting-started/#option-2-run-propeller-binaries-directly-without-docker","title":"Option 2: Run Propeller binaries directly (without Docker)","text":"<p>In this mode:</p> <ul> <li>SuperMQ may still run in Docker (via <code>make start-supermq</code>), but</li> <li>You run the Propeller processes (<code>propeller-manager</code>, <code>propeller-proplet</code>, <code>propeller-proxy</code>) directly on your host.</li> </ul> <p>The provisioning step is the same as in Option 1:</p> <ol> <li>Start SuperMQ (Docker or however you like)</li> <li>Run <code>propeller-cli provision</code> to generate <code>config.toml</code></li> </ol> <p>Make sure <code>config.toml</code> is in the directory where you will start the binaries, or set env vars to point them at the correct file.</p>"},{"location":"getting-started/#1-start-the-manager","title":"1. Start the manager","text":"<pre><code>propeller-manager\n</code></pre> <p>If everything is configured correctly, you\u2019ll see logs similar to:</p> <pre><code>{\"time\":\"2025-06-12T14:13:56.74162598+03:00\",\"level\":\"INFO\",\"msg\":\"MQTT connection lost\"}\n{\"time\":\"2025-06-12T14:13:56.793894993+03:00\",\"level\":\"INFO\",\"msg\":\"Subscribe to MQTT topic completed successfully\",\"duration\":\"52.272009ms\"}\n{\"time\":\"2025-06-12T14:13:56.794210043+03:00\",\"level\":\"INFO\",\"msg\":\"manager service http server listening at localhost:7070 without TLS\"}\n</code></pre> <p>The manager exposes an HTTP API on <code>localhost:7070</code>.</p>"},{"location":"getting-started/#2-start-the-proplet","title":"2. Start the proplet","text":"<p>In another terminal:</p> <pre><code>propeller-proplet\n</code></pre> <p>Example logs:</p> <pre><code>{\"time\":\"2025-06-12T14:14:44.362072799+03:00\",\"level\":\"INFO\",\"msg\":\"MQTT connection lost\"}\n{\"time\":\"2025-06-12T14:14:44.398147897+03:00\",\"level\":\"INFO\",\"msg\":\"Proplet service is running.\"}\n</code></pre> <p>A proplet will automatically register itself with the manager.</p>"},{"location":"getting-started/#3-start-the-proxy","title":"3. Start the proxy","text":"<p>The proxy needs to know which OCI registry to pull WebAssembly images from. Set a few environment variables, then start it:</p> <pre><code>export PROXY_REGISTRY_URL=\"docker.io\"\nexport PROXY_AUTHENTICATE=\"TRUE\"\nexport PROXY_REGISTRY_USERNAME=\"\"   # set if your registry requires auth\nexport PROXY_REGISTRY_PASSWORD=\"\"   # set if your registry requires auth\n\npropeller-proxy\n</code></pre> <p>Example logs:</p> <pre><code>{\"time\":\"2025-06-12T14:15:18.438848211+03:00\",\"level\":\"INFO\",\"msg\":\"MQTT connection lost\"}\n{\"time\":\"2025-06-12T14:15:18.438823293+03:00\",\"level\":\"INFO\",\"msg\":\"successfully initialized MQTT and HTTP config\"}\n{\"time\":\"2025-06-12T14:15:18.438886395+03:00\",\"level\":\"INFO\",\"msg\":\"starting proxy service\"}\n{\"time\":\"2025-06-12T14:15:18.452592155+03:00\",\"level\":\"INFO\",\"msg\":\"successfully subscribed to topic\"}\n</code></pre>"},{"location":"getting-started/#postman-collection","title":"Postman Collection","text":"<p>This is a collection of the API calls that can be used to interact with the Propeller system.</p>"},{"location":"getting-started/#api","title":"API","text":""},{"location":"getting-started/#list-proplets","title":"List Proplets","text":"<pre><code>curl -X GET \"http://localhost:7070/proplets\"\n</code></pre> <p>This will output a response like the following:</p> <pre><code>{\n  \"offset\": 0,\n  \"limit\": 100,\n  \"total\": 1,\n  \"proplets\": [\n    {\n      \"id\": \"fa407362-9c5f-41b8-9a09-9d0c0b039287\",\n      \"name\": \"Wojahn-Omohundro\",\n      \"task_count\": 1,\n      \"alive\": true,\n      \"alive_history\": [\n        \"2025-06-12T14:22:04.379038459+03:00\",\n        \"2025-06-12T14:22:14.378443596+03:00\",\n        \"2025-06-12T14:22:24.379305586+03:00\",\n        \"2025-06-12T14:22:34.378765631+03:00\",\n        \"2025-06-12T14:22:44.381274342+03:00\",\n        \"2025-06-12T14:22:54.378152057+03:00\",\n        \"2025-06-12T14:23:04.380171407+03:00\",\n        \"2025-06-12T14:23:14.379503767+03:00\",\n        \"2025-06-12T14:23:24.379971214+03:00\",\n        \"2025-06-12T14:23:34.378886406+03:00\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"getting-started/#create-task","title":"Create task","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"name\": \"add\", \"inputs\": [10, 20]}'\n</code></pre> <p>This will output a response like the following:</p> <pre><code>{\n  \"id\": \"e9858e56-a1dd-4e5a-9288-130f7be783ed\",\n  \"name\": \"add\",\n  \"state\": 0,\n  \"cli_args\": null,\n  \"inputs\": [10, 20],\n  \"start_time\": \"0001-01-01T00:00:00Z\",\n  \"finish_time\": \"0001-01-01T00:00:00Z\",\n  \"created_at\": \"2025-06-12T14:25:22.407167091+03:00\",\n  \"updated_at\": \"0001-01-01T00:00:00Z\"\n}\n</code></pre> <p>You can use the CLI to create a task as follows:</p> <pre><code># propeller-cli tasks create &lt;name&gt;\npropeller-cli tasks create demo\n</code></pre> <p>This will output a response like the following:</p> <pre><code>{\n  \"created_at\": \"2025-09-16T10:25:31.491528704Z\",\n  \"finish_time\": \"0001-01-01T00:00:00Z\",\n  \"id\": \"2ccb6b7c-3ce8-4c27-be19-01172954d593\",\n  \"name\": \"demo\",\n  \"start_time\": \"0001-01-01T00:00:00Z\",\n  \"updated_at\": \"0001-01-01T00:00:00Z\"\n}\n</code></pre>"},{"location":"getting-started/#get-a-task","title":"Get a task","text":"<pre><code>curl -X GET \"http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed\"\n</code></pre> <p>This will output a response like the following:</p> <pre><code>{\n  \"id\": \"e9858e56-a1dd-4e5a-9288-130f7be783ed\",\n  \"name\": \"add\",\n  \"state\": 0,\n  \"cli_args\": null,\n  \"inputs\": [10, 20],\n  \"start_time\": \"0001-01-01T00:00:00Z\",\n  \"finish_time\": \"0001-01-01T00:00:00Z\",\n  \"created_at\": \"2025-06-12T14:25:22.407167091+03:00\",\n  \"updated_at\": \"0001-01-01T00:00:00Z\"\n}\n</code></pre> <p>You can use the CLI to get a task as follows:</p> <pre><code># propeller-cli tasks view &lt;id&gt;\npropeller-cli tasks view 2ccb6b7c-3ce8-4c27-be19-01172954d593\n</code></pre> <p>This will output a response like the following:</p> <pre><code>{\n  \"created_at\": \"2025-09-16T10:25:31.491528704Z\",\n  \"finish_time\": \"0001-01-01T00:00:00Z\",\n  \"id\": \"2ccb6b7c-3ce8-4c27-be19-01172954d593\",\n  \"name\": \"demo\",\n  \"start_time\": \"0001-01-01T00:00:00Z\",\n  \"updated_at\": \"0001-01-01T00:00:00Z\"\n}\n</code></pre>"},{"location":"getting-started/#upload-wasm-file","title":"Upload Wasm File","text":"<pre><code>curl -X PUT \"http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed/upload\" \\\n-F 'file=@&lt;propeller_path&gt;/build/addition.wasm'\n</code></pre>"},{"location":"getting-started/#update-task-with-base64-encoded-wasm-file","title":"Update task with base64 encoded Wasm file","text":"<pre><code>curl --location --request PUT 'http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed' \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"file\": \"AGFzbQEAAAABBwFgAn9/AX8DAgEABwgBBG1haW4AAAoJAQcAIAAgAWoL\"\n}'\n</code></pre> <pre><code>propeller-cli tasks update e9858e56-a1dd-4e5a-9288-130f7be783ed '{\"file\": \"AGFzbQEAAAABBwFgAn9/AX8DAgEABwgBBG1haW4AAAoJAQcAIAAgAWoL\"}'\n</code></pre>"},{"location":"getting-started/#start-a-task","title":"Start a task","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed/start\"\n</code></pre> <p>You can use the CLI to start a task as follows:</p> <pre><code># propeller-cli tasks start &lt;id&gt;\npropeller-cli tasks start 2ccb6b7c-3ce8-4c27-be19-01172954d593\n</code></pre> <p>This will output a response like the following:</p> <pre><code>ok\n</code></pre>"},{"location":"getting-started/#stop-a-task","title":"Stop a task","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks/e9858e56-a1dd-4e5a-9288-130f7be783ed/stop\"\n</code></pre>"},{"location":"getting-started/#creating-tasks-from-oci-registry-images","title":"Creating Tasks from OCI Registry Images","text":"<p>For WebAssembly modules stored in an OCI registry, you can specify the image URL during task creation. The proxy will automatically retrieve the WASM file from the registry when the task starts, eliminating the need for manual file uploads.</p> <pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"name\": \"add\", \"inputs\": [10, 20], \"image_url\": \"docker.io/mrstevenyaga/add.wasm\"}'\n</code></pre> <p>The proxy will handle pulling the image from the specified OCI registry during task execution, streamlining the deployment process.</p>"},{"location":"manager/","title":"Manager","text":""},{"location":"manager/#overview","title":"Overview","text":"<p>The Manager service is a central component of the Propeller system, responsible for managing tasks and proplets. It provides a set of APIs for task and proplet management, handles task scheduling and execution, and monitors the state of tasks and proplets. The architecture of the Manager service is designed to be modular, scalable, and maintainable, leveraging various components and middleware to achieve these goals.</p>"},{"location":"manager/#architectural-components","title":"Architectural Components","text":""},{"location":"manager/#1-service-interface","title":"1. Service Interface","text":"<p>The <code>Service</code> interface defines the core functionalities provided by the Manager service. It includes methods for managing proplets and tasks, as well as for subscribing to MQTT topics. This interface ensures that the service can be easily extended or replaced with different implementations.</p>"},{"location":"manager/#2-api-endpoints","title":"2. API Endpoints","text":"<p>The Manager service exposes several HTTP endpoints for interacting with tasks and proplets. These endpoints are implemented using the Go-Kit library, which provides a structured way to define and handle HTTP requests and responses.</p>"},{"location":"manager/#3-middleware","title":"3. Middleware","text":"<p>The Manager service includes several middleware components that enhance its functionality:</p> <ul> <li>Logging Middleware: Logs the details of each service method call, including the duration and any errors that occurred.</li> <li>Metrics Middleware: Collects metrics for each service method call, such as the number of calls and the latency.</li> <li>Tracing Middleware: Adds tracing information to each service method call, using OpenTelemetry to provide distributed tracing capabilities.</li> </ul>"},{"location":"manager/#4-storage","title":"4. Storage","text":"<p>The Manager service uses storage components to persist tasks and proplets. These storage components are abstracted behind interfaces, allowing for different storage implementations (e.g., in-memory, database) to be used interchangeably. The storage components include:</p> <ul> <li>Tasks Storage: Stores task details.</li> <li>Proplets Storage: Stores proplet details.</li> <li>Task-Proplet Mapping Storage: Stores the mapping between tasks and proplets.</li> </ul>"},{"location":"manager/#5-scheduler","title":"5. Scheduler","text":"<p>The Manager service uses a scheduler to select the appropriate proplet for a task based on certain criteria. The scheduler is responsible for distributing tasks across available proplets in an efficient manner, ensuring optimal resource utilization. The current implementation uses a round-robin scheduler, which selects the next available proplet in a cyclic manner.</p>"},{"location":"manager/#6-pubsub","title":"6. PubSub","text":"<p>The Manager service uses a PubSub component to publish and subscribe to MQTT topics for task and proplet management. This component allows the service to communicate with other components of the Propeller system, such as proplets, to coordinate task execution and monitor their state.</p>"},{"location":"manager/#7-internal-handlers","title":"7. Internal Handlers","text":"<p>The Manager service includes internal handlers for managing proplets and tasks. These handlers are responsible for processing messages received from MQTT topics and updating the state of tasks and proplets accordingly. The handlers include:</p> <ul> <li>Proplet Handlers: Handle the creation, liveness updates, and result updates of proplets.</li> <li>Task Handlers: Handle the creation, updating, and deletion of tasks.</li> </ul>"},{"location":"manager/#8-health-and-metrics-endpoints","title":"8. Health and Metrics Endpoints","text":"<p>The Manager service includes endpoints for health checks and metrics collection:</p> <ul> <li>Health Endpoint: Provides a health check endpoint (<code>/health</code>) that returns the health status of the service.</li> <li>Metrics Endpoint: Provides a metrics endpoint (<code>/metrics</code>) that exposes Prometheus metrics for the service.</li> </ul>"},{"location":"manager/#data-flow","title":"Data Flow","text":""},{"location":"manager/#1-task-creation","title":"1. Task Creation","text":"<ul> <li>A client sends a <code>POST</code> request to the <code>/tasks</code> endpoint with the task details.</li> <li>The service creates a new task, assigns a unique ID, and stores it in the tasks storage.</li> <li>The service returns the created task to the client.</li> </ul>"},{"location":"manager/#2-task-execution","title":"2. Task Execution","text":"<ul> <li>A client sends a <code>POST</code> request to the <code>/tasks/{taskID}/start</code> endpoint to start a task.</li> <li>The service retrieves the task from the tasks storage and selects an appropriate proplet using the scheduler.</li> <li>The task can also specify which proplet to use.</li> <li>The service publishes a start message to the MQTT topic for the selected proplet.</li> <li>The proplet executes the task and publishes the results to the MQTT topic.</li> <li>The service processes the results and updates the task state in the tasks storage.</li> </ul>"},{"location":"manager/#3-proplet-management","title":"3. Proplet Management","text":"<ul> <li>Proplets periodically send liveness updates to the MQTT topic.</li> <li>The service processes the liveness updates and updates the state of the proplets in the proplets storage.</li> <li>The service can also handle the creation of new proplets and the updating of proplet details.</li> </ul>"},{"location":"monitoring/","title":"Monitoring","text":""},{"location":"monitoring/#overview","title":"Overview","text":"<p>Propeller tracks OS-level metrics for every WebAssembly task running on proplets. The system collects CPU usage, memory consumption, disk I/O, thread counts, and more with minimal performance overhead.</p> <p>Propeller tracks OS-level metrics for every WebAssembly task running on proplets. The system collects CPU usage, memory consumption, disk I/O, thread counts, and more with minimal performance overhead. The Rust proplet includes built-in monitoring using the <code>sysinfo</code> crate for cross-platform metrics. This provides compatibility across Linux, macOS, and Windows environments.</p>"},{"location":"monitoring/#architecture","title":"Architecture","text":"<p>Each proplet monitors its running tasks independently and reports metrics to the manager via MQTT. The manager aggregates metrics from all proplets, stores historical data, and exposes REST API endpoints for querying.</p> <p></p>"},{"location":"monitoring/#data-flow","title":"Data Flow","text":"<ol> <li>Proplet spawns a monitoring thread for each task</li> <li>Thread collects process metrics at configured intervals (1-120 seconds)</li> <li>Metrics are published to MQTT topics:</li> <li>Proplet-level: <code>m/{domain}/c/{channel}/control/proplet/metrics</code></li> <li>Task-level: <code>m/{domain}/c/{channel}/control/proplet/task_metrics</code></li> <li>Manager receives and stores metrics in memory</li> <li>API clients query metrics via HTTP endpoints</li> </ol>"},{"location":"monitoring/#component-responsibilities","title":"Component Responsibilities","text":"<ul> <li>Proplet: Collects task-level process metrics using system APIs</li> <li>Manager: Aggregates, stores, and serves metrics via REST API</li> <li>MQTT Broker: Routes metrics between proplets and manager</li> </ul>"},{"location":"monitoring/#metrics","title":"Metrics","text":"<p>The system tracks the following process-level metrics:</p> Metric Description Unit CPU Usage Process CPU time as percentage of one core Percent (0-100+) Memory Usage Process memory consumption Bytes Memory Percent Process memory as percentage of total RAM Percent (0-100) Disk Read Cumulative bytes read from disk Bytes Disk Write Cumulative bytes written to disk Bytes Uptime Process runtime since start Seconds Thread Count Number of OS threads Integer File Descriptors Open file handles (Linux/macOS) Integer <p>Each metric sample includes an ISO 8601 timestamp for time-series analysis.</p>"},{"location":"monitoring/#monitoring-profiles","title":"Monitoring Profiles","text":"<p>Profiles define which metrics to collect, how often, and how much history to retain.</p>"},{"location":"monitoring/#standard","title":"Standard","text":"<p>Balanced monitoring for typical tasks.</p> <pre><code>{\n  \"enabled\": true,\n  \"interval\": 10,\n  \"collect_cpu\": true,\n  \"collect_memory\": true,\n  \"collect_disk_io\": true,\n  \"collect_threads\": true,\n  \"collect_file_descriptors\": true,\n  \"export_to_mqtt\": true,\n  \"retain_history\": true,\n  \"history_size\": 100\n}\n</code></pre> <ul> <li>Interval: 10 seconds</li> <li>Metrics: All available</li> <li>History: 100 samples (~16 minutes)</li> <li>Best for: Short to medium tasks, general workloads</li> </ul>"},{"location":"monitoring/#minimal","title":"Minimal","text":"<p>Lightweight monitoring for resource-constrained devices.</p> <pre><code>{\n  \"enabled\": true,\n  \"interval\": 60,\n  \"collect_cpu\": true,\n  \"collect_memory\": true,\n  \"collect_disk_io\": false,\n  \"collect_threads\": false,\n  \"collect_file_descriptors\": false,\n  \"export_to_mqtt\": false,\n  \"retain_history\": false,\n  \"history_size\": 0\n}\n</code></pre> <ul> <li>Interval: 60 seconds</li> <li>Metrics: CPU and memory only</li> <li>History: None</li> <li>Best for: IoT devices, edge nodes, battery-powered systems</li> </ul>"},{"location":"monitoring/#intensive","title":"Intensive","text":"<p>High-frequency monitoring for debugging and profiling.</p> <pre><code>{\n  \"enabled\": true,\n  \"interval\": 1,\n  \"collect_cpu\": true,\n  \"collect_memory\": true,\n  \"collect_disk_io\": true,\n  \"collect_threads\": true,\n  \"collect_file_descriptors\": true,\n  \"export_to_mqtt\": true,\n  \"retain_history\": true,\n  \"history_size\": 1000\n}\n</code></pre> <ul> <li>Interval: 1 second</li> <li>Metrics: All available</li> <li>History: 1000 samples (~16 minutes)</li> <li>Best for: Performance troubleshooting, memory leak detection, development</li> </ul>"},{"location":"monitoring/#batch-processing","title":"Batch processing","text":"<p>Optimized for long-running data processing tasks.</p> <pre><code>{\n  \"enabled\": true,\n  \"interval\": 30,\n  \"collect_cpu\": true,\n  \"collect_memory\": true,\n  \"collect_disk_io\": true,\n  \"collect_threads\": false,\n  \"collect_file_descriptors\": false,\n  \"export_to_mqtt\": true,\n  \"retain_history\": true,\n  \"history_size\": 200\n}\n</code></pre> <ul> <li>Interval: 30 seconds</li> <li>Metrics: CPU, memory, disk I/O</li> <li>History: 200 samples (~100 minutes)</li> <li>Best for: ETL pipelines, batch jobs, data transformations</li> </ul>"},{"location":"monitoring/#long-running-daemon","title":"Long-running daemon","text":"<p>Low-frequency monitoring for background services.</p> <pre><code>{\n  \"enabled\": true,\n  \"interval\": 120,\n  \"collect_cpu\": true,\n  \"collect_memory\": true,\n  \"collect_disk_io\": true,\n  \"collect_threads\": true,\n  \"collect_file_descriptors\": true,\n  \"export_to_mqtt\": true,\n  \"retain_history\": true,\n  \"history_size\": 500\n}\n</code></pre> <ul> <li>Interval: 120 seconds</li> <li>Metrics: All available</li> <li>History: 500 samples (~16 hours)</li> <li>Best for: Background daemons, always-on services, message processors</li> </ul>"},{"location":"monitoring/#automatic-selection","title":"Automatic selection","text":"<p>If no profile is specified, Propeller automatically selects an appropriate profile:</p> <ul> <li>Non-daemon tasks: Standard profile (10s intervals)</li> <li>Daemon tasks: Long-running daemon profile (120s intervals)</li> </ul>"},{"location":"monitoring/#configuration","title":"Configuration","text":""},{"location":"monitoring/#global-settings","title":"Global Settings","text":"<p>Control monitoring behavior using environment variables.</p> <p>Proplet environment variables:</p> <pre><code>export PROPLET_ENABLE_MONITORING=true  # Enable/disable monitoring (default: true)\n</code></pre> <p>This setting applies to all tasks unless overridden by per-task configuration.</p>"},{"location":"monitoring/#per-task-configuration","title":"Per-Task Configuration","text":"<p>Specify a monitoring profile in your task payload to override global settings.</p> <p>Example task with custom monitoring:</p> <pre><code>{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440001\",\n  \"name\": \"compute\",\n  \"image_url\": \"docker.io/myorg/compute:v1\",\n  \"inputs\": [10, 20],\n  \"daemon\": false,\n  \"monitoring_profile\": {\n    \"enabled\": true,\n    \"interval\": 5,\n    \"collect_cpu\": true,\n    \"collect_memory\": true,\n    \"collect_disk_io\": true,\n    \"collect_threads\": true,\n    \"collect_file_descriptors\": true,\n    \"export_to_mqtt\": true,\n    \"retain_history\": true,\n    \"history_size\": 200\n  }\n}\n</code></pre> <p>If no profile is specified, Propeller uses automatic selection based on the task type.</p>"},{"location":"monitoring/#examples","title":"Examples","text":""},{"location":"monitoring/#standard-monitoring","title":"Standard Monitoring","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"compute\",\n  \"image_url\": \"docker.io/myorg/compute:v1\",\n  \"inputs\": [10, 20],\n  \"daemon\": false\n}'\n</code></pre> <p>The task uses the standard profile with 10-second metric intervals.</p>"},{"location":"monitoring/#high-frequency-debugging","title":"High-Frequency Debugging","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"debug_task\",\n  \"image_url\": \"docker.io/myorg/app:debug\",\n  \"inputs\": [],\n  \"monitoring_profile\": {\n    \"enabled\": true,\n    \"interval\": 1,\n    \"collect_cpu\": true,\n    \"collect_memory\": true,\n    \"collect_disk_io\": true,\n    \"collect_threads\": true,\n    \"collect_file_descriptors\": true,\n    \"export_to_mqtt\": true,\n    \"retain_history\": true,\n    \"history_size\": 1000\n  }\n}'\n</code></pre> <p>Metrics are collected every second with 1000-sample history retention.</p>"},{"location":"monitoring/#minimal-overhead","title":"Minimal Overhead","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"lightweight_task\",\n  \"image_url\": \"docker.io/myorg/light:v1\",\n  \"monitoring_profile\": {\n    \"enabled\": true,\n    \"interval\": 60,\n    \"collect_cpu\": true,\n    \"collect_memory\": true,\n    \"collect_disk_io\": false,\n    \"collect_threads\": false,\n    \"collect_file_descriptors\": false,\n    \"export_to_mqtt\": false,\n    \"retain_history\": false,\n    \"history_size\": 0\n  }\n}'\n</code></pre> <p>Only CPU and memory are collected every 60 seconds with no MQTT export.</p>"},{"location":"monitoring/#batch-processing_1","title":"Batch Processing","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"process_batch\",\n  \"image_url\": \"docker.io/myorg/batch:v1\",\n  \"inputs\": [1000],\n  \"env\": {\n    \"BATCH_SIZE\": \"1000\",\n    \"WORKERS\": \"4\"\n  },\n  \"monitoring_profile\": {\n    \"enabled\": true,\n    \"interval\": 30,\n    \"collect_cpu\": true,\n    \"collect_memory\": true,\n    \"collect_disk_io\": true,\n    \"collect_threads\": false,\n    \"collect_file_descriptors\": false,\n    \"export_to_mqtt\": true,\n    \"retain_history\": true,\n    \"history_size\": 200\n  }\n}'\n</code></pre> <p>Metrics focus on CPU, memory, and disk I/O with 30-second intervals.</p>"},{"location":"monitoring/#metrics-export","title":"Metrics Export","text":""},{"location":"monitoring/#mqtt-topics","title":"MQTT Topics","text":"<p>Topic pattern:</p> <pre><code>m/{domain_id}/c/{channel_id}/metrics/proplet\n</code></pre> <p>All proplets publish to this topic regardless of implementation (Go or Rust).</p>"},{"location":"monitoring/#message-format","title":"Message Format","text":"<pre><code>{\n  \"task_id\": \"550e8400-e29b-41d4-a716-446655440001\",\n  \"proplet_id\": \"7c9e6679-7425-40de-944b-e07fc1f90ae7\",\n  \"metrics\": {\n    \"cpu_percent\": 23.5,\n    \"memory_bytes\": 52428800,\n    \"memory_percent\": 1.2,\n    \"disk_read_bytes\": 1048576,\n    \"disk_write_bytes\": 524288,\n    \"uptime_seconds\": 45,\n    \"thread_count\": 2,\n    \"file_descriptor_count\": 8\n  },\n  \"aggregated\": {\n    \"avg_cpu_usage\": 38.2,\n    \"max_cpu_usage\": 65.0,\n    \"avg_memory_usage\": 62914560,\n    \"max_memory_usage\": 71303168,\n    \"total_disk_read\": 2097152,\n    \"total_disk_write\": 1048576,\n    \"sample_count\": 24\n  },\n  \"timestamp\": \"2025-01-15T10:35:22.123456Z\"\n}\n</code></pre> <p>The <code>aggregated</code> field is only present when <code>retain_history: true</code> in the monitoring profile.</p>"},{"location":"monitoring/#subscribing-to-metrics","title":"Subscribing to Metrics","text":"<p>Subscribe to specific domain/channel:</p> <pre><code>mosquitto_sub -h localhost -p 1883 \\\n  -t \"m/domain-123/c/channel-456/metrics/proplet\" -v\n</code></pre> <p>Subscribe to all metrics:</p> <pre><code>mosquitto_sub -h localhost -p 1883 \\\n  -t \"m/+/c/+/metrics/#\" -v\n</code></pre>"},{"location":"monitoring/#api-endpoints","title":"API Endpoints","text":"<p>Get task metrics:</p> <pre><code>curl \"http://localhost:7070/tasks/{task_id}/metrics?offset=0&amp;limit=100\"\n</code></pre> <p>Get proplet metrics:</p> <pre><code>curl \"http://localhost:7070/proplets/{proplet_id}/metrics?offset=0&amp;limit=100\"\n</code></pre> <p>Response includes paginated metrics with aggregated statistics.</p>"},{"location":"monitoring/#platform-support","title":"Platform Support","text":""},{"location":"monitoring/#linux","title":"Linux","text":"Metric Method CPU <code>/proc/[pid]/stat</code> Memory <code>/proc/[pid]/status</code> Disk I/O <code>/proc/[pid]/io</code> Threads <code>/proc/[pid]/task</code> File descriptors <code>/proc/[pid]/fd</code> <p>All metrics are available with high accuracy.</p>"},{"location":"monitoring/#macos","title":"macOS","text":"<p>Full metric support using system APIs.</p> Metric Method CPU System calls Memory System APIs Disk I/O System counters Threads System APIs File descriptors <code>lsof</code> or system calls <p>Performance is comparable to Linux with all metrics available.</p>"},{"location":"monitoring/#windows","title":"Windows","text":"<p>Limited metric support due to platform constraints.</p> Metric Support CPU Full Memory Full Disk I/O Full Threads Limited (may report 1) File descriptors Not supported (always 0) <p>Consider running on Linux/macOS for full observability.</p>"},{"location":"monitoring/#integration-with-external-systems","title":"Integration with External Systems","text":""},{"location":"monitoring/#prometheus","title":"Prometheus","text":"<p>Install mqtt2prometheus:</p> <pre><code>docker run -d \\\n  --name mqtt2prometheus \\\n  -p 9641:9641 \\\n  hikhvar/mqtt2prometheus:latest\n</code></pre> <p>Configure Prometheus scraping:</p> <pre><code>scrape_configs:\n  - job_name: \"propeller\"\n    static_configs:\n      - targets: [\"mqtt2prometheus:9641\"]\n</code></pre> <p>Metrics become queryable in PromQL for alerting and dashboards.</p>"},{"location":"monitoring/#grafana","title":"Grafana","text":"<p>Build dashboards using Prometheus or MQTT datasource.</p> <p>Recommended panels:</p> <ul> <li>CPU usage timeline (line chart)</li> <li>Memory consumption (area chart)</li> <li>Disk I/O throughput (stacked area)</li> <li>Thread count (gauge)</li> <li>Per-task comparison (bar chart)</li> </ul> <p>Import metrics from Prometheus or connect directly to MQTT broker.</p>"},{"location":"monitoring/#performance-overhead","title":"Performance Overhead","text":"Profile CPU Overhead Memory Overhead Minimal &lt; 0.1% ~1 MB Standard &lt; 0.5% ~2 MB Intensive &lt; 2% ~5 MB <p>Memory usage scales linearly with history retention:</p> <ul> <li>No history: ~1 MB</li> <li>100 samples: ~2 MB</li> <li>1000 samples: ~5 MB</li> </ul> <p>CPU overhead primarily comes from system call frequency.</p>"},{"location":"monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"monitoring/#no-metrics-published","title":"No Metrics Published","text":"<p>Check global monitoring setting:</p> <pre><code>echo $PROPLET_ENABLE_MONITORING\n</code></pre> <p>Verify MQTT connectivity:</p> <pre><code>mosquitto_sub -h localhost -p 1883 -t \"m/+/c/+/metrics/#\" -v\n</code></pre> <p>Ensure task has monitoring enabled:</p> <pre><code>{\n  \"monitoring_profile\": {\n    \"enabled\": true,\n    \"export_to_mqtt\": true\n  }\n}\n</code></pre> <p>Review proplet logs:</p> <pre><code>docker logs propeller-proplet\n</code></pre>"},{"location":"monitoring/#high-cpu-overhead","title":"High CPU Overhead","text":"<p>Reduce collection frequency and disable unused metrics.</p> <pre><code>{\n  \"monitoring_profile\": {\n    \"interval\": 60,\n    \"collect_disk_io\": false,\n    \"collect_threads\": false,\n    \"retain_history\": false\n  }\n}\n</code></pre>"},{"location":"monitoring/#high-memory-usage","title":"High Memory Usage","text":"<p>Disable history retention or reduce sample count.</p> <pre><code>{\n  \"monitoring_profile\": {\n    \"retain_history\": false,\n    \"history_size\": 0\n  }\n}\n</code></pre>"},{"location":"monitoring/#missing-metrics-on-windows","title":"Missing Metrics on Windows","text":"<p>Windows has limited support for threads and file descriptors. Use Linux or macOS for full metric availability.</p>"},{"location":"monitoring/#inaccurate-cpu-measurements","title":"Inaccurate CPU Measurements","text":"<p>CPU percentage is calculated over the collection interval. Use intervals \u2265 1 second for stable readings. CPU-bound processes show more accurate metrics than I/O-bound processes.</p>"},{"location":"monitoring/#api-reference","title":"API Reference","text":""},{"location":"monitoring/#monitoring-profile-schema","title":"Monitoring Profile Schema","text":"<pre><code>{\n  \"enabled\": true,\n  \"interval\": 10,\n  \"collect_cpu\": true,\n  \"collect_memory\": true,\n  \"collect_disk_io\": true,\n  \"collect_threads\": true,\n  \"collect_file_descriptors\": true,\n  \"export_to_mqtt\": true,\n  \"retain_history\": true,\n  \"history_size\": 100\n}\n</code></pre> Field Type Description <code>enabled</code> boolean Enable/disable monitoring <code>interval</code> integer Collection interval (seconds) <code>collect_cpu</code> boolean Track CPU usage <code>collect_memory</code> boolean Track memory usage <code>collect_disk_io</code> boolean Track disk I/O <code>collect_threads</code> boolean Track thread count <code>collect_file_descriptors</code> boolean Track file descriptors <code>export_to_mqtt</code> boolean Publish to MQTT <code>retain_history</code> boolean Keep historical samples <code>history_size</code> integer Number of samples to retain"},{"location":"monitoring/#metrics-schema","title":"Metrics Schema","text":"<pre><code>{\n  \"cpu_percent\": 23.5,\n  \"memory_bytes\": 52428800,\n  \"memory_percent\": 1.2,\n  \"disk_read_bytes\": 1048576,\n  \"disk_write_bytes\": 524288,\n  \"uptime_seconds\": 45,\n  \"thread_count\": 2,\n  \"file_descriptor_count\": 8\n}\n</code></pre> Field Type Description <code>cpu_percent</code> float CPU usage (0-100+ per core) <code>memory_bytes</code> integer Memory usage in bytes <code>memory_percent</code> float Memory as % of total RAM <code>disk_read_bytes</code> integer Cumulative bytes read <code>disk_write_bytes</code> integer Cumulative bytes written <code>uptime_seconds</code> integer Process runtime <code>thread_count</code> integer OS thread count <code>file_descriptor_count</code> integer Open file handles"},{"location":"monitoring/#aggregated-metrics-schema","title":"Aggregated Metrics Schema","text":"<pre><code>{\n  \"avg_cpu_usage\": 38.2,\n  \"max_cpu_usage\": 65.0,\n  \"avg_memory_usage\": 62914560,\n  \"max_memory_usage\": 71303168,\n  \"total_disk_read\": 2097152,\n  \"total_disk_write\": 1048576,\n  \"sample_count\": 24\n}\n</code></pre> Field Type Description <code>avg_cpu_usage</code> float Average CPU over history <code>max_cpu_usage</code> float Peak CPU over history <code>avg_memory_usage</code> integer Average memory (bytes) <code>max_memory_usage</code> integer Peak memory (bytes) <code>total_disk_read</code> integer Total bytes read <code>total_disk_write</code> integer Total bytes written <code>sample_count</code> integer Number of samples"},{"location":"monitoring/#getting-started","title":"Getting Started","text":""},{"location":"monitoring/#start-infrastructure","title":"Start Infrastructure","text":"<pre><code>cd propeller\nmake start-supermq\n</code></pre>"},{"location":"monitoring/#enable-monitoring","title":"Enable Monitoring","text":"<pre><code>export PROPLET_ENABLE_MONITORING=true\ndocker restart propeller-proplet\n</code></pre>"},{"location":"monitoring/#subscribe-to-metrics","title":"Subscribe to Metrics","text":"<pre><code>mosquitto_sub -h localhost -p 1883 -t \"m/+/c/+/metrics/#\" -v\n</code></pre>"},{"location":"monitoring/#create-task","title":"Create Task","text":"<pre><code>curl -X POST \"http://localhost:7070/tasks\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"name\": \"compute\",\n  \"image_url\": \"docker.io/myorg/compute:v1\",\n  \"inputs\": [10, 20]\n}'\n</code></pre> <p>Start the task:</p> <pre><code>curl -X POST \"http://localhost:7070/tasks/{task_id}/start\"\n</code></pre> <p>Metrics will appear in the MQTT subscriber terminal every 10 seconds.</p>"},{"location":"proplet/","title":"Proplet","text":"<p>The <code>proplet</code> is a worker that executes WebAssembly functions. It can be configured to use either the embedded <code>wazero</code> runtime or an external WebAssembly runtime on the host system.</p>"},{"location":"proplet/#configuration","title":"Configuration","text":"<p>The <code>proplet</code> is configured using environment variables.</p> Environment Variable Description Default <code>PROPLET_LOG_LEVEL</code> Log level (e.g., <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>) <code>info</code> <code>PROPLET_INSTANCE_ID</code> A unique ID for this proplet instance. A new UUID <code>PROPLET_MQTT_ADDRESS</code> The address of the MQTT broker. <code>tcp://localhost:1883</code> <code>PROPLET_MQTT_TIMEOUT</code> The timeout for MQTT operations. <code>30s</code> <code>PROPLET_MQTT_QOS</code> The Quality of Service level for MQTT messages. <code>2</code> <code>PROPLET_LIVELINESS_INTERVAL</code> The interval at which the proplet sends liveliness messages. <code>10s</code> <code>PROPLET_DOMAIN_ID</code> The domain ID for this proplet. <code>PROPLET_CHANNEL_ID</code> The channel ID for this proplet. <code>PROPLET_CLIENT_ID</code> The client ID for MQTT authentication. <code>PROPLET_CLIENT_KEY</code> The client key for MQTT authentication. <code>PROPLET_EXTERNAL_WASM_RUNTIME</code> The path to an external WebAssembly runtime. If not set, the embedded <code>wazero</code> runtime will be used. <code>\"\"</code> (empty string)"},{"location":"proplet/#usage","title":"Usage","text":""},{"location":"proplet/#using-the-embedded-wazero-runtime","title":"Using the Embedded <code>wazero</code> Runtime","text":"<p>By default, <code>proplet</code> uses the embedded <code>wazero</code> runtime. To run it, simply set the required environment variables and start the application:</p> <pre><code>export PROPLET_DOMAIN_ID=\"your_domain_id\"\nexport PROPLET_CHANNEL_ID=\"your_channel_id\"\nexport PROPLET_CLIENT_ID=\"your_client_id\"\nexport PROPLET_CLIENT_KEY=\"your_client_key\"\npropeller-proplet\n</code></pre>"},{"location":"proplet/#using-a-host-webassembly-runtime","title":"Using a Host WebAssembly Runtime","text":"<p>To use an external WebAssembly runtime (e.g., <code>wasmtime</code>, <code>wasmer</code>), set the <code>PROPLET_EXTERNAL_WASM_RUNTIME</code> environment variable to the path of the runtime executable.</p> <p>For example, to use <code>wasmtime</code>:</p> <pre><code>export PROPLET_DOMAIN_ID=\"your_domain_id\"\nexport PROPLET_CHANNEL_ID=\"your_channel_id\"\nexport PROPLET_CLIENT_ID=\"your_client_id\"\nexport PROPLET_CLIENT_KEY=\"your_client_key\"\nexport PROPLET_EXTERNAL_WASM_RUNTIME=\"/usr/bin/wasmtime\"\nPROPLET_EXTERNAL_WASM_RUNTIME=wasmtime propeller-proplet\n</code></pre> <p>You will also need to provide cli arguments to the task so that the runtime can be started. For example, to run the <code>addition</code> example with <code>wasmtime</code>:</p> <pre><code>wasmtime --invoke add /home/rodneyosodo/code/absmach/propeller/db3d44e8-6e27-464a-aaeb-e643ec298dff.wasm 10 20\n</code></pre> <p>Hence the cli aguments are <code>--invoke</code> and <code>add</code> and the path to the wasm file. The task will then be created as follows:</p> <pre><code>{\n  \"name\": \"add\",\n  \"cli_args\": [\"--invoke\", \"add\"],\n  \"inputs\": [10, 20]\n}\n</code></pre>"},{"location":"proplet/#proplet-command-handling","title":"Proplet Command Handling","text":""},{"location":"proplet/#start-command-flow","title":"Start Command Flow","text":"<p>The start command is sent by the Manager to the Proplet on the topic <code>m/:domain_id/c/:channel_id/control/manager/start</code></p>"},{"location":"proplet/#1-parse-the-start-command","title":"1. Parse the Start Command","text":"<p>The MQTT message payload is unmarshaled into a <code>StartRequest</code> structure containing the <code>AppName</code> and any required parameters for the application. If the payload is invalid or <code>AppName</code> is missing, an error is logged, and no further action is taken.</p>"},{"location":"proplet/#2-publish-a-fetch-request","title":"2. Publish a Fetch Request","text":"<p>A fetch request is sent to the Registry Proxy to retrieve the WebAssembly (Wasm) binary chunks for the specified application. This request is published to the topic <code>m/:domain_id/c/:channel_id/registry/proplet</code>.</p>"},{"location":"proplet/#3-wait-for-wasm-binary-chunks","title":"3. Wait for Wasm Binary Chunks","text":"<p>The system monitors the reception of Wasm chunks from the Registry Proxy, which are published to the topic <code>m/:domain_id/c/:channel_id/registry/server</code> and processed by the <code>handleChunk</code> function.</p>"},{"location":"proplet/#4-assemble-and-validate-chunks","title":"4. Assemble and Validate Chunks","text":"<p>Once all chunks are received, as determined by comparing the number of received chunks to the <code>TotalChunks</code> field in the chunk metadata, the chunks are assembled into a complete Wasm binary and validated to ensure integrity.</p>"},{"location":"proplet/#5-deploy-and-run-the-application","title":"5. Deploy and Run the Application","text":"<p>The assembled Wasm binary is passed to the Wazero runtime for instantiation and execution, where the specified function (e.g., <code>main</code>) in the Wasm module is invoked.</p>"},{"location":"proplet/#runtime-functions-startapp","title":"Runtime Functions: StartApp","text":"<p>The <code>StartApp</code> function in <code>runtime.go</code> handles the instantiation and execution of Wasm modules. It:</p> <ol> <li>Validate Input Parameters: Ensures <code>appName</code>, <code>wasmBinary</code>, and <code>functionName</code> are provided and valid. Errors are returned if any parameter is missing or invalid.</li> <li>Acquire Mutex Lock: Locks the runtime to ensure thread-safe access to the <code>modules</code> map.</li> <li>Check for Existing App Instance: Verifies if the app is already running. If found, an error is returned to prevent duplicate instances.</li> <li>Instantiate the Wasm Module: Passes the <code>wasmBinary</code> to the Wazero runtime's <code>Instantiate</code> method to create a Wasm module.</li> <li>Retrieve the Exported Function: Locates the <code>functionName</code> in the module. If the function is missing, the module is closed, and an error is returned.</li> <li>Store the Module in the Runtime: Saves the instantiated module in the <code>modules</code> map for tracking running applications.</li> <li>Release Mutex Lock: Unlocks the runtime after the module is added to the map.</li> <li>Return the Exported Function: Returns the Wasm function for execution.</li> </ol>"},{"location":"proplet/#6-log-success-or-errors","title":"6. Log Success or Errors","text":"<p>A success message is logged if the application starts successfully, while detailed errors are logged if any step in the process (e.g., chunk assembly, instantiation, or execution) fails.</p>"},{"location":"proplet/#stop-command-flow","title":"Stop Command Flow","text":"<p>The stop command is sent by the Manager to the Proplet on the topic <code>m/:domain_id/c/:channel_id/control/manager/stop</code></p>"},{"location":"proplet/#1-parse-the-stop-command","title":"1. Parse the Stop Command","text":"<p>The MQTT message payload is unmarshaled into a <code>StopRequest</code> structure containing the <code>AppName</code> of the application to stop. If the payload is invalid or <code>AppName</code> is missing, an error is logged, and no further action is taken.</p>"},{"location":"proplet/#2-stop-the-application","title":"2. Stop the Application","text":"<p>The <code>StopApp</code> method in the Wazero runtime is invoked, which checks if the application is running, closes the corresponding Wasm module, and removes the application from the runtime's internal tracking.</p>"},{"location":"proplet/#runtime-functions-stopapp","title":"Runtime Functions: StopApp","text":"<p>The <code>StopApp</code> function in <code>runtime.go</code> stops and cleans up a running Wasm module. It:</p> <ol> <li>Validate Input Parameters: Checks if <code>appName</code> is provided. If missing, an error is returned.</li> <li>Acquire Mutex Lock: Locks the runtime to ensure thread-safe access to the <code>modules</code> map.</li> <li>Check for Running App: Looks up the app in the <code>modules</code> map. If the app is not found, an error is returned.</li> <li>Close the Wasm Module: Calls the module's <code>Close</code> method to release all resources associated with the app. If closing fails, an error is logged and returned.</li> <li>Remove the App from Runtime: Deletes the app entry from the <code>modules</code> map to update the runtime's state.</li> <li>Release Mutex Lock: Unlocks the runtime after the app has been removed from the map.</li> </ol>"},{"location":"proplet/#3-log-success-or-errors","title":"3. Log Success or Errors","text":"<p>A success message is logged with the text <code>\"App '&lt;AppName&gt;' stopped successfully.\"</code> if the application stops successfully. If the application is not running or an error occurs during the stop operation, detailed error information is logged.</p> <p>The Manager knows which Proplet is on which channel through the following mechanisms:</p> <ol> <li>Startup Notification (<code>create</code> topic):</li> </ol> <p>When a Proplet starts, it publishes a message on the topic:</p> <pre><code>m/:domain_id/c/:manager_channel_id/messages/control/proplet/create\n</code></pre> <p>The payload of this message includes the <code>PropletID</code> and <code>ChannelID</code>, notifying the Manager about the mapping of Proplet IDs to their respective channels:</p> <pre><code>{\n  \"PropletID\": \"{PropletID}\",\n  \"ChanID\": \"{ChannelID}\"\n}\n</code></pre> <ol> <li>Liveliness Updates (<code>alive</code> topic):</li> </ol> <p>To ensure that the Proplet is still active, it periodically publishes messages on the topic:</p> <pre><code>m/:domain_id/c/:manager_channel_id/messages/control/proplet/alive\n</code></pre> <p>The payload contains the same <code>PropletID</code> and <code>ChannelID</code> information. This helps the Manager maintain an updated map of active Proplets and their channels:</p> <pre><code>{\n  \"status\": \"alive\",\n  \"PropletID\": \"{PropletID}\",\n  \"ChanID\": \"{ChannelID}\"\n}\n</code></pre> <ol> <li>Last Will &amp; Testament (LWT):</li> </ol> <p>If the Proplet goes offline unexpectedly, the MQTT broker automatically publishes a message on the same <code>alive</code> topic with a payload indicating the Proplet's offline status:</p> <pre><code>{\n  \"status\": \"offline\",\n  \"PropletID\": \"{PropletID}\",\n  \"ChanID\": \"{ChannelID}\"\n}\n</code></pre> <p>These mechanisms ensure that the Manager is always aware of the active Proplets and their corresponding channels. The Manager can utilize this data to send specific control commands or monitor the Proplets effectively.</p>"},{"location":"proplet/#registry-workflow","title":"Registry Workflow","text":"<ol> <li> <p>Proplet Fetches Wasm Binary:</p> </li> <li> <p>Publishes a fetch request on the <code>proplet</code> topic.</p> </li> <li> <p>Waits for chunks on the <code>server</code> topic.</p> </li> <li> <p>Proplet Handles Registry Updates:</p> </li> <li>Subscribes to the <code>updateRegistry</code> topic.</li> <li>Updates the registry configuration upon receiving a valid payload.</li> <li>Publishes the status (success or failure) to the <code>registry</code> topic.</li> </ol>"},{"location":"proplet/#1-fetch-request","title":"1. Fetch Request","text":"<p>The Proplet uses this topic to request Wasm binary chunks for a specific application from the Registry Proxy.</p> <ul> <li>Topic:</li> </ul> <pre><code>m/:domain_id/c/:channel_id/registry/proplet\n</code></pre> <ul> <li>Payload is a JSON object containing the name of the application (<code>app_name</code>) for which the WebAssembly (Wasm) binary chunks are requested:</li> </ul> <pre><code>{\n  \"app_name\": \"{AppName}\"\n}\n</code></pre>"},{"location":"proplet/#2-image-chunks-delivery","title":"2. Image Chunks Delivery","text":"<p>The Registry Proxy publishes Wasm binary chunks to this topic for the Proplet to assemble into a complete binary. The Proplet monitors this topic to receive the chunks sequentially.</p> <ul> <li>Topic:</li> </ul> <pre><code>m/:domain_id/c/:channel_id/registry/server\n</code></pre> <ul> <li>Payload is a JSON object representing a single chunk of the requested Wasm binary:</li> </ul> <pre><code>{\n  \"app_name\": \"{AppName}\",\n  \"chunk_idx\": {ChunkIndex},\n  \"total_chunks\": {TotalChunks},\n  \"data\": \"{Base64EncodedChunkData}\"\n}\n</code></pre>"},{"location":"proplet/#3-registry-configuration-update","title":"3. Registry Configuration Update","text":"<ul> <li>Allows the Manager to update the Proplet's registry configuration dynamically.</li> </ul> <pre><code>m/:domain_id/c/:channel_id/control/manager/updateRegistry\n</code></pre> <ul> <li>Payload is a JSON object containing the new registry URL and token for updating the Proplet's registry configuration:</li> </ul> <pre><code>{\n  \"registry_url\": \"{NewRegistryURL}\",\n  \"registry_token\": \"{NewRegistryToken}\"\n}\n</code></pre>"},{"location":"proplet/#4-acknowledgment-for-registry-updates","title":"4. Acknowledgment for Registry Updates","text":"<ul> <li>The Proplet uses this topic to acknowledge whether the registry configuration update was successful or failed.</li> </ul> <pre><code>m/:domain_id/c/:channel_id/control/manager/registry\n</code></pre> <ul> <li> <p>Payload is a JSON object indicating the success or failure of a registry update:</p> </li> <li> <p>Success:</p> <pre><code>{\n  \"status\": \"success\"\n}\n</code></pre> </li> <li> <p>Failure:</p> <pre><code>{\n  \"status\": \"failure\",\n  \"error\": \"{ErrorMessage}\"\n}\n</code></pre> </li> </ul>"},{"location":"proxy/","title":"Proxy Service","text":"<p>The Proxy Service acts as a bridge between MQTT and HTTP protocols in the Propeller system. It enables bidirectional communication between MQTT clients and HTTP endpoints, allowing for seamless integration of different protocols. The proxy service is responsible for fetching WebAssembly modules from an OCI-compliant registry, chunking them, and publishing them over MQTT for <code>proplet</code> instances to consume.</p>"},{"location":"proxy/#overview","title":"Overview","text":"<p>The proxy service performs two main functions:</p> <ol> <li>Subscribes to MQTT topics and forwards messages to HTTP endpoints</li> <li>Streams data between MQTT and HTTP protocols</li> </ol>"},{"location":"proxy/#usage","title":"Usage","text":"<p>To use the proxy service, you need to set the required environment variables and run the <code>main.go</code> file in the <code>cmd/proxy</code> directory.</p> <pre><code>PROXY_REGISTRY_URL=\"docker.io\"\nPROXY_AUTHENTICATE=\"TRUE\"\nPROXY_REGISTRY_USERNAME=\"docker_username\"\nPROXY_REGISTRY_PASSWORD=\"docker_password\"\npropeller-proxy\n</code></pre> <p>This will change the task definition. Since we are using hosted wasm modules, we need to specify the image URL. Hence the task definition will look like this:</p> <pre><code>{\n  \"name\": \"add\",\n  \"inputs\": [10, 20],\n  \"image_url\": \"docker.io/mrstevenyaga/add.wasm\"\n}\n</code></pre>"},{"location":"proxy/#how-it-works","title":"How It Works","text":"<p>The proxy service facilitates the download of WebAssembly (WASM) containers through a multi-step process:</p> <p></p> <ol> <li> <p>Initial Request    The proplet sends a download request via the MQTT topic: <code>m/:domain_id/c/:channel_id/messages/registry/proplet</code>    This request is received by the proxy service's MQTT subscriber</p> </li> <li> <p>OCI Registry Download    The HTTP side of the proxy service receives this request    It then sends a download request to the OCI registry to fetch the WASM container    The container is downloaded as an OCI image</p> </li> <li> <p>Chunked Data Transfer    Once downloaded, the WASM image is split into chunks    These chunks are sent back to the proplet via the MQTT topic: <code>m/:domain_id/c/:channel_id/messages/registry/server</code>    This chunked approach ensures efficient handling of large WASM files</p> </li> </ol>"},{"location":"proxy/#architecture-details","title":"Architecture Details","text":""},{"location":"proxy/#streaming-system","title":"Streaming System","text":"<p>The proxy service implements a concurrent streaming architecture with two main components:</p> <ol> <li> <p>HTTP Stream    Handles container fetching from the OCI registry.    Splits containers into configurable chunk sizes    Forwards chunks to the MQTT stream via an internal channel.    Implements context-based cancellation for graceful shutdown.</p> </li> <li> <p>MQTT Stream    Receives chunks from the HTTP stream.    Publishes chunks to MQTT topics.    Tracks chunk delivery progress.    Maintains a map of container chunks to ensure complete delivery.</p> </li> </ol>"},{"location":"proxy/#chunk-management","title":"Chunk Management","text":"<ul> <li>Uses a buffered channel system with a capacity of 10 chunks</li> <li>Tracks the progress of chunk delivery for each container</li> <li>Provides completion notifications when all chunks are successfully sent</li> <li>Automatically cleans up tracking data after successful delivery</li> </ul>"},{"location":"proxy/#performance-features","title":"Performance Features","text":"<ul> <li>Buffered Operations: Implements chunk buffering to optimize memory usage and transfer speed</li> <li>Concurrent Processing: Separate goroutines for HTTP and MQTT operations</li> <li>Progress Tracking: Real-time tracking of chunk delivery status</li> <li>Memory Management: Automatic cleanup of completed transfers</li> </ul>"},{"location":"proxy/#configuration","title":"Configuration","text":"<p>The proxy service is configured using environment variables.</p>"},{"location":"proxy/#environment-variables","title":"Environment Variables","text":"Environment Variable Description <code>PROXY_LOG_LEVEL</code> Log level (e.g., <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>). <code>PROXY_INSTANCE_ID</code> A unique ID for this proxy instance."},{"location":"proxy/#mqtt-configuration","title":"MQTT Configuration","text":"Variable Description Default Required <code>PROXY_MQTT_ADDRESS</code> URL of the MQTT broker <code>tcp://localhost:1883</code> Yes <code>PROXY_MQTT_TIMEOUT</code> The timeout for MQTT operations. <code>30s</code> No <code>PROXY_MQTT_QOS</code> The Quality of Service level for MQTT messages. <code>2</code> No <code>PROXY_DOMAIN_ID</code> The domain ID for this proxy. <code>\"\"</code> Yes <code>PROXY_CLIENT_ID</code> Unique identifier for the proplet <code>\"\"</code> Yes <code>PROXY_CHANNEL_ID</code> Channel identifier for MQTT <code>\"\"</code> Yes <code>PROXY_CLIENT_KEY</code> Password for MQTT authentication <code>\"\"</code> Yes"},{"location":"proxy/#registry-configuration","title":"Registry Configuration","text":"Variable Description Default Required <code>PROXY_REGISTRY_URL</code> URL of the OCI registry <code>\"\"</code> Yes <code>PROXY_AUTHENTICATE</code> Enable/disable registry authentication <code>false</code> No <code>PROXY_REGISTRY_USERNAME</code> Username for registry authentication <code>\"\"</code> Only if <code>PROXY_AUTHENTICATE=true</code> <code>PROXY_REGISTRY_PASSWORD</code> Password for registry authentication <code>\"\"</code> Only if <code>PROXY_AUTHENTICATE=true</code> <code>PROXY_REGISTRY_TOKEN</code> Access token for registry authentication <code>\"\"</code> Alternative to username/password <code>PROXY_CHUNK_SIZE</code> The size of the chunks to split the Wasm module into <code>512000</code> No"},{"location":"proxy/#example-configuration","title":"Example Configuration","text":"<p>Export the required environment variables in your terminal:</p> <pre><code># Registry Configuration\nexport PROXY_REGISTRY_URL=\"&lt;registry_url&gt;\"\nexport PROXY_AUTHENTICATE=\"TRUE\"\nexport PROXY_REGISTRY_USERNAME=\"&lt;your_docker_username&gt;\"\nexport PROXY_REGISTRY_PASSWORD=\"&lt;your_docker_password&gt;\"\n\n# MQTT Configuration\nexport PROPLET_THING_KEY=\"&lt;secret&gt;\"\nexport PROPLET_THING_ID=\"&lt;proplet_id&gt;\"\nexport PROPLET_CHANNEL_ID=\"&lt;channel_id&gt;\"\n</code></pre>"},{"location":"proxy/#authentication","title":"Authentication","text":"<p>If your registry requires authentication, you can set the <code>PROXY_AUTHENTICATE</code> environment variable to <code>true</code> and provide either a token or a username and password.</p>"},{"location":"proxy/#token-authentication","title":"Token Authentication","text":"<pre><code>export PROXY_AUTHENTICATE=\"true\"\nexport PROXY_REGISTRY_TOKEN=\"your_token\"\n</code></pre>"},{"location":"proxy/#usernamepassword-authentication","title":"Username/Password Authentication","text":"<pre><code>export PROXY_AUTHENTICATE=\"true\"\nexport PROXY_REGISTRY_USERNAME=\"your_username\"\nexport PROXY_REGISTRY_PASSWORD=\"your_password\"\n</code></pre>"},{"location":"proxy/#running-the-service","title":"Running the Service","text":"<p>After exporting the environment variables, you can run the proxy service as shown:</p> <pre><code>make all &amp;&amp; make install\npropeller-proxy\n</code></pre> <p>This will install the binary in your GOBIN directory (ensure your GOBIN is configured correctly).</p>"},{"location":"proxy/#deploying-a-local-oci-registry","title":"Deploying a Local OCI Registry","text":"<p>Propeller supports pulling Wasm modules from any OCI-compliant registry. You can use a public registry like Docker Hub or set up your own private registry. You can deploy your own OCI registry using Docker and configure the proxy to pull WASM modules from it. This is useful for development and testing purposes.</p>"},{"location":"proxy/#1-run-a-local-registry","title":"1. Run a Local Registry","text":"<p>First, run a local OCI registry using the official Docker image:</p> <pre><code>docker run -d -p 5000:5000 --name registry registry:3.0.0\n</code></pre> <p>This command will start a local registry in detached mode and map port 5000 on your host to port 5000 on the container.</p>"},{"location":"proxy/#2-push-a-wasm-module-to-the-local-registry","title":"2. Push a WASM Module to the Local Registry","text":"<p>Next, you need to push a WASM module to your local registry. You can use a tool like <code>oras</code> or <code>wasm-to-oci</code> to do this. First, create WASM module. We can use the <code>addition.wasm</code> module from the propeller example after building the wasm module.</p> <pre><code>git clone https://github.com/absmach/propeller.git\ncd propeller\nmake all\n</code></pre> <p>Now, push the <code>addition.wasm</code> file to your local registry using <code>wasm-to-oci</code>:</p> <pre><code>wasm-to-oci push ./build/addition.wasm localhost:5000/rodneydav/addition.wasm\nwasm-to-oci push ./build/addition.wasm docker.io/rodneydav/addition.wasm\n</code></pre>"},{"location":"proxy/#3-configure-the-proxy","title":"3. Configure the Proxy","text":"<p>Finally, configure the proxy to use your local registry by setting the following environment variables:</p> <pre><code>export PROXY_REGISTRY_URL=\"localhost:5000\"\nexport PROXY_AUTHENTICATE=\"false\"  # No authentication for local registry\n</code></pre> <p>Now, when you run the proxy, it will pull the <code>addition.wasm</code> module from your local registry when a request for <code>localhost:5000/addition</code> is made.</p>"},{"location":"proxy/#service-flow","title":"Service Flow","text":"<ol> <li> <p>Initialization    Loads configuration from environment variables.    Sets up logging with structured logging support.    Creates a new proxy service instance.    Initializes MQTT client and communication channels.</p> </li> <li> <p>Connection    Establishes connection to the MQTT broker.    Subscribes to configured topics.    Sets up HTTP streaming with the registry.    Initializes chunk buffering system.</p> </li> <li> <p>Operation    Runs two concurrent streams:</p> </li> <li> <p>StreamHTTP: Handles HTTP communication with the OCI registry.</p> </li> <li>StreamMQTT: Handles MQTT communication for proplet requests and responses.</li> </ol> <p>Uses error groups for graceful error handling and shutdown. Maintains chunk delivery tracking. Provides real-time progress logging.</p> <ol> <li>Error Handling    Implements comprehensive error logging with context. Graceful shutdown with proper resource cleanup. Automatic disconnection from MQTT broker on service termination. Retry mechanisms for failed operations. Context-based cancellation support.</li> </ol>"},{"location":"proxy/#http-registry-operations","title":"HTTP Registry Operations","text":"<p>The HTTP configuration supports:</p> <ul> <li>Registry operations with optional authentication (username/password or token)</li> <li>Automatic retry mechanism for failed requests</li> <li>Chunked data handling with configurable chunk size (512KB default)</li> <li>Static credential caching for authenticated requests</li> <li>Progress tracking for multi-chunk transfers</li> </ul>"},{"location":"reference/","title":"Process Monitoring Implementation","text":"<p>This document describes the complete process monitoring implementation for Rust proplets in the Propeller distributed task execution system.</p>"},{"location":"reference/#overview","title":"Overview","text":"<p>Comprehensive OS-level process monitoring has been implemented for:</p> <ul> <li>Rust Proplet - Using <code>sysinfo</code> crate for cross-platform metrics</li> <li>Manager - Ready for integration (metrics aggregation and visualization)</li> </ul>"},{"location":"reference/#monitoring-profiles","title":"Monitoring Profiles","text":"<p>Profiles define which metrics to collect, how often, and how much history to retain.</p> <p>The Rust implementation provides two built-in profiles:</p> Profile Interval Metrics Export History Use Case Standard 10s All Yes 100 General purpose Long-running Daemon 120s All Yes 500 Background services"},{"location":"reference/#custom-profiles","title":"Custom Profiles","text":"<p>You can also define custom monitoring profiles via JSON configuration with the following options:</p> <ul> <li><code>enabled</code>: Enable/disable monitoring (default: <code>true</code>)</li> <li><code>interval</code>: Collection interval in seconds (default: <code>10</code>)</li> <li><code>collect_cpu</code>: Collect CPU metrics (default: <code>true</code>)</li> <li><code>collect_memory</code>: Collect memory metrics (default: <code>true</code>)</li> <li><code>collect_disk_io</code>: Collect disk I/O metrics (default: <code>true</code>)</li> <li><code>collect_threads</code>: Collect thread count (default: <code>true</code>)</li> <li><code>collect_file_descriptors</code>: Collect file descriptor count (default: <code>true</code>)</li> <li><code>export_to_mqtt</code>: Publish metrics to MQTT (default: <code>true</code>)</li> <li><code>retain_history</code>: Keep metrics history (default: <code>true</code>)</li> <li><code>history_size</code>: Maximum history entries (default: <code>100</code>)</li> </ul>"},{"location":"reference/#metrics-collected","title":"Metrics Collected","text":""},{"location":"reference/#common-metrics-all-platforms","title":"Common Metrics (All Platforms)","text":"<ul> <li>CPU usage percentage</li> <li>Memory usage (bytes and percentage)</li> <li>Disk I/O (read/write bytes)</li> <li>Network I/O (rx/tx bytes)</li> <li>Process uptime</li> </ul>"},{"location":"reference/#platform-specific-metrics","title":"Platform-Specific Metrics","text":"Metric Linux macOS Windows Thread Count \u2713 \u2713 Limited File Descriptors \u2713 \u2713 \u2717 Detailed Memory Stats \u2713 \u2713 \u2713"},{"location":"reference/#mqtt-topics","title":"MQTT Topics","text":""},{"location":"reference/#proplet-level-metrics","title":"Proplet-Level Metrics","text":"<pre><code>m/{domain_id}/c/{channel_id}/control/proplet/metrics\n\nPublishes overall proplet health metrics.\n\n### Task-Level Metrics\n\n```txt\nm/{domain_id}/c/{channel_id}/control/proplet/task_metrics\nm/{domain_id}/c/{channel_id}/metrics/proplet\n</code></pre> <p>Publishes per-task process metrics.</p>"},{"location":"reference/#message-format","title":"Message Format","text":"<pre><code>{\n  \"task_id\": \"uuid\",\n  \"proplet_id\": \"uuid\",\n  \"metrics\": {\n    \"cpu_percent\": 42.5,\n    \"memory_bytes\": 67108864,\n    \"memory_percent\": 1.5,\n    \"disk_read_bytes\": 1048576,\n    \"disk_write_bytes\": 524288,\n    \"network_rx_bytes\": 4096,\n    \"network_tx_bytes\": 8192,\n    \"uptime_seconds\": 120,\n    \"thread_count\": 4,\n    \"file_descriptor_count\": 12,\n    \"timestamp\": \"2025-01-15T10:30:00.000Z\"\n  },\n  \"aggregated\": {\n    \"avg_cpu_usage\": 38.2,\n    \"max_cpu_usage\": 65.0,\n    \"avg_memory_usage\": 62914560,\n    \"max_memory_usage\": 71303168,\n    \"total_disk_read\": 2097152,\n    \"total_disk_write\": 1048576,\n    \"total_network_rx\": 12288,\n    \"total_network_tx\": 24576,\n    \"sample_count\": 24\n  }\n}\n</code></pre>"},{"location":"reference/#configuration","title":"Configuration","text":""},{"location":"reference/#rust-proplet-environment-variables","title":"Rust Proplet Environment Variables","text":"<pre><code>export PROPLET_ENABLE_MONITORING=true     # Enable/disable monitoring (default: true)\nexport PROPLET_METRICS_INTERVAL=10        # Proplet-level metrics interval in seconds (default: 10)\n</code></pre>"},{"location":"reference/#per-task-configuration-json","title":"Per-Task Configuration (JSON)","text":"<pre><code>{\n  \"monitoring_profile\": {\n    \"enabled\": true,\n    \"interval\": 5000000000,\n    \"collect_cpu\": true,\n    \"collect_memory\": true,\n    \"collect_disk_io\": true,\n    \"collect_network_io\": true,\n    \"collect_threads\": true,\n    \"collect_file_descriptors\": true,\n    \"export_to_mqtt\": true,\n    \"retain_history\": true,\n    \"history_size\": 200\n  }\n}\n</code></pre>"},{"location":"reference/#performance-impact","title":"Performance Impact","text":"<p>Measured overhead across platforms:</p> Profile CPU Overhead Memory Overhead Minimal &lt; 0.1% ~1 MB Standard &lt; 0.5% ~2 MB Intensive &lt; 2% ~5 MB"},{"location":"reference/#usage-examples","title":"Usage Examples","text":"<pre><code>task := task.Task{\n    ID:       \"task-123\",\n    Name:     \"compute\",\n    ImageURL: \"registry.example.com/compute:v1\",\n    Daemon:   false,\n    MonitoringProfile: &amp;monitoring.StandardProfile(),\n}\n</code></pre>"},{"location":"reference/#rust-start-task-with-monitoring","title":"Rust - Start Task with Monitoring","text":"<pre><code>{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440001\",\n  \"functionName\": \"compute\",\n  \"imageURL\": \"registry.example.com/compute:v1\",\n  \"daemon\": false,\n  \"monitoringProfile\": {\n    \"enabled\": true,\n    \"interval\": 10,\n    \"collect_cpu\": true,\n    \"collect_memory\": true,\n    \"export_to_mqtt\": true,\n    \"retain_history\": true,\n    \"history_size\": 100\n  }\n}\n</code></pre>"},{"location":"reference/#integration-with-monitoring-systems","title":"Integration with Monitoring Systems","text":""},{"location":"reference/#prometheus","title":"Prometheus","text":"<p>Use MQTT-to-Prometheus exporter:</p> <pre><code>scrape_configs:\n  - job_name: \"propeller\"\n    static_configs:\n      - targets: [\"mqtt-exporter:9641\"]\n</code></pre>"},{"location":"reference/#grafana","title":"Grafana","text":"<p>Create dashboards with:</p> <ul> <li>CPU usage over time</li> <li>Memory consumption trends</li> <li>Disk/Network I/O rates</li> <li>Per-task resource usage</li> </ul>"},{"location":"reference/#custom-monitoring","title":"Custom Monitoring","text":"<p>Subscribe to MQTT topics:</p> <pre><code>mosquitto_sub -h localhost -t \"m/+/c/+/*/metrics\" -v\n</code></pre>"},{"location":"reference/#testing","title":"Testing","text":""},{"location":"reference/#manual-test","title":"Manual Test","text":"<pre><code># Start proplet\n./build/proplet\n\n# Submit a task\ncurl -X POST http://localhost:8080/tasks \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"id\": \"test-123\",\n    \"name\": \"compute\",\n    \"file\": \"...\",\n    \"monitoring_profile\": {\n      \"enabled\": true,\n      \"interval\": 5000000000,\n      \"export_to_mqtt\": true\n    }\n  }'\n\n# Monitor metrics\nmosquitto_sub -h localhost -t \"m/+/c/+/*/metrics\" -v\n</code></pre>"},{"location":"reference/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Manager Integration</li> <li>Aggregate metrics from all proplets</li> <li>Historical metrics storage</li> <li>Metrics API endpoints</li> <li> <p>Alerting on anomalies</p> </li> <li> <p>Advanced Metrics</p> </li> <li>GPU usage (if available)</li> <li>Container-specific metrics (cgroups)</li> <li>Custom application metrics</li> <li> <p>Distributed tracing correlation</p> </li> <li> <p>Optimization</p> </li> <li>Adaptive sampling rates</li> <li>Metric compression</li> <li>Batched MQTT publishing</li> <li> <p>Metrics rollups/aggregation</p> </li> <li> <p>Visualization</p> </li> <li>Built-in dashboards</li> <li>Real-time metric streaming</li> <li>Historical trend analysis</li> <li>Anomaly detection</li> </ol>"},{"location":"reference/#references","title":"References","text":"<ul> <li>Rust Implementation: <code>proplet-rs/src/monitoring/</code></li> <li>Examples: <code>examples/monitoring-example.md</code></li> <li>Rust Docs: <code>proplet-rs/MONITORING.md</code></li> </ul>"},{"location":"zephyr/","title":"Deploying WAMR on Zephyr for ESP32","text":""},{"location":"zephyr/#1-set-up-zephyr-development-environment","title":"1. Set Up Zephyr Development Environment","text":""},{"location":"zephyr/#install-dependencies-on-your-development-machine","title":"Install Dependencies on your development machine","text":"<p>Update your system. For debian based systems you can use the following command:</p> <pre><code>sudo apt update\nsudo apt upgrade\n</code></pre> <p>Install the required tools:</p> <pre><code>sudo apt install --no-install-recommends git cmake ninja-build gperf \\\nccache dfu-util device-tree-compiler wget \\\npython3-dev python3-pip python3-setuptools python3-tk python3-wheel xz-utils file \\\nmake gcc gcc-multilib g++-multilib libsdl2-dev libmagic1\n</code></pre> <p>Verify tool versions:</p> <pre><code>cmake --version\npython3 --version\ndtc --version\n</code></pre> <p>Ensure versions meet the minimum requirements: CMake 3.20.5, Python 3.10, and Devicetree Compiler 1.4.6.</p>"},{"location":"zephyr/#get-zephyr-and-python-dependencies-on-your-development-machine","title":"Get Zephyr and Python Dependencies on your development machine","text":"<p>Install Python venv package::</p> <pre><code>sudo apt install python3-venv\n</code></pre> <p>Create a new virtual environment:</p> <pre><code>python3 -m venv ~/zephyrproject/.venv\n</code></pre> <p>Activate the virtual environment:</p> <pre><code>source ~/zephyrproject/.venv/bin/activate\n</code></pre> <p>Install west:</p> <pre><code>pip install west\n</code></pre> <p>Create a Zephyr workspace and clone the repository:</p> <pre><code>west init ~/zephyrproject\ncd ~/zephyrproject\nwest update\n</code></pre> <p>Export Zephyr CMake package:</p> <pre><code>west zephyr-export\n</code></pre> <p>Install Python dependencies:</p> <pre><code>west packages pip --install\n</code></pre> <p>Install the Zephyr SDK:</p> <pre><code>cd ~/zephyrproject/zephyr\nwest sdk install\n</code></pre> <p>You can also install Zephyr SDK without using the west sdk command, as described in this Zephyr SDK installation guide.</p> <p>Fetch Espressif binary blobs:</p> <pre><code>west blobs fetch hal_espressif\n</code></pre> <p>The <code>ZEPHYR_BASE</code> environment variable is essential for locating Zephyr's core build system, CMake scripts, and modules. Without this variable set, Zephyr tools like <code>west</code> will fail to build applications.</p> <p>To confirm whether the <code>ZEPHYR_BASE</code> environment variable is configured correctly, use the following command:</p> <pre><code>echo $ZEPHYR_BASE\n</code></pre> <p>If the output is empty or incorrect, follow the steps below to set it.</p> <ol> <li>Activate your Zephyr Virtual Environment:</li> </ol> <p>If you're using a virtual environment for Zephyr, activate it first:</p> <pre><code>source ~/zephyrproject/.venv/bin/activate\n</code></pre> <ol> <li>Set the <code>ZEPHYR_BASE</code> Variable:</li> </ol> <p>Once activated, set the <code>ZEPHYR_BASE</code> variable to point to the Zephyr directory:</p> <pre><code>export ZEPHYR_BASE=~/zephyrproject/zephyr\n</code></pre> <ol> <li>Make the Change Permanent:</li> </ol> <p>To ensure the <code>ZEPHYR_BASE</code> variable is set automatically in future sessions, add the following line to your shell's configuration file (<code>.bashrc</code> for Bash or <code>.zshrc</code> for Zsh):</p> <pre><code>export ZEPHYR_BASE=~/zephyrproject/zephyr\n</code></pre> <p>After adding the line, apply the changes by running:</p> <pre><code>source ~/.bashrc   # For Bash users\nsource ~/.zshrc    # For Zsh users\n</code></pre> <ul> <li>For more information on Zephyr environment variables, visit the Zephyr Environment Variables Documentation.</li> <li>For a comprehensive guide on setting up Zephyr, refer to the official Zephyr Getting Started Guide.</li> <li>For board-specific information, such as the Espressif ESP32-S3 DevKitC, refer to the official documentation for setup and configuration details.</li> <li>To see the full list of supported boards, refer to the Zephyr Board Documentation.</li> </ul>"},{"location":"zephyr/#2-install-esp-idf-on-your-development-machine","title":"2. Install ESP-IDF on your development machine","text":"<p>Do not install ESP-IDF inside the Zephyr virtual environment. ESP-IDF is a separate development framework with its own setup and toolchain requirements, which should be installed and managed globally or in its own isolated environment. Global Installation (Preferred). This way, its tools and environment are available for any project on the ESP32, including Zephyr.</p> <p>Without ESP-IDF:</p> <ul> <li>You cannot compile or flash code for the ESP32.</li> <li>Zephyr won\u2019t be able to recognize or support the ESP32-S3 during build or runtime.</li> </ul>"},{"location":"zephyr/#option-1-using-vs-code-extension-recommended","title":"Option 1: Using VS Code Extension (Recommended)","text":"<p>Install the ESP-IDF extension:</p> <ul> <li>Navigate to View &gt; Extensions in VS Code.</li> <li>Search for \"ESP-IDF Extension\" and install it.</li> </ul> <p>Configure the ESP-IDF extension:</p> <ul> <li>Open Command Palette (<code>Ctrl+Shift+P</code> or <code>Cmd+Shift+P</code>).</li> <li>Run <code>ESP-IDF: Configure ESP-IDF Extension</code>.</li> <li>Follow the setup wizard to download and install ESP-IDF.</li> </ul> <p>Ensure correct paths for IDF:</p> <ul> <li>Set <code>IDF_PATH</code> and <code>IDF_TOOLS_PATH</code> appropriately (default: <code>$HOME/.espressif</code>).</li> </ul> <p>Add OpenOCD rules for Linux. The command typically looks like:</p> <pre><code>sudo cp --update=none /home/&lt;username&gt;/.espressif/tools/openocd-esp32/&lt;version&gt;/share/openocd/contrib/60-openocd.rules /etc/udev/rules.d/\n</code></pre> <p>then reload udev rules to apply the changes:</p> <pre><code>sudo udevadm control --reload-rules\nsudo udevadm trigger\n</code></pre> <p>For more detailed information, refer to the official ESP-IDF Extension Guide.</p>"},{"location":"zephyr/#option-2-manual-installation","title":"Option 2: Manual Installation","text":"<p>Download ESP-IDF:</p> <pre><code>mkdir -p ~/esp\ncd ~/esp\nwget https://github.com/espressif/esp-idf/releases/download/v5.3.2/esp-idf-v5.3.2.zip\nunzip esp-idf-v5.3.2.zip -d v5.3.2\n</code></pre> <p>Ensure the directory structure is correct after unzipping. The export script requires paths to be consistent.</p> <p>Export the ESP-IDF environment:</p> <pre><code>source ~/esp/v5.3.2/esp-idf/export.sh\n</code></pre> <p>Run this command in every new terminal session, or automate it by adding the export command to your shell's startup script (~/.bashrc, ~/.zshrc, etc.).</p> <p>Verify the installation:</p> <p>Check the installed ESP-IDF version:</p> <pre><code>idf.py --version\n</code></pre> <p>If the <code>idf.py</code> command fails with <code>command not found</code>, source the ESP-IDF Environment in VS Code. To avoid manually sourcing the <code>export.sh</code> script every time you open a terminal:</p> <ul> <li>Open your shell configuration file (<code>~/.zshrc</code> or <code>~/.bashrc</code>):</li> </ul> <pre><code>nano ~/.zshrc\n</code></pre> <ul> <li>Add this line at the bottom:</li> </ul> <pre><code>source ~/esp/v5.3.2/esp-idf/export.sh\n</code></pre> <ul> <li>Save and reload the shell configuration:</li> </ul> <pre><code>source ~/.zshrc\n</code></pre> <ul> <li> <p>Once the environment is sourced:</p> </li> <li> <p>Check the Xtensa toolchain:</p> <pre><code>xtensa-esp32s3-elf-gcc --version\n</code></pre> </li> <li> <p>Verify <code>idf.py</code> again:</p> <pre><code>idf.py --version\n</code></pre> </li> </ul>"},{"location":"zephyr/#3-test-zephyrs-integration-with-esp-idf","title":"3. Test Zephyr's Integration with ESP-IDF","text":"<p>Navigate to your Zephyr workspace:</p> <pre><code>cd ~/zephyrproject\n</code></pre> <p>Activate the virtual environment. This ensures that Zephyr tools (e.g., west, CMake) and configurations are properly used during the build process.</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Build the Hello World sample:</p> <pre><code>west build -b esp32s3_devkitc/esp32s3/procpu zephyr/samples/hello_world\n</code></pre> <p>Flash the firmware:</p> <pre><code>west flash\n</code></pre> <p>Monitor the output:</p> <pre><code>west espressif monitor\n</code></pre> <p>A successful run shows that the entire build-flash-boot-debug toolchains are functional for your development board.</p> <p>NOTE:</p> <ul> <li>Before building, list all supported boards to verify the correct target name. Look for your desired board in the output of:</li> </ul> <pre><code>west boards\n</code></pre> <p>In Zephyr\u2019s newer versions, boards like esp32s3_devkitc are split into multiple \u201csub-boards\u201d for each core. So instead of building with:</p> <pre><code>west build -b esp32s3_devkitc zephyr/samples/hello_world\n</code></pre> <p>you need to specify which core to target, e.g. <code>esp32s3_devkitc/esp32s3/procpu</code> (for the primary processor core, which we will use in this example) or the <code>esp32s3_devkitc/esp32s3/appcpu</code> (for the application processor core)</p> <ul> <li>If you see the message <code>ninja: no work to do</code>, it means the build system has detected no changes since the last build, and no new compilation is needed. Use the <code>--pristine</code> flag to ensure a completely clean build environment:</li> </ul> <pre><code>west build -b esp32s3_devkitc/esp32s3/procpu zephyr/samples/hello_world --pristine\n</code></pre> <ul> <li>Use <code>west flash --erase</code> if the board has residual firmware causing conflicts.</li> <li>Ensure that <code>west espressif monitor</code> is not running when you attempt to flash the firmware. It keeps the serial port busy, preventing the <code>west flash</code> command from accessing it.</li> </ul>"},{"location":"zephyr/#using-webassembly-micro-runtime-wamr-with-zephyr","title":"Using WebAssembly Micro Runtime (WAMR) with Zephyr","text":""},{"location":"zephyr/#step-1-clone-wamr-repository","title":"Step 1: Clone WAMR repository","text":"<pre><code>cd ~/zephyrproject\ngit clone https://github.com/bytecodealliance/wasm-micro-runtime.git\n</code></pre> <p>After running the above commands, your folder structure will look like this:</p> <pre><code>~/zephyrproject/\n\u251c\u2500\u2500 zephyr/\n\u251c\u2500\u2500 modules/\n\u251c\u2500\u2500 wasm-micro-runtime/\n</code></pre> <p>Note: It's not necessary to clone WAMR inside the <code>zephyrproject</code> folder, but it\u2019s easier to keep everything organized in one place. If you choose to place it elsewhere, you will need to update some configuration files to point to the correct location of the WAMR repository.</p>"},{"location":"zephyr/#step-2-update-cmakeliststxt-optional","title":"Step 2: Update CMakeLists.txt (Optional)","text":"<p>If you decided to place the WAMR repository outside of the <code>zephyrproject</code> folder, you will need to tell Zephyr where to find it. You can do this by updating your <code>CMakeLists.txt</code> file.</p> <p>Add these lines:</p> <pre><code>set(WAMR_ROOT /path/to/wasm-micro-runtime)\ninclude(${WAMR_ROOT}/build-scripts/runtime_lib.cmake)\n</code></pre> <p>Make sure to replace <code>/path/to/wasm-micro-runtime</code> with the actual path where you placed the WAMR source.</p>"},{"location":"zephyr/#step-3-test-your-installation","title":"Step 3: Test Your Installation","text":"<p>To make sure everything is set up correctly, build and run a test application.</p> <ol> <li>Go to the <code>basic</code> sample directory:</li> </ol> <pre><code>cd samples/basic\n</code></pre> <ol> <li>Inside the <code>basic</code> sample folder, you\u2019ll find a script called <code>build.sh</code>. This script compiles both the native application and the WebAssembly (WASM) application. To build the project, run:</li> </ol> <pre><code>./build.sh\n</code></pre> <ol> <li>After the build finishes, you will find the output files in the <code>out</code> directory. To run the test application, go to the <code>out</code> folder:</li> </ol> <pre><code>cd out\n</code></pre> <ol> <li>Run the application with the following command:</li> </ol> <pre><code>./basic -f wasm-apps/testapp.wasm\n</code></pre> <p>You should see output like this:</p> <pre><code>calling into WASM function: generate_float\nNative finished calling wasm function generate_float(), returned a float value: 102009.921875f\ncalling into WASM function: float_to_string\ncalling into native function: intToStr\ncalling into native function: get_pow\ncalling into native function: intToStr\nNative finished calling wasm function: float_to_string, returned a formatted string: 102009.921\n</code></pre>"},{"location":"zephyr/#step-4-clean-build-artifacts","title":"Step 4: Clean Build Artifacts","text":"<p>If you want to clean up the build files, simply run:</p> <pre><code>./build.sh clean\n</code></pre>"},{"location":"zephyr/#step-5-deploy-wamr-on-zephyr-for-esp32","title":"Step 5: Deploy WAMR on Zephyr for ESP32","text":"<p>After testing WAMR locally, deploy it to the ESP32 board using Zephyr.</p> <ol> <li>Go to the WAMR example directory for Zephyr:</li> </ol> <pre><code>cd ~/zephyrproject/wasm-micro-runtime/product-mini/platforms/zephyr/simple\n</code></pre> <ol> <li>If you haven\u2019t already, activate your Zephyr virtual environment:</li> </ol> <pre><code>source ~/zephyrproject/.venv/bin/activate\n</code></pre> <ol> <li>Build the WAMR example for your ESP32 board. Replace <code>&lt;your_board&gt;</code> with your specific board name, like <code>esp32s3_devkitc</code>:</li> </ol> <pre><code>west build -b &lt;your_board&gt;\n</code></pre> <ol> <li>Flash the firmware to your ESP32 board:</li> </ol> <pre><code>west flash\n</code></pre> <ol> <li>To see what's happening on the board, open the serial monitor:</li> </ol> <pre><code>west espressif monitor\n</code></pre>"},{"location":"zephyr/#using-a-webassembly-module-with-zephyr","title":"Using a WebAssembly Module with Zephyr","text":"<p>The sample C code is in <code>src/wasm-app-riscv64/main.c</code>. To generate a <code>.wasm</code> file, run the build script located in <code>src/wasm-app-riscv64/build.sh</code>.</p> <pre><code>./build.sh\n</code></pre> <p>This creates <code>test.wasm</code>, <code>test_wasm.h</code>, and <code>test_wasm_riscv64.h</code>. Replace <code>src/test_wasm.h</code> and <code>src/test_wasm_riscv64.h</code> with the newly generated files from <code>src/wasm-app-riscv64</code>.</p> <p>Build the firmware (replace <code>&lt;your_board&gt;</code> with the board name):</p> <pre><code>west build -b &lt;your_board&gt;\n</code></pre> <p>Flash the firmware:</p> <pre><code>west flash\n</code></pre> <p>Use the serial monitor to see output:</p> <pre><code>west espressif monitor\n</code></pre>"},{"location":"zephyr/#potential-pitfalls-and-solutions","title":"Potential Pitfalls and Solutions","text":""},{"location":"zephyr/#1-permission-denied-for-devttyusb0","title":"1. Permission Denied for <code>/dev/ttyUSB0</code>","text":"<p>Add your user to the <code>dialout</code> group then log out and log back in or restart the system.:</p> <pre><code>sudo usermod -aG dialout $USER\n</code></pre>"},{"location":"zephyr/#2-west-not-found","title":"2. <code>west</code> Not Found","text":"<p>Activate the virtual environment:</p> <pre><code>source ~/zephyrproject/.venv/bin/activate\n</code></pre>"},{"location":"zephyr/#3-build-fails-with-missing-board-qualifiers","title":"3. Build Fails with Missing Board Qualifiers","text":"<p>Use the correct board target as described in The board qualifiers. For ESP32s3, for example:</p> <pre><code>west build -b esp32s3_devkitc/esp32s3/procpu zephyr/samples/hello_world\n</code></pre>"},{"location":"zephyr/#4-serial-port-already-in-use","title":"4. Serial Port Already in Use","text":"<ol> <li>Identify the process using the port and kill it:</li> </ol> <pre><code>lsof /dev/ttyUSB0\nkill &lt;PID&gt;\n</code></pre>"},{"location":"zephyr/#5-cmake-source-directory-mismatch","title":"5. CMake source directory mismatch","text":"<p>Clear the existing CMake cache to resolve the mismatch by deleting the <code>build</code> directory and then re-run the <code>west build</code> command.</p> <pre><code>rm -rf ~/zephyrproject/zephyr/build\n</code></pre>"}]}